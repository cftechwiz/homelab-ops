---
# Source: sumologic/templates/logs/common/pdb.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: sumologic-sumologic-otelcol-logs-pdb
  namespace: monitoring
  labels:
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: sumologic-sumologic-otelcol-logs
  minAvailable: 2
---
# Source: sumologic/templates/metrics/common/pdb.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: sumologic-sumologic-otelcol-metrics-pdb
  namespace: monitoring
  labels:
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: sumologic-sumologic-otelcol-metrics
  minAvailable: 2
---
# Source: sumologic/charts/kube-prometheus-stack/charts/kube-state-metrics/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: kube-state-metrics-4.20.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "2.6.0"
    release: sumologic
  name: sumologic-kube-state-metrics
  namespace: monitoring
imagePullSecrets:
  []
---
# Source: sumologic/charts/kube-prometheus-stack/charts/prometheus-node-exporter/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sumologic-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.3.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/version: "1.3.1"
    jobLabel: node-exporter
    release: sumologic
  annotations:
    {}
imagePullSecrets:
  []
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus-operator/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sumologic-kube-prometheus-operator
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-operator
    app.kubernetes.io/name: kube-prometheus-stack-prometheus-operator
    app.kubernetes.io/component: prometheus-operator

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sumologic-kube-prometheus-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus
    app.kubernetes.io/name: kube-prometheus-stack-prometheus
    app.kubernetes.io/component: prometheus

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
---
# Source: sumologic/templates/logs/collector/otelcol/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sumologic-sumologic-otelcol-logs-collector
  labels:
    app: sumologic-sumologic-otelcol-logs-collector
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
---
# Source: sumologic/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sumologic-sumologic
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/additionalScrapeConfigs.yaml
apiVersion: v1
kind: Secret
metadata:
  name: sumologic-kube-prometheus-prometheus-scrape-confg
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus-scrape-confg

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
data:
  additional-scrape-configs.yaml: "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"
---
# Source: sumologic/templates/chart-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-configmap
  labels:
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  metadataLogs: sumologic-sumologic-metadata-logs
  metadataMetrics: sumologic-sumologic-remote-write-proxy
  metadataNamespace: monitoring
---
# Source: sumologic/templates/events/otelcol/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-otelcol-events
  labels:
    app: sumologic-sumologic-otelcol-events
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  config.yaml: |
    exporters:
      sumologic:
        endpoint: ${SUMO_ENDPOINT_DEFAULT_EVENTS_SOURCE}
        json_logs:
          add_timestamp: true
          timestamp_key: timestamp
        log_format: json
        sending_queue:
          enabled: true
          storage: file_storage
    extensions:
      file_storage:
        directory: /var/lib/storage/events
        timeout: 10s
      health_check: {}
      pprof: {}
    processors:
      batch:
        send_batch_max_size: 2048
        send_batch_size: 1024
        timeout: 1s
      memory_limiter:
        check_interval: 1s
        limit_percentage: 70
        spike_limit_percentage: 20
      resource/add_cluster:
        attributes:
        - action: upsert
          key: cluster
          value: kubernetes
      source:
        collector: kubernetes
        source_category: kubernetes/events
        source_category_prefix: ""
        source_name: events
      sumologic_schema:
        add_cloud_namespace: false
    receivers:
      raw_k8s_events: {}
    service:
      extensions:
      - health_check
      - file_storage
      - pprof
      pipelines:
        logs/events:
          exporters:
          - sumologic
          processors:
          - memory_limiter
          - resource/add_cluster
          - source
          - sumologic_schema
          - batch
          receivers:
          - raw_k8s_events
      telemetry:
        logs:
          level: info
---
# Source: sumologic/templates/instrumentation/otelcol-instrumentation/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-otelcol-instrumentation
  labels:
    app: sumologic-sumologic-otelcol-instrumentation
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  otelcol.instrumentation.conf.yaml: |
    exporters:
      otlphttp/traces:
        endpoint: http://sumologic-sumologic-traces-gateway.monitoring:4318
      sumologic/metrics:
        compress_encoding: gzip
        endpoint: ${SUMO_ENDPOINT_DEFAULT_METRICS_SOURCE}
        log_format: text
        max_request_body_size: 1048576
        metric_format: prometheus
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_elapsed_time: 120s
          max_interval: 30s
        sending_queue:
          enabled: false
          num_consumers: 10
          queue_size: 5000
        timeout: 5s
    extensions:
      health_check: {}
      memory_ballast:
        size_mib: 250
      pprof: {}
    processors:
      batch:
        send_batch_max_size: 512
        send_batch_size: 256
        timeout: 5s
      k8s_tagger:
        extract:
          annotations:
          - key: '*'
            tag_name: k8s.pod.annotation.%s
          labels:
          - key: '*'
            tag_name: k8s.pod.label.%s
          metadata:
          - containerId
          - containerName
          - daemonSetName
          - deploymentName
          - hostName
          - namespace
          - nodeName
          - podId
          - podName
          - replicaSetName
          - serviceName
          - statefulSetName
          namespace_labels:
          - key: '*'
            tag_name: k8s.namespace.label.%s
        owner_lookup_enabled: true
        passthrough: false
      memory_limiter:
        check_interval: 5s
        limit_percentage: 75
        spike_limit_percentage: 20
      resource:
        attributes:
        - action: upsert
          key: k8s.cluster.name
          value: kubernetes
      resourcedetection:
        detectors:
        - system
        override: false
        timeout: 10s
      source:
        annotation_prefix: k8s.pod.annotation.
        collector: "kubernetes"
        exclude:
          k8s.container.name: ""
          k8s.host.name: ""
          k8s.namespace.name: ""
          k8s.pod.name: ""
        pod_key: k8s.pod.name
        pod_name_key: k8s.pod.pod_name
        pod_template_hash_key: k8s.pod.label.pod-template-hash
        source_category: "%{k8s.namespace.name}/%{k8s.pod.pod_name}"
        source_category_prefix: "kubernetes/"
        source_category_replace_dash: "/"
        source_host: '%{k8s.pod.hostname}'
        source_name: "%{k8s.namespace.name}.%{k8s.pod.pod_name}.%{k8s.container.name}"
    receivers:
      jaeger:
        protocols:
          grpc:
            endpoint: 0.0.0.0:14250
          thrift_binary:
            endpoint: 0.0.0.0:6832
          thrift_compact:
            endpoint: 0.0.0.0:6831
          thrift_http:
            endpoint: 0.0.0.0:14268
      opencensus:
        endpoint: 0.0.0.0:55678
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      otlp/deprecated:
        protocols:
          http:
            endpoint: 0.0.0.0:55681
      zipkin:
        endpoint: 0.0.0.0:9411
    service:
      extensions:
      - health_check
      - memory_ballast
      - pprof
      pipelines:
        metrics:
          exporters:
          - sumologic/metrics
          processors:
          - memory_limiter
          - k8s_tagger
          - source
          - resource
          - batch
          receivers:
          - otlp
          - otlp/deprecated
        traces:
          exporters:
          - otlphttp/traces
          processors:
          - memory_limiter
          - k8s_tagger
          - source
          - resource
          - batch
          receivers:
          - jaeger
          - opencensus
          - otlp
          - otlp/deprecated
          - zipkin
---
# Source: sumologic/templates/instrumentation/traces-gateway/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-traces-gateway
  labels:
    app: sumologic-sumologic-traces-gateway
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  traces.gateway.conf.yaml: |
    exporters:
      loadbalancing:
        protocol:
          otlp:
            timeout: 10s
            tls:
              insecure: true
        resolver:
          dns:
            hostname: sumologic-sumologic-traces-sampler-headless.monitoring
            port: 4317
    extensions:
      health_check: {}
      memory_ballast:
        size_mib: 250
      pprof: {}
    processors:
      batch:
        send_batch_max_size: 512
        send_batch_size: 256
        timeout: 5s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 75
        spike_limit_percentage: 20
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    service:
      extensions:
      - health_check
      - memory_ballast
      - pprof
      pipelines:
        traces:
          exporters:
          - loadbalancing
          processors:
          - memory_limiter
          - batch
          receivers:
          - otlp
---
# Source: sumologic/templates/instrumentation/traces-sampler/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-traces-sampler
  labels:
    app: sumologic-sumologic-traces-sampler
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  traces.sampler.conf.yaml: |
    exporters:
      otlphttp:
        compression: gzip
        traces_endpoint: ${SUMO_ENDPOINT_DEFAULT_TRACES_SOURCE}
    extensions:
      health_check: {}
      memory_ballast:
        size_mib: 683
      pprof: {}
    processors:
      batch:
        send_batch_max_size: 512
        send_batch_size: 256
        timeout: 5s
      cascading_filter:
        num_traces: 200000
      memory_limiter:
        check_interval: 5s
        limit_percentage: 75
        spike_limit_percentage: 20
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    service:
      extensions:
      - health_check
      - memory_ballast
      - pprof
      pipelines:
        traces:
          exporters:
          - otlphttp
          processors:
          - memory_limiter
          - cascading_filter
          - batch
          receivers:
          - otlp
---
# Source: sumologic/templates/logs/collector/otelcol/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-otelcol-logs-collector
  labels:
    app: sumologic-sumologic-otelcol-logs-collector
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  config.yaml: |
    exporters:
      otlphttp:
        endpoint: http://${LOGS_METADATA_SVC}.${NAMESPACE}.svc.cluster.local.:4318
    extensions:
      file_storage:
        compaction:
          directory: /var/lib/storage/otc
          on_rebound: true
          on_start: true
        directory: /var/lib/storage/otc
        timeout: 10s
      health_check: {}
      pprof: {}
    processors:
      batch:
        send_batch_max_size: 2000
        send_batch_size: 1000
        timeout: 1s
      logstransform/systemd:
        operators:
        - from: body._SYSTEMD_UNIT
          to: attributes._SYSTEMD_UNIT
          type: copy
        - from: body.SYSLOG_FACILITY
          to: attributes.SYSLOG_FACILITY
          type: copy
        - from: body._HOSTNAME
          to: attributes._HOSTNAME
          type: copy
        - from: body.PRIORITY
          to: attributes.PRIORITY
          type: copy
        - field: attributes["fluent.tag"]
          type: add
          value: EXPR("host." + attributes["_SYSTEMD_UNIT"])
        - field: body.__CURSOR
          type: remove
        - field: body.__MONOTONIC_TIMESTAMP
          type: remove
    receivers:
      filelog/containers:
        fingerprint_size: 17408
        include:
        - /var/log/pods/*/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          output: merge-cri-lines
          parse_to: body
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)( |)(?P<log>.*)$
          timestamp:
            layout: "2006-01-02T15:04:05.000000000-07:00"
            layout_type: gotime
            parse_from: body.time
          type: regex_parser
        - id: parser-containerd
          output: merge-cri-lines
          parse_to: body
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*)( |)(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: body.time
          type: regex_parser
        - id: parser-docker
          output: merge-docker-lines
          parse_to: body
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: body.time
          type: json_parser
        - combine_field: body.log
          combine_with: ""
          id: merge-docker-lines
          is_last_entry: body.log matches "\n$"
          output: strip-trailing-newline
          source_identifier: attributes["log.file.path"]
          type: recombine
        - combine_field: body.log
          combine_with: ""
          id: merge-cri-lines
          is_last_entry: body.logtag == "F"
          output: merge-multiline-logs
          overwrite_with: newest
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: strip-trailing-newline
          output: merge-multiline-logs
          parse_from: body.log
          parse_to: body
          regex: |-
            ^(?P<log>.*)
            $
          type: regex_parser
        - combine_field: body.log
          combine_with: |2+

          id: merge-multiline-logs
          is_first_entry: body.log matches "^\\[?\\d{4}-\\d{1,2}-\\d{1,2}.\\d{2}:\\d{2}:\\d{2}"
          output: extract-metadata-from-filepath
          source_identifier: attributes["log.file.path"]
          type: recombine
        - id: extract-metadata-from-filepath
          parse_from: attributes["log.file.path"]
          regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<run_id>\d+)\.log$
          type: regex_parser
        - from: body.stream
          id: move-attributes
          to: attributes["stream"]
          type: move
        - from: attributes.container_name
          to: attributes["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: attributes["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: attributes["k8s.pod.name"]
          type: move
        - field: attributes.run_id
          type: remove
        - field: attributes.uid
          type: remove
        - field: attributes["log.file.path"]
          type: remove
        - from: body.log
          to: body
          type: move
        storage: file_storage
      journald:
        directory: /var/log/journal
        units:
        - addon-config.service
        - addon-run.service
        - cfn-etcd-environment.service
        - cfn-signal.service
        - clean-ca-certificates.service
        - containerd.service
        - coreos-metadata.service
        - coreos-setup-environment.service
        - coreos-tmpfiles.service
        - dbus.service
        - docker.service
        - efs.service
        - etcd-member.service
        - etcd.service
        - etcd2.service
        - etcd3.service
        - etcdadm-check.service
        - etcdadm-reconfigure.service
        - etcdadm-save.service
        - etcdadm-update-status.service
        - flanneld.service
        - format-etcd2-volume.service
        - kube-node-taint-and-uncordon.service
        - kubelet.service
        - ldconfig.service
        - locksmithd.service
        - logrotate.service
        - lvm2-monitor.service
        - mdmon.service
        - nfs-idmapd.service
        - nfs-mountd.service
        - nfs-server.service
        - nfs-utils.service
        - node-problem-detector.service
        - ntp.service
        - oem-cloudinit.service
        - rkt-gc.service
        - rkt-metadata.service
        - rpc-idmapd.service
        - rpc-mountd.service
        - rpc-statd.service
        - rpcbind.service
        - set-aws-environment.service
        - system-cloudinit.service
        - systemd-timesyncd.service
        - update-ca-certificates.service
        - user-cloudinit.service
        - var-lib-etcd2.service
    service:
      extensions:
      - health_check
      - file_storage
      - pprof
      pipelines:
        logs/containers:
          exporters:
          - otlphttp
          processors:
          - batch
          receivers:
          - filelog/containers
        logs/systemd:
          exporters:
          - otlphttp
          processors:
          - logstransform/systemd
          - batch
          receivers:
          - journald
      telemetry:
        logs:
          level: info
---
# Source: sumologic/templates/logs/otelcol/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-otelcol-logs
  labels:
    app: sumologic-sumologic-otelcol-logs
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  config.yaml: |
    exporters:
      sumologic/containers:
        endpoint: ${SUMO_ENDPOINT_DEFAULT_LOGS_SOURCE}
        json_logs:
          add_timestamp: true
          flatten_body: false
          timestamp_key: timestamp
        log_format: json
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
      sumologic/systemd:
        endpoint: ${SUMO_ENDPOINT_DEFAULT_LOGS_SOURCE}
        json_logs:
          add_timestamp: true
          flatten_body: true
          timestamp_key: timestamp
        log_format: json
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
    extensions:
      file_storage:
        compaction:
          directory: /var/lib/storage/otc
          on_rebound: true
          on_start: true
        directory: /var/lib/storage/otc
        timeout: 10s
      health_check: {}
      pprof: {}
    processors:
      attributes/extract_systemd_source_fields:
        actions:
        - action: extract
          key: fluent.tag
          pattern: ^host\.(?P<_sourceName>[a-zA-z0-9]+)\..+$
        - action: insert
          from_attribute: _HOSTNAME
          key: _sourceHost
      attributes/fluent_containers:
        actions:
        - action: extract
          key: fluent.tag
          pattern: ^containers\.var\.log\.containers\.(?P<k8s_pod_name>[^_]+)_(?P<k8s_namespace>[^_]+)_(?P<k8s_container_name>.+)-(?P<container_id>[a-f0-9]{64})\.log$
        - action: insert
          from_attribute: container_id
          key: k8s.container.id
        - action: delete
          key: container_id
        - action: insert
          from_attribute: k8s_pod_name
          key: k8s.pod.name
        - action: delete
          key: k8s_pod_name
        - action: insert
          from_attribute: k8s_namespace
          key: k8s.namespace.name
        - action: delete
          key: k8s_namespace
        - action: insert
          from_attribute: k8s_container_name
          key: k8s.container.name
        - action: delete
          key: k8s_container_name
      attributes/remove_fluent_tag:
        actions:
        - action: delete
          key: fluent.tag
      batch:
        send_batch_max_size: 2048
        send_batch_size: 1024
        timeout: 1s
      filter/exclude_kubelet:
        logs:
          exclude:
            match_type: strict
            record_attributes:
            - key: _SYSTEMD_UNIT
              value: kubelet.service
      filter/exclude_kubelet_hostname:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: _HOSTNAME
              value: $^
      filter/exclude_kubelet_priority:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: PRIORITY
              value: $^
      filter/exclude_kubelet_syslog:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: SYSLOG_FACILITY
              value: $^
      filter/exclude_kubelet_unit:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: _SYSTEMD_UNIT
              value: $^
      filter/exclude_systemd_hostname:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: _HOSTNAME
              value: $^
      filter/exclude_systemd_priority:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: PRIORITY
              value: $^
      filter/exclude_systemd_syslog:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: SYSLOG_FACILITY
              value: $^
      filter/exclude_systemd_unit:
        logs:
          exclude:
            match_type: regexp
            record_attributes:
            - key: _SYSTEMD_UNIT
              value: $^
      filter/include_containers:
        logs:
          include:
            match_type: regexp
            record_attributes:
            - key: k8s.container.name
              value: .+
      filter/include_fluent_tag_containers:
        logs:
          include:
            match_type: regexp
            record_attributes:
            - key: fluent.tag
              value: containers\..+
      filter/include_fluent_tag_host:
        logs:
          include:
            match_type: regexp
            record_attributes:
            - key: fluent.tag
              value: host\..+
      filter/include_kubelet:
        logs:
          include:
            match_type: strict
            record_attributes:
            - key: _SYSTEMD_UNIT
              value: kubelet.service
      filter/include_systemd:
        logs:
          include:
            match_type: regexp
            record_attributes:
            - key: _SYSTEMD_UNIT
              value: .+
      groupbyattrs/containers:
        keys:
        - k8s.container.id
        - k8s.container.name
        - k8s.namespace.name
        - k8s.pod.name
        - _collector
      groupbyattrs/systemd:
        keys:
        - _sourceName
        - _sourceHost
        - _collector
      k8s_tagger:
        extract:
          annotations:
          - key: '*'
            tag_name: pod_annotations_%s
          delimiter: _
          labels:
          - key: '*'
            tag_name: pod_labels_%s
          metadata:
          - daemonSetName
          - deploymentName
          - hostName
          - namespace
          - nodeName
          - podName
          - serviceName
          - statefulSetName
          namespace_labels:
          - key: '*'
            tag_name: namespace_labels_%s
        owner_lookup_enabled: true
        passthrough: false
        pod_association:
        - from: build_hostname
      logstransform/containers_parse_json:
        operators:
        - if: body matches "^{[\\s\\S]+"
          parse_from: body
          parse_to: body
          type: json_parser
      memory_limiter:
        check_interval: 5s
        limit_percentage: 75
        spike_limit_percentage: 20
      resource/add_cluster:
        attributes:
        - action: upsert
          key: cluster
          value: kubernetes
      resource/containers_copy_node_to_host:
        attributes:
        - action: upsert
          from_attribute: k8s.node.name
          key: k8s.pod.hostname
      resource/drop_annotations:
        attributes:
        - action: delete
          pattern: ^pod_annotations_.*
      resource/remove_pod_name:
        attributes:
        - action: delete
          key: pod_name
      resource/set_empty_source_metadata:
        attributes:
        - action: insert
          key: _sourceCategory
          value: ""
        - action: insert
          key: _sourceHost
          value: ""
        - action: insert
          key: _sourceName
          value: ""
      source/containers:
        annotation_prefix: pod_annotations_
        collector: kubernetes
        container_annotations:
          enabled: false
          prefixes: []
        exclude:
          container: ""
          namespace: ""
          node: ""
          pod: ""
        pod_key: pod
        pod_name_key: pod_name
        pod_template_hash_key: pod_labels_pod-template-hash
        source_category: '%{namespace}/%{pod_name}'
        source_category_prefix: kubernetes/
        source_category_replace_dash: /
        source_host: ""
        source_name: '%{namespace}.%{pod}.%{container}'
      source/kubelet:
        collector: kubernetes
        source_category: kubelet
        source_category_prefix: kubernetes/
        source_category_replace_dash: /
        source_host: '%{_sourceHost}'
        source_name: k8s_kubelet
      source/systemd:
        collector: kubernetes
        source_category: system
        source_category_prefix: kubernetes/
        source_category_replace_dash: /
        source_host: '%{_sourceHost}'
        source_name: '%{_sourceName}'
      sumologic_schema:
        add_cloud_namespace: false
      transform/remove_attributes:
        log_statements:
        - context: log
          statements:
          - limit(attributes, 0, [])
    receivers:
      otlp:
        protocols:
          http:
            endpoint: 0.0.0.0:4318
    service:
      extensions:
      - health_check
      - file_storage
      - pprof
      pipelines:
        logs/otlp/containers:
          exporters:
          - sumologic/containers
          processors:
          - memory_limiter
          - filter/include_containers
          - groupbyattrs/containers
          - k8s_tagger
          - resource/add_cluster
          - resource/set_empty_source_metadata
          - resource/containers_copy_node_to_host
          - sumologic_schema
          - source/containers
          - logstransform/containers_parse_json
          - resource/remove_pod_name
          - resource/drop_annotations
          - batch
          receivers:
          - otlp
        logs/otlp/kubelet:
          exporters:
          - sumologic/systemd
          processors:
          - memory_limiter
          - filter/include_fluent_tag_host
          - filter/include_kubelet
          - filter/exclude_kubelet_syslog
          - filter/exclude_kubelet_hostname
          - filter/exclude_kubelet_priority
          - filter/exclude_kubelet_unit
          - attributes/extract_systemd_source_fields
          - attributes/remove_fluent_tag
          - groupbyattrs/systemd
          - resource/add_cluster
          - source/kubelet
          - transform/remove_attributes
          - batch
          receivers:
          - otlp
        logs/otlp/systemd:
          exporters:
          - sumologic/systemd
          processors:
          - memory_limiter
          - filter/include_fluent_tag_host
          - filter/include_systemd
          - filter/exclude_kubelet
          - filter/exclude_systemd_syslog
          - filter/exclude_systemd_hostname
          - filter/exclude_systemd_priority
          - filter/exclude_systemd_unit
          - attributes/extract_systemd_source_fields
          - attributes/remove_fluent_tag
          - groupbyattrs/systemd
          - resource/add_cluster
          - source/systemd
          - transform/remove_attributes
          - batch
          receivers:
          - otlp
      telemetry:
        logs:
          level: info
---
# Source: sumologic/templates/metrics/otelcol/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-otelcol-metrics
  labels:
    app: sumologic-sumologic-otelcol-metrics
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  config.yaml: |
    exporters:
      sumologic/apiserver:
        endpoint: ${SUMO_ENDPOINT_APISERVER_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
      sumologic/control_plane:
        endpoint: ${SUMO_ENDPOINT_CONTROL_PLANE_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
      sumologic/controller:
        endpoint: ${SUMO_ENDPOINT_CONTROLLER_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
      sumologic/default:
        endpoint: ${SUMO_ENDPOINT_DEFAULT_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
      sumologic/kubelet:
        endpoint: ${SUMO_ENDPOINT_KUBELET_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
      sumologic/node:
        endpoint: ${SUMO_ENDPOINT_NODE_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
      sumologic/scheduler:
        endpoint: ${SUMO_ENDPOINT_SCHEDULER_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
      sumologic/state:
        endpoint: ${SUMO_ENDPOINT_STATE_METRICS_SOURCE}
        max_request_body_size: 16777216
        metric_format: prometheus
        sending_queue:
          enabled: true
          num_consumers: 10
          queue_size: 10000
          storage: file_storage
        timeout: 30s
    extensions:
      file_storage:
        compaction:
          directory: /var/lib/storage/otc
          on_rebound: true
          on_start: true
        directory: /var/lib/storage/otc
        timeout: 10s
      health_check: {}
      pprof: {}
    processors:
      batch:
        send_batch_max_size: 2048
        send_batch_size: 1024
        timeout: 1s
      k8s_tagger:
        extract:
          delimiter: _
          labels:
          - key: '*'
            tag_name: pod_labels_%s
          metadata:
          - daemonSetName
          - deploymentName
          - nodeName
          - replicaSetName
          - serviceName
          - statefulSetName
        owner_lookup_enabled: true
        passthrough: false
        pod_association:
        - from: build_hostname
      memory_limiter:
        check_interval: 5s
        limit_percentage: 75
        spike_limit_percentage: 20
      metricstransform:
        transforms:
          action: update
          include: ^prometheus_remote_write_(.*)$$
          match_type: regexp
          new_name: $$1
      resource:
        attributes:
        - action: upsert
          from_attribute: namespace
          key: k8s.namespace.name
        - action: delete
          key: namespace
        - action: upsert
          from_attribute: pod
          key: k8s.pod.name
        - action: delete
          key: pod
        - action: upsert
          from_attribute: container
          key: k8s.container.name
        - action: delete
          key: container
        - action: upsert
          from_attribute: service
          key: prometheus_service
        - action: delete
          key: service
        - action: upsert
          key: _origin
          value: kubernetes
        - action: upsert
          key: cluster
          value: kubernetes
      resource/delete_source_metadata:
        attributes:
        - action: delete
          key: _sourceCategory
        - action: delete
          key: _sourceHost
        - action: delete
          key: _sourceName
      resource/remove_k8s_pod_pod_name:
        attributes:
        - action: delete
          key: k8s.pod.pod_name
      routing:
        attribute_source: resource
        default_exporters:
        - sumologic/default
        drop_resource_routing_attribute: true
        from_attribute: http_listener_v2_path
        table:
        - exporters:
          - sumologic/apiserver
          value: /prometheus.metrics.apiserver
        - exporters:
          - sumologic/kubelet
          value: /prometheus.metrics.container
        - exporters:
          - sumologic/control_plane
          value: /prometheus.metrics.control-plane.coredns
        - exporters:
          - sumologic/control_plane
          value: /prometheus.metrics.control-plane.kube-etcd
        - exporters:
          - sumologic/controller
          value: /prometheus.metrics.controller-manager
        - exporters:
          - sumologic/kubelet
          value: /prometheus.metrics.kubelet
        - exporters:
          - sumologic/node
          value: /prometheus.metrics.node
        - exporters:
          - sumologic/scheduler
          value: /prometheus.metrics.scheduler
        - exporters:
          - sumologic/state
          value: /prometheus.metrics.state
      source:
        collector: kubernetes
      sumologic_schema:
        add_cloud_namespace: false
    receivers:
      telegraf:
        agent_config: |
          [agent]
            interval = "30s"
            flush_interval = "30s"
            omit_hostname = true
          [[inputs.http_listener_v2]]
            # wait longer than prometheus
            read_timeout = "30s"
            write_timeout = "30s"
            service_address = ":9888"
            data_format = "prometheusremotewrite"
            path_tag = true
            paths = [
              "/prometheus.metrics",
              "/prometheus.metrics.apiserver",
              "/prometheus.metrics.applications.activemq",
              "/prometheus.metrics.applications.apache",
              "/prometheus.metrics.applications.cassandra",
              "/prometheus.metrics.applications.couchbase",
              "/prometheus.metrics.applications.custom",
              "/prometheus.metrics.applications.elasticsearch",
              "/prometheus.metrics.applications.haproxy",
              "/prometheus.metrics.applications.jmx",
              "/prometheus.metrics.applications.kafka",
              "/prometheus.metrics.applications.memcached",
              "/prometheus.metrics.applications.mongodb",
              "/prometheus.metrics.applications.mysql",
              "/prometheus.metrics.applications.nginx",
              "/prometheus.metrics.applications.nginx-ingress",
              "/prometheus.metrics.applications.postgresql",
              "/prometheus.metrics.applications.rabbitmq",
              "/prometheus.metrics.applications.redis",
              "/prometheus.metrics.applications.sqlserver",
              "/prometheus.metrics.applications.squidproxy",
              "/prometheus.metrics.applications.tomcat",
              "/prometheus.metrics.applications.varnish",
              "/prometheus.metrics.container",
              "/prometheus.metrics.control-plane.coredns",
              "/prometheus.metrics.control-plane.kube-etcd",
              "/prometheus.metrics.controller-manager",
              "/prometheus.metrics.kubelet",
              "/prometheus.metrics.node",
              "/prometheus.metrics.operator.rule",
              "/prometheus.metrics.scheduler",
              "/prometheus.metrics.state"
            ]
    service:
      extensions:
      - health_check
      - file_storage
      - pprof
      pipelines:
        metrics:
          exporters:
          - sumologic/default
          - sumologic/apiserver
          - sumologic/control_plane
          - sumologic/controller
          - sumologic/kubelet
          - sumologic/node
          - sumologic/scheduler
          - sumologic/state
          processors:
          - memory_limiter
          - metricstransform
          - resource
          - k8s_tagger
          - source
          - resource/remove_k8s_pod_pod_name
          - resource/delete_source_metadata
          - sumologic_schema
          - batch
          - routing
          receivers:
          - telegraf
      telemetry:
        logs:
          level: info
---
# Source: sumologic/templates/metrics/remote-write-proxy/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumologic-sumologic-remote-write-proxy
  labels:
    app: sumologic-sumologic-remote-write-proxy
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
    remote-write-proxy.conf: |
      upstream remote {
          server sumologic-sumologic-metadata-metrics:9888;
      }

      server {
          listen 8080 default_server;

          location / {
              client_body_buffer_size 64k;
              proxy_pass http://remote;
          }
      }
---
# Source: sumologic/charts/kube-prometheus-stack/charts/kube-state-metrics/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    helm.sh/chart: kube-state-metrics-4.20.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "2.6.0"
    release: sumologic
  name: sumologic-kube-state-metrics
rules:

- apiGroups: ["certificates.k8s.io"]
  resources:
  - certificatesigningrequests
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - cronjobs
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - daemonsets
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - deployments
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - endpoints
  verbs: ["list", "watch"]

- apiGroups: ["autoscaling"]
  resources:
  - horizontalpodautoscalers
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - jobs
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - limitranges
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - mutatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - namespaces
  verbs: ["list", "watch"]

- apiGroups: ["networking.k8s.io"]
  resources:
  - networkpolicies
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - nodes
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumeclaims
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumes
  verbs: ["list", "watch"]

- apiGroups: ["policy"]
  resources:
    - poddisruptionbudgets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - pods
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - replicasets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - replicationcontrollers
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - resourcequotas
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - secrets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - services
  verbs: ["list", "watch"]

- apiGroups: ["apps"]
  resources:
  - statefulsets
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - storageclasses
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - validatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - volumeattachments
  verbs: ["list", "watch"]
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus-operator/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: sumologic-kube-prometheus-operator
  labels:
    app: kube-prometheus-stack-operator

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
rules:
- apiGroups:
  - monitoring.coreos.com
  resources:
  - alertmanagers
  - alertmanagers/finalizers
  - alertmanagerconfigs
  - prometheuses
  - prometheuses/status
  - prometheuses/finalizers
  - thanosrulers
  - thanosrulers/finalizers
  - servicemonitors
  - podmonitors
  - probes
  - prometheusrules
  verbs:
  - '*'
- apiGroups:
  - apps
  resources:
  - statefulsets
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - list
  - delete
- apiGroups:
  - ""
  resources:
  - services
  - services/finalizers
  - endpoints
  verbs:
  - get
  - create
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: sumologic-kube-prometheus-prometheus
  labels:
    app: kube-prometheus-stack-prometheus

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
rules:
# This permission are not in the kube-prometheus repo
# they're grabbed from https://github.com/prometheus/prometheus/blob/master/documentation/examples/rbac-setup.yml
- apiGroups: [""]
  resources:
  - nodes
  - nodes/metrics
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - "networking.k8s.io"
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics", "/metrics/cadvisor"]
  verbs: ["get"]
---
# Source: sumologic/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: sumologic-sumologic
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
rules:
- apiGroups: ["", "apps", "extensions", "events.k8s.io"]
  resources:
  - configmaps
  - daemonsets
  - deployments
  - endpoints
  - events
  - namespaces
  - nodes
  - pods
  - replicasets
  - services
  - statefulsets
  verbs: ["get", "list", "watch"]
- apiGroups: ["batch"]
  resources:
  - cronjobs
  - jobs
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
    - configmaps
  verbs: ["create", "patch"]
---
# Source: sumologic/charts/kube-prometheus-stack/charts/kube-state-metrics/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    helm.sh/chart: kube-state-metrics-4.20.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "2.6.0"
    release: sumologic
  name: sumologic-kube-state-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: sumologic-kube-state-metrics
subjects:
- kind: ServiceAccount
  name: sumologic-kube-state-metrics
  namespace: monitoring
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus-operator/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: sumologic-kube-prometheus-operator
  labels:
    app: kube-prometheus-stack-operator

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: sumologic-kube-prometheus-operator
subjects:
- kind: ServiceAccount
  name: sumologic-kube-prometheus-operator
  namespace: monitoring
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: sumologic-kube-prometheus-prometheus
  labels:
    app: kube-prometheus-stack-prometheus

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: sumologic-kube-prometheus-prometheus
subjects:
  - kind: ServiceAccount
    name: sumologic-kube-prometheus-prometheus
    namespace: monitoring
---
# Source: sumologic/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: sumologic-sumologic
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
subjects:
- kind: ServiceAccount
  namespace: monitoring
  name: sumologic-sumologic
roleRef:
  kind: ClusterRole
  name: sumologic-sumologic
  apiGroup: rbac.authorization.k8s.io
---
# Source: sumologic/charts/kube-prometheus-stack/charts/kube-state-metrics/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-kube-state-metrics
  namespace: monitoring
  labels:
    helm.sh/chart: kube-state-metrics-4.20.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "2.6.0"
    release: sumologic
  annotations:
    prometheus.io/scrape: 'true'
spec:
  type: "ClusterIP"
  ports:
  - name: "http"
    protocol: TCP
    port: 8080
    targetPort: 8080

  selector:
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: sumologic
---
# Source: sumologic/charts/kube-prometheus-stack/charts/prometheus-node-exporter/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.3.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/version: "1.3.1"
    jobLabel: node-exporter
    release: sumologic
  annotations:
    prometheus.io/scrape: "true"
spec:
  type: ClusterIP
  ports:
    - port: 9100
      targetPort: 9100
      protocol: TCP
      name: http-metrics
  selector:
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/name: prometheus-node-exporter
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus-operator/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-kube-prometheus-operator
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-operator

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  ports:
  - name: http
    port: 8080
    targetPort: http
  selector:
    app: kube-prometheus-stack-operator
    release: "sumologic"
  type: "ClusterIP"
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-kube-prometheus-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus
    self-monitor: "true"

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  ports:
  - name: http-web
    port: 9090
    targetPort: 9090
  publishNotReadyAddresses: false
  selector:
    app.kubernetes.io/name: prometheus
    prometheus: sumologic-kube-prometheus-prometheus
  type: "ClusterIP"
---
# Source: sumologic/templates/events/common/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-otelcol-events-headless
  labels:
    app: sumologic-sumologic-otelcol-events-headless
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
    sumologic.com/app: otelcol-events
    sumologic.com/component: events
spec:
  selector:
    app: sumologic-sumologic-otelcol-events
  clusterIP: None
  ports:
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP
  - name: otelcol-metrics
    port: 8888
    targetPort: 8888
    protocol: TCP
---
# Source: sumologic/templates/events/common/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-otelcol-events
  labels:
    app: sumologic-sumologic-otelcol-events
    sumologic.com/scrape: "true"
    sumologic.com/app: otelcol-events
    sumologic.com/component: events
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    app: sumologic-sumologic-otelcol-events
  ports:
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP
  - name: otelcol-metrics
    port: 8888
    targetPort: 8888
    protocol: TCP
---
# Source: sumologic/templates/instrumentation/otelcol-instrumentation/service-deprecated-otelcol.yaml
# Service will point to otelcolInstrumentation as deprecated and after 2023-01-15 should be removed.


apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-otelcol
  labels:
    app: sumologic-sumologic-otelcol-instrumentation
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    app: sumologic-sumologic-otelcol-instrumentation
  # In case of changes related to open ports for otelcol please update NOTES.TXT
  ports:
  - name: jaeger-sampling # Default endpoint for Jaeger Sampling (if enabled)
    port: 5778
  - name: jaeger-thrift-compact # Default endpoint for Jaeger Thrift Compact receiver.
    port: 6831
    protocol: UDP
  - name: jaeger-thrift-binary # Default endpoint for Jaeger Thrift Binary receiver.
    port: 6832
    protocol: UDP
  - name: metrics # Default endpoint for querying metrics.
    port: 8888
  - name: zipkin # Default endpoint for Zipkin receiver.
    port: 9411
  - name: jaeger-grpc  # Default endpoint for Jaeger gRPC
    port: 14250
  - name: jaegert-channel  # Default endpoint for Jaeger TChannel receiver.
    port: 14267
  - name: jaeger-thrift-http # Default endpoint for Jaeger HTTP receiver.
    port: 14268
  - name: opencensus # Default endpoint for Opencensus receiver.
    port: 55678
  - name: otlp-grpc # Default endpoint for OTLP gRPC receiver.
    port: 4317
  - name: otlp-http # Default endpoint for OTLP HTTP receiver.
    port: 4318
  - name: otlp-grpc-old # Old endpoint for OTLP gRPC receiver.
    port: 55680
  - name: otlp-http-old # Default endpoint for OTLP HTTP receiver.
    port: 55681
---
# Source: sumologic/templates/instrumentation/otelcol-instrumentation/service-otelagent.yaml
# Service will point to otelcolInstrumentation.


apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-otelagent
  labels:
    app: sumologic-sumologic-otelcol-instrumentation
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    app: sumologic-sumologic-otelcol-instrumentation
  # In case of changes related to open ports for otelcol please update NOTES.TXT
  ports:
  - name: jaeger-sampling # Default endpoint for Jaeger Sampling (if enabled)
    port: 5778
  - name: jaeger-thrift-compact # Default endpoint for Jaeger Thrift Compact receiver.
    port: 6831
    protocol: UDP
  - name: jaeger-thrift-binary # Default endpoint for Jaeger Thrift Binary receiver.
    port: 6832
    protocol: UDP
  - name: metrics # Default endpoint for querying metrics.
    port: 8888
  - name: zipkin # Default endpoint for Zipkin receiver.
    port: 9411
  - name: jaeger-grpc  # Default endpoint for Jaeger gRPC
    port: 14250
  - name: jaegert-channel  # Default endpoint for Jaeger TChannel receiver.
    port: 14267
  - name: jaeger-thrift-http # Default endpoint for Jaeger HTTP receiver.
    port: 14268
  - name: opencensus # Default endpoint for Opencensus receiver.
    port: 55678
  - name: otlp-grpc # Default endpoint for OTLP gRPC receiver.
    port: 4317
  - name: otlp-http # Default endpoint for OTLP HTTP receiver.
    port: 4318
  - name: otlp-grpc-old # Old endpoint for OTLP gRPC receiver.
    port: 55680
  - name: otlp-http-old # Default endpoint for OTLP HTTP receiver.
    port: 55681
---
# Source: sumologic/templates/instrumentation/traces-gateway/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-traces-gateway
  labels:
    app: sumologic-sumologic-traces-gateway
    sumologic.com/scrape: "true"
    sumologic.com/component: traces
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    app: sumologic-sumologic-traces-gateway
    component: sumologic-sumologic-traces-gateway-component
  ports:
  - name: pprof
    port: 1777
  - name: metrics # Default endpoint for querying metrics.
    port: 8888
  - name: otlp-grpc # Default endpoint for OTLP gRPC receiver.
    port: 4317
  - name: otlp-http # Default endpoint for OTLP HTTP receiver.
    port: 4318
---
# Source: sumologic/templates/instrumentation/traces-sampler/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-traces-sampler-headless
  labels:
    app: sumologic-sumologic-traces-sampler-headless
    sumologic.com/scrape: "true"
    sumologic.com/component: traces
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  # Otel DNS load balancing requires collector service to be headless
  # in order to skip k8s load balancing and instead populate DNS records.
  clusterIP: None
  selector:
    app: sumologic-sumologic-traces-sampler
  ports:
  - name: pprof
    port: 1777
  - name: metrics # Default endpoint for querying metrics.
    port: 8888
  - name: otlp-grpc # Default endpoint for OTLP gRPC receiver.
    port: 4317
  - name: otlp-http # Default endpoint for OTLP HTTP receiver.
    port: 4318
---
# Source: sumologic/templates/logs/collector/otelcol/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-otelcol-logs-collector
  labels:
    app: sumologic-sumologic-otelcol-logs-collector
    sumologic.com/scrape: "true"
    sumologic.com/app: otelcol-logs-collector
    sumologic.com/component: logs
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    app.kubernetes.io/name: sumologic-sumologic-otelcol-logs-collector
  ports:
  - name: metrics
    port: 8888
    targetPort: 8888
    protocol: TCP
---
# Source: sumologic/templates/logs/common/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-otelcol-logs-headless
  labels:
    app: sumologic-sumologic-otelcol-logs-headless
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
    sumologic.com/app: fluentd-logs
    sumologic.com/component: logs
spec:
  selector:
    app: sumologic-sumologic-otelcol-logs
  clusterIP: None
  ports:
  - name: otlphttp
    port: 4318
    targetPort: 4318
    protocol: TCP
  - name: fluent-bit
    port: 24321
    targetPort: 24321
    protocol: TCP
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP
---
# Source: sumologic/templates/logs/common/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-metadata-logs
  labels:
    app: sumologic-sumologic-otelcol-logs
    sumologic.com/scrape: "true"
    sumologic.com/app: fluentd-logs
    sumologic.com/component: logs
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    app: sumologic-sumologic-otelcol-logs
  ports:
  - name: otlphttp
    port: 4318
    targetPort: 4318
    protocol: TCP
  - name: fluent-bit
    port: 24321
    targetPort: 24321
    protocol: TCP
  - name: otelcol-metrics
    port: 8888
    targetPort: 8888
    protocol: TCP
---
# Source: sumologic/templates/metrics/common/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-otelcol-metrics-headless
  labels:
    app: sumologic-sumologic-otelcol-metrics-headless
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
    sumologic.com/app: fluentd-metrics
    sumologic.com/component: metrics
spec:
  selector:
    app: sumologic-sumologic-otelcol-metrics
  clusterIP: None
  ports:
  - name: prom-write
    port: 9888
    targetPort: 9888
    protocol: TCP
  - name: metrics
    port: 24231
    targetPort: 24231
    protocol: TCP
---
# Source: sumologic/templates/metrics/common/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-metadata-metrics
  labels:
    app: sumologic-sumologic-otelcol-metrics
    sumologic.com/scrape: "true"
    sumologic.com/app: fluentd-metrics
    sumologic.com/component: metrics
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    app: sumologic-sumologic-otelcol-metrics
  ports:
  - name: prom-write
    port: 9888
    targetPort: 9888
    protocol: TCP
  - name: otelcol-metrics
    port: 8888
    targetPort: 8888
    protocol: TCP
---
# Source: sumologic/templates/metrics/remote-write-proxy/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumologic-sumologic-remote-write-proxy
  labels:
    app: sumologic-sumologic-remote-write-proxy
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  ports:
    - name: http
      port: 9888
      targetPort: 8080
  selector:
    app: sumologic-sumologic-remote-write-proxy
---
# Source: sumologic/charts/kube-prometheus-stack/charts/prometheus-node-exporter/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: sumologic-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.3.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/version: "1.3.1"
    jobLabel: node-exporter
    release: sumologic
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: sumologic
      app.kubernetes.io/name: prometheus-node-exporter
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        helm.sh/chart: prometheus-node-exporter-4.3.0
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: metrics
        app.kubernetes.io/part-of: prometheus-node-exporter
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/name: prometheus-node-exporter
        app.kubernetes.io/version: "1.3.1"
        jobLabel: node-exporter
        release: sumologic
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    spec:
      automountServiceAccountToken: false
      serviceAccountName: sumologic-prometheus-node-exporter
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      containers:
        - name: node-exporter
          image: quay.io/prometheus/node-exporter:v1.3.1
          imagePullPolicy: IfNotPresent
          args:
            - --path.procfs=/host/proc
            - --path.sysfs=/host/sys
            - --path.rootfs=/host/root
            - --web.listen-address=[$(HOST_IP)]:9100
            - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/.+)($|/)
            - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|iso9660|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tracefs)$
          env:
          - name: HOST_IP
            value: 0.0.0.0
          ports:
            - name: http-metrics
              containerPort: 9100
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              httpHeaders:
              path: /
              port: 9100
              scheme: HTTP
            initialDelaySeconds: 0
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              httpHeaders:
              path: /
              port: 9100
              scheme: HTTP
            initialDelaySeconds: 0
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            {}
          volumeMounts:
            - name: proc
              mountPath: /host/proc
              readOnly:  true
            - name: sys
              mountPath: /host/sys
              readOnly: true
            - name: root
              mountPath: /host/root
              mountPropagation: HostToContainer
              readOnly: true
      hostNetwork: true
      hostPID: true
      tolerations:
        - effect: NoSchedule
          operator: Exists
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: sys
          hostPath:
            path: /sys
        - name: root
          hostPath:
            path: /
---
# Source: sumologic/templates/logs/collector/otelcol/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: sumologic-sumologic-otelcol-logs-collector
  labels:
    app: sumologic-sumologic-otelcol-logs-collector
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: sumologic-sumologic-otelcol-logs-collector
  template:
    metadata:
      annotations:
        checksum/config: 61b7bd674b832a66cdf8a290e2fd5d17ee94b97652042877c01279dbe963ee99
      labels:
        app.kubernetes.io/name: sumologic-sumologic-otelcol-logs-collector
        app.kubernetes.io/app-name: sumologic-sumologic-otelcol-logs-collector
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      securityContext:
        fsGroup: 0
        runAsGroup: 0
        runAsUser: 0
      priorityClassName: "sumologic-sumologic-priorityclass"
      containers:
      - args:
        - --config=/etc/otelcol/config.yaml
        image: public.ecr.aws/sumologic/sumologic-otel-collector:0.69.0-sumo-0
        imagePullPolicy: IfNotPresent
        name: otelcol
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 100m
            memory: 32Mi
        volumeMounts:
        - mountPath: /etc/otelcol
          name: otelcol-config
        - mountPath: /var/log/pods
          name: varlogpods
          readOnly: true
        - mountPath: /var/lib/docker/containers
          name: varlibdockercontainers
          readOnly: true
        - mountPath: /var/lib/storage/otc
          name: file-storage
        - mountPath: /var/log/journal
          name: varlogjournal
          readOnly: true
        env:
        - name: LOGS_METADATA_SVC
          valueFrom:
            configMapKeyRef:
              name: sumologic-configmap
              key: metadataLogs
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        securityContext:
          capabilities:
            drop:
            - ALL
        ports:
        - name: pprof
          containerPort: 1777
          protocol: TCP
        - name: metrics
          containerPort: 8888
          protocol: TCP
      initContainers: # ensure the host path is owned by the otel user group
      - name: changeowner
        image: public.ecr.aws/docker/library/busybox:latest
        securityContext:
          capabilities:
            add:
            - CAP_CHOWN
            drop:
            - ALL
        command:
        - "sh"
        - "-c"
        - |
          chown -R \
            0:0 \
            /var/lib/storage/otc
        volumeMounts:
        - mountPath: /var/lib/storage/otc
          name: file-storage
      volumes:
      - configMap:
          defaultMode: 420
          items:
          - key: config.yaml
            path: config.yaml
          name: sumologic-sumologic-otelcol-logs-collector
        name: otelcol-config
      - hostPath:
          path: /var/log/pods
          type: ""
        name: varlogpods
      - hostPath:
          path: /var/lib/docker/containers
          type: ""
        name: varlibdockercontainers
      - hostPath:
          path: /var/lib/otc
          type: DirectoryOrCreate
        name: file-storage
      - hostPath:
          path: /var/log/journal/
          type: ""
        name: varlogjournal
      serviceAccountName: sumologic-sumologic-otelcol-logs-collector
---
# Source: sumologic/charts/kube-prometheus-stack/charts/kube-state-metrics/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sumologic-kube-state-metrics
  namespace: monitoring
  labels:
    helm.sh/chart: kube-state-metrics-4.20.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "2.6.0"
    release: sumologic
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/instance: sumologic
  replicas: 1
  template:
    metadata:
      labels:
        helm.sh/chart: kube-state-metrics-4.20.2
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: metrics
        app.kubernetes.io/part-of: kube-state-metrics
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "2.6.0"
        release: sumologic
    spec:
      hostNetwork: false
      serviceAccountName: sumologic-kube-state-metrics
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsUser: 65534
      containers:
      - name: kube-state-metrics
        args:
        - --port=8080
        - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
        imagePullPolicy: IfNotPresent
        image: "registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.6.0"
        ports:
        - containerPort: 8080
          name: "http"
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus-operator/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sumologic-kube-prometheus-operator
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-operator

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kube-prometheus-stack-operator
      release: "sumologic"
  template:
    metadata:
      labels:
        app: kube-prometheus-stack-operator

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "40.5.0"
        app.kubernetes.io/part-of: kube-prometheus-stack
        chart: kube-prometheus-stack-40.5.0
        release: "sumologic"
        heritage: "Helm"
    spec:
      containers:
        - name: kube-prometheus-stack
          image: "quay.io/prometheus-operator/prometheus-operator:v0.59.2"
          imagePullPolicy: "IfNotPresent"
          args:
            - --kubelet-service=kube-system/sumologic-kube-prometheus-kubelet
            - --localhost=127.0.0.1
            - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.59.2
            - --config-reloader-cpu-request=200m
            - --config-reloader-cpu-limit=200m
            - --config-reloader-memory-request=50Mi
            - --config-reloader-memory-limit=50Mi
            - --thanos-default-base-image=quay.io/thanos/thanos:v0.28.0
          ports:
            - containerPort: 8080
              name: http
          resources:
            {}
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: sumologic-kube-prometheus-operator
---
# Source: sumologic/templates/instrumentation/traces-gateway/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sumologic-sumologic-traces-gateway
  labels:
    app: sumologic-sumologic-traces-gateway
    component: sumologic-sumologic-traces-gateway-component
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  minReadySeconds: 5
  replicas: 1
  selector:
    matchLabels:
      app: sumologic-sumologic-traces-gateway
      component: sumologic-sumologic-traces-gateway-component
  template:
    metadata:
      annotations:
        checksum/config: 7757458d16d88c9a50f2c095e0a31ba80ebd1c4cd5cc4fd207fd6685bc891497
      labels:
        app: sumologic-sumologic-traces-gateway
        component: sumologic-sumologic-traces-gateway-component
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      serviceAccountName: sumologic-sumologic
      # Otel agent quits if the load balancing backend (collector/samples) is
      # not ready during first connect attempt. Restart policy `Always` guarantees that
      # the agent will have a chance to retry when collector is ready.
      restartPolicy: Always
      containers:
      - name: otelcol
        image: public.ecr.aws/sumologic/sumologic-otel-collector:0.69.0-sumo-0
        imagePullPolicy: IfNotPresent
        args:
          - "--config=/conf/traces.gateway.conf.yaml"
        env:
        - name: GOGC
          value: "80"
        - name: SUMO_ENDPOINT_DEFAULT_TRACES_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-traces
        - name: SUMO_ENDPOINT_DEFAULT_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics
        - name: NO_PROXY
          value: kubernetes.default.svc
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 50m
            memory: 196Mi
        ports:
        - name: pprof
          containerPort: 1777
          protocol: TCP
        - containerPort: 5778  # Default endpoint for Jaeger Sampling.
        - containerPort: 6831  # Default endpoint for Jaeger Thrift Compact receiver.
          protocol: UDP
        - containerPort: 6832  # Default endpoint for Jaeger Thrift Binary receiver.
          protocol: UDP
        - containerPort: 8888  # Default endpoint for querying metrics.
        - containerPort: 9411  # Default endpoint for Zipkin receiver.
        - containerPort: 14250 # Default endpoint for Jaeger gRPC receiver.
        - containerPort: 14267 # Default endpoint for Jaeger TChannel receiver.
        - containerPort: 14268 # Default endpoint for Jaeger HTTP receiver.
        - containerPort: 55678 # Default endpoint for Opencensus receiver.
        - containerPort: 4317  # Default endpoint for OTLP receiver.
        - containerPort: 4318  # Default endpoint for OTLP HTTP receiver.
        - containerPort: 55680 # Old endpoint for OTLP gRPC receiver.
        - containerPort: 55681 # Default endpoint for OTLP HTTP receiver. (deprecated)
        volumeMounts:
        - name: tracesgateway-config-vol
          mountPath: /conf
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          periodSeconds: 15
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          periodSeconds: 10
          timeoutSeconds: 3
        startupProbe:
          httpGet:
            path: /
            port: 13133
          failureThreshold: 60
          periodSeconds: 5
          timeoutSeconds: 3
      volumes:
        - configMap:
            name: sumologic-sumologic-traces-gateway
          name: tracesgateway-config-vol
---
# Source: sumologic/templates/instrumentation/traces-sampler/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sumologic-sumologic-traces-sampler
  labels:
    app: sumologic-sumologic-traces-sampler
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  minReadySeconds: 5
  progressDeadlineSeconds: 120
  replicas: 1
  selector:
    matchLabels:
      app: sumologic-sumologic-traces-sampler
  template:
    metadata:
      annotations:
        checksum/config: af219a21b88bae001e471be72cadf7b2dfe41aa81c911e5d22ca1643063c58a0
      labels:
        app: sumologic-sumologic-traces-sampler
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      serviceAccountName: sumologic-sumologic
      containers:
      - name: otelcol
        image: public.ecr.aws/sumologic/sumologic-otel-collector:0.69.0-sumo-0
        imagePullPolicy: IfNotPresent
        args:
          - --config=/conf/traces.sampler.conf.yaml
        env:
        - name: GOGC
          value: "80"
        - name: SUMO_ENDPOINT_DEFAULT_TRACES_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-traces
        - name: NO_PROXY
          value: kubernetes.default.svc
        resources:
          limits:
            cpu: 2000m
            memory: 4Gi
          requests:
            cpu: 200m
            memory: 384Mi
        ports:
        - name: pprof
          containerPort: 1777
          protocol: TCP
        - containerPort: 5778  # Default endpoint for Jaeger Sampling.
        - containerPort: 6831  # Default endpoint for Jaeger Thrift Compact receiver.
          protocol: UDP
        - containerPort: 6832  # Default endpoint for Jaeger Thrift Binary receiver.
          protocol: UDP
        - containerPort: 8888  # Default endpoint for querying metrics.
        - containerPort: 9411  # Default endpoint for Zipkin receiver.
        - containerPort: 14250 # Default endpoint for Jaeger gRPC receiver.
        - containerPort: 14267 # Default endpoint for Jaeger TChannel receiver.
        - containerPort: 14268 # Default endpoint for Jaeger HTTP receiver.
        - containerPort: 55678 # Default endpoint for Opencensus receiver.
        - containerPort: 4317  # Default endpoint for OTLP gRPC receiver.
        - containerPort: 4318  # Default endpoint for OTLP HTTP receiver.
        - containerPort: 55680 # Old endpoint for OTLP gRPC receiver.
        - containerPort: 55681 # Default endpoint for OTLP HTTP receiver. (deprecated)
        volumeMounts:
        - name: otel-collector-config-vol
          mountPath: /conf
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
      volumes:
        - configMap:
            name: sumologic-sumologic-traces-sampler
          name: otel-collector-config-vol
---
# Source: sumologic/templates/metrics/remote-write-proxy/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sumologic-sumologic-remote-write-proxy
  labels:
    app: sumologic-sumologic-remote-write-proxy
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: sumologic-sumologic-remote-write-proxy
  replicas: 3
  template:
    metadata:
      annotations:
        checksum/config: 3cebc26cc5a96177ef96f0b7401136020f72211c978cca6055edcc4d112ffe0c
      labels:
        app: sumologic-sumologic-remote-write-proxy
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      securityContext:
        {}
      containers:
      - name: nginx
        image: public.ecr.aws/sumologic/nginx-unprivileged:1.23.1-alpine
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
        resources:
          limits:
            cpu: 1000m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        livenessProbe:
          tcpSocket:
            port: 8080
          failureThreshold: 6
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          tcpSocket:
            port: 8080
          failureThreshold: 3
          initialDelaySeconds: 5
          periodSeconds: 5
          successThreshold: 1
          timeoutSeconds: 3
        env:
        # this setting makes the entrypoint automatically set the number of worker processes based
        # on cpu limit data, by using the cgroups API
        - name: NGINX_ENTRYPOINT_WORKER_PROCESSES_AUTOTUNE
          value: "1"
        volumeMounts:
          - name: config
            mountPath: /etc/nginx/conf.d/remote-write-proxy.conf
            subPath: remote-write-proxy.conf
      volumes:
        - name: config
          configMap:
            name: sumologic-sumologic-remote-write-proxy
---
# Source: sumologic/templates/events/otelcol/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sumologic-sumologic-otelcol-events
  labels:
    app: sumologic-sumologic-otelcol-events
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: sumologic-sumologic-otelcol-events
  serviceName: sumologic-sumologic-otelcol-events-headless
  podManagementPolicy: "Parallel"
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/config: b4b8d1223dcebb45201b657191efc66de2b717b9ae3da5576e469fd7cc2eb9fc
      labels:
        app: sumologic-sumologic-otelcol-events
        sumologic.com/scrape: "true"
        sumologic.com/app: otelcol-events
        sumologic.com/component: events
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      serviceAccountName: sumologic-sumologic
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - sumologic-sumologic-otelcol-logs
                  - sumologic-sumologic-otelcol-events
                - key: app
                  operator: In
                  values:
                  - prometheus-operator-prometheus
              topologyKey: "kubernetes.io/hostname"
      volumes:
      - name: config-volume
        configMap:
          name: sumologic-sumologic-otelcol-events
      securityContext:
        fsGroup: 999
      containers:
      - name: otelcol
        image: public.ecr.aws/sumologic/sumologic-otel-collector:0.69.0-sumo-0
        imagePullPolicy: IfNotPresent
        args:
          - --config=/etc/otel/config.yaml
        resources:
          limits:
            cpu: 2000m
            memory: 2Gi
          requests:
            cpu: 200m
            memory: 500Mi
        ports:
        - name: metrics
          containerPort: 8888
          protocol: TCP
        - name: pprof
          containerPort: 1777
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 15
          periodSeconds: 15
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
        startupProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 60
          periodSeconds: 3
        volumeMounts:
        - name: config-volume
          mountPath: /etc/otel/config.yaml
          subPath: config.yaml
        - name: file-storage
          mountPath: /var/lib/storage/events
        env:
        - name: SUMO_ENDPOINT_DEFAULT_EVENTS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-events
        - name: NO_PROXY
          value: kubernetes.default.svc
  volumeClaimTemplates:
  - metadata:
      name: file-storage
    spec:
      accessModes: [ReadWriteOnce]
      storageClassName:
      resources:
        requests:
          storage: 10Gi
---
# Source: sumologic/templates/instrumentation/otelcol-instrumentation/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sumologic-sumologic-otelcol-instrumentation
  labels:
    app: sumologic-sumologic-otelcol-instrumentation
    component: sumologic-sumologic-otelcol-instrumentation-component
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: sumologic-sumologic-otelcol-instrumentation
  serviceName: sumologic-sumologic-otelcol-instrumentation
  podManagementPolicy: "Parallel"
  replicas: 3
  template:
    metadata:
      annotations:
        checksum/config: 9793a6860f56ddb737fac3dccb5fe82907e9c1d5ec13be5792b6ad2e7e728c65
      labels:
        app: sumologic-sumologic-otelcol-instrumentation
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      serviceAccountName: sumologic-sumologic
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - sumologic-sumologic-otelcol-instrumentation
                - key: app
                  operator: In
                  values:
                  - prometheus-operator-prometheus
              topologyKey: "kubernetes.io/hostname"
      volumes:
        - configMap:
            name: sumologic-sumologic-otelcol-instrumentation
          name: otelcolinstrumentation-config-vol
      securityContext:
        fsGroup: 999
      containers:
      - name: otelcol
        image: public.ecr.aws/sumologic/sumologic-otel-collector:0.69.0-sumo-0
        imagePullPolicy: IfNotPresent
        args:
          - "--config=/conf/otelcol.instrumentation.conf.yaml"
        resources:
          limits:
            cpu: 2000m
            memory: 4Gi
          requests:
            cpu: 500m
            memory: 768Mi
        ports:
        - name: pprof
          containerPort: 1777
          protocol: TCP
        - containerPort: 5778  # Default endpoint for Jaeger Sampling.
        - containerPort: 6831  # Default endpoint for Jaeger Thrift Compact receiver.
          protocol: UDP
        - containerPort: 6832  # Default endpoint for Jaeger Thrift Binary receiver.
          protocol: UDP
        - containerPort: 8888  # Default endpoint for querying metrics.
        - containerPort: 9411  # Default endpoint for Zipkin receiver.
        - containerPort: 14250 # Default endpoint for Jaeger gRPC receiver.
        - containerPort: 14267 # Default endpoint for Jaeger TChannel receiver.
        - containerPort: 14268 # Default endpoint for Jaeger HTTP receiver.
        - containerPort: 55678 # Default endpoint for Opencensus receiver.
        - containerPort: 4317  # Default endpoint for OTLP receiver.
        - containerPort: 4318  # Default endpoint for OTLP HTTP receiver.
        - containerPort: 55681 # Default endpoint for OTLP HTTP receiver. (deprecated)
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 15
          periodSeconds: 15
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
        startupProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 60
          periodSeconds: 3
        volumeMounts:
        - name: otelcolinstrumentation-config-vol
          mountPath: /conf
        env:
        - name: SUMO_ENDPOINT_DEFAULT_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics
---
# Source: sumologic/templates/logs/otelcol/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sumologic-sumologic-otelcol-logs
  labels:
    app: sumologic-sumologic-otelcol-logs
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: sumologic-sumologic-otelcol-logs
  serviceName: sumologic-sumologic-otelcol-logs-headless
  podManagementPolicy: "Parallel"
  replicas: 3
  template:
    metadata:
      annotations:
        checksum/config: 0b04a13e065ee2c2e65575f4636e1b484587dd77822b3033820d52c2604872be
      labels:
        app: sumologic-sumologic-otelcol-logs
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      serviceAccountName: sumologic-sumologic
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - sumologic-sumologic-otelcol-logs
                  - sumologic-sumologic-otelcol-metrics
                - key: app
                  operator: In
                  values:
                  - prometheus-operator-prometheus
              topologyKey: "kubernetes.io/hostname"
      volumes:
      - name: config-volume
        configMap:
          name: sumologic-sumologic-otelcol-logs
      securityContext:
        fsGroup: 999
      containers:
      - name: otelcol
        image: public.ecr.aws/sumologic/sumologic-otel-collector:0.69.0-sumo-0
        imagePullPolicy: IfNotPresent
        args:
          - --config=/etc/otel/config.yaml
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 768Mi
        ports:
        - name: fluent-bit
          containerPort: 24321
          protocol: TCP
        - name: metrics
          containerPort: 8888
          protocol: TCP
        - name: otlphttp
          containerPort: 4318
          protocol: TCP
        - name: pprof
          containerPort: 1777
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 15
          periodSeconds: 15
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
        startupProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 60
          periodSeconds: 3
        volumeMounts:
        - name: config-volume
          mountPath: /etc/otel/config.yaml
          subPath: config.yaml
        - name: file-storage
          mountPath: /var/lib/storage/otc
        env:
        - name: SUMO_ENDPOINT_DEFAULT_LOGS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-logs
        - name: NO_PROXY
          value: kubernetes.default.svc
  volumeClaimTemplates:
  - metadata:
      name: file-storage
    spec:
      accessModes: [ReadWriteOnce]
      storageClassName:
      resources:
        requests:
          storage: 10Gi
---
# Source: sumologic/templates/metrics/otelcol/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sumologic-sumologic-otelcol-metrics
  labels:
    app: sumologic-sumologic-otelcol-metrics
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: sumologic-sumologic-otelcol-metrics
  serviceName: sumologic-sumologic-otelcol-metrics-headless
  podManagementPolicy: "Parallel"
  replicas: 3
  template:
    metadata:
      annotations:
        checksum/config: 8b6c6d6d1867a4d1c085dbfc3a599320ef6e55cf537953579cebedaf35ca4cf4
      labels:
        app: sumologic-sumologic-otelcol-metrics
        chart: "sumologic-3.1.1"
        release: "sumologic"
        heritage: "Helm"
    spec:
      serviceAccountName: sumologic-sumologic
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - sumologic-sumologic-otelcol-logs
                  - sumologic-sumologic-otelcol-metrics
                - key: app
                  operator: In
                  values:
                  - prometheus-operator-prometheus
              topologyKey: "kubernetes.io/hostname"
      volumes:
      - name: config-volume
        configMap:
          name: sumologic-sumologic-otelcol-metrics
      securityContext:
        fsGroup: 999
      containers:
      - name: otelcol
        image: public.ecr.aws/sumologic/sumologic-otel-collector:0.69.0-sumo-0
        imagePullPolicy: IfNotPresent
        args:
          - --config=/etc/otel/config.yaml
        resources:
          limits:
            cpu: 1000m
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 768Mi
        ports:
        - name: prom-write
          containerPort: 9888
          protocol: TCP
        - name: metrics
          containerPort: 8888
          protocol: TCP
        - name: pprof
          containerPort: 1777
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 15
          periodSeconds: 15
          timeoutSeconds: 10
        readinessProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 3
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
        startupProbe:
          httpGet:
            path: /
            port: 13133 # Health Check extension default port.
          failureThreshold: 60
          periodSeconds: 3
        volumeMounts:
        - name: config-volume
          mountPath: /etc/otel/config.yaml
          subPath: config.yaml
        - name: file-storage
          mountPath: /var/lib/storage/otc
        env:
        - name: SUMO_ENDPOINT_APISERVER_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-apiserver
        - name: SUMO_ENDPOINT_CONTROL_PLANE_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-control_plane_metrics_source
        - name: SUMO_ENDPOINT_CONTROLLER_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kube-controller-manager
        - name: SUMO_ENDPOINT_DEFAULT_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics
        - name: SUMO_ENDPOINT_KUBELET_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kubelet
        - name: SUMO_ENDPOINT_NODE_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-node-exporter
        - name: SUMO_ENDPOINT_SCHEDULER_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kube-scheduler
        - name: SUMO_ENDPOINT_STATE_METRICS_SOURCE
          valueFrom:
            secretKeyRef:
              name: sumologic
              key: endpoint-metrics-kube-state
        - name: NO_PROXY
          value: kubernetes.default.svc
  volumeClaimTemplates:
  - metadata:
      name: file-storage
    spec:
      accessModes: [ReadWriteOnce]
      storageClassName:
      resources:
        requests:
          storage: 10Gi
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/additionalPrometheusRules.yaml
apiVersion: v1
kind: List
metadata:
  name: sumologic-kube-prometheus-additional-prometheus-rules
  namespace: monitoring
items:
  - apiVersion: monitoring.coreos.com/v1
    kind: PrometheusRule
    metadata:
      name: kube-prometheus-stack-pre-1.14-node-rules
      namespace: monitoring
      labels:
        app: kube-prometheus-stack

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "40.5.0"
        app.kubernetes.io/part-of: kube-prometheus-stack
        chart: kube-prometheus-stack-40.5.0
        release: "sumologic"
        heritage: "Helm"
    spec:
      groups:
        - name: node-pre-1.14.rules
          rules:
          - expr: sum(min(kube_pod_info) by (node))
            record: ':kube_pod_info_node_count:'
          - expr: 1 - avg(rate(node_cpu_seconds_total{job="node-exporter",mode="idle"}[1m]))
            record: :node_cpu_utilisation:avg1m
          - expr: |-
              1 - avg by (node) (
                rate(node_cpu_seconds_total{job="node-exporter",mode="idle"}[1m])
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:)
            record: node:node_cpu_utilisation:avg1m
          - expr: |-
              1 -
              sum(
                node_memory_MemFree_bytes{job="node-exporter"} +
                node_memory_Cached_bytes{job="node-exporter"} +
                node_memory_Buffers_bytes{job="node-exporter"}
              )
              /
              sum(node_memory_MemTotal_bytes{job="node-exporter"})
            record: ':node_memory_utilisation:'
          - expr: |-
              sum by (node) (
                (
                  node_memory_MemFree_bytes{job="node-exporter"} +
                  node_memory_Cached_bytes{job="node-exporter"} +
                  node_memory_Buffers_bytes{job="node-exporter"}
                )
                * on (namespace, pod) group_left(node)
                  node_namespace_pod:kube_pod_info:
              )
            record: node:node_memory_bytes_available:sum
          - expr: |-
              (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
              /
              node:node_memory_bytes_total:sum
            record: node:node_memory_utilisation:ratio
          - expr: |-
              1 -
              sum by (node) (
                (
                  node_memory_MemFree_bytes{job="node-exporter"} +
                  node_memory_Cached_bytes{job="node-exporter"} +
                  node_memory_Buffers_bytes{job="node-exporter"}
                )
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
              /
              sum by (node) (
                node_memory_MemTotal_bytes{job="node-exporter"}
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
            record: 'node:node_memory_utilisation:'
          - expr: 1 - (node:node_memory_bytes_available:sum / node:node_memory_bytes_total:sum)
            record: 'node:node_memory_utilisation_2:'
          - expr: |-
              max by (instance, namespace, pod, device) ((node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"}
              - node_filesystem_avail_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
              / node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"})
            record: 'node:node_filesystem_usage:'
          - expr: |-
              sum by (node) (
                node_memory_MemTotal_bytes{job="node-exporter"}
                * on (namespace, pod) group_left(node)
                  node_namespace_pod:kube_pod_info:
              )
            record: node:node_memory_bytes_total:sum
          - expr: |-
              sum(irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[1m])) +
              sum(irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[1m]))
            record: :node_net_utilisation:sum_irate
          - expr: |-
              sum by (node) (
                (irate(node_network_receive_bytes_total{job="node-exporter",device!~"veth.+"}[1m]) +
                irate(node_network_transmit_bytes_total{job="node-exporter",device!~"veth.+"}[1m]))
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
            record: node:node_net_utilisation:sum_irate
          - expr: |-
              sum(irate(node_network_receive_drop_total{job="node-exporter",device!~"veth.+"}[1m])) +
              sum(irate(node_network_transmit_drop_total{job="node-exporter",device!~"veth.+"}[1m]))
            record: :node_net_saturation:sum_irate
          - expr: |-
              sum by (node) (
                (irate(node_network_receive_drop_total{job="node-exporter",device!~"veth.+"}[1m]) +
                irate(node_network_transmit_drop_total{job="node-exporter",device!~"veth.+"}[1m]))
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
            record: node:node_net_saturation:sum_irate
          - expr: |-
              sum(node_load1{job="node-exporter"})
              /
              sum(node:node_num_cpu:sum)
            record: ':node_cpu_saturation_load1:'
          - expr: avg(irate(node_disk_io_time_weighted_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m]))
            record: :node_disk_saturation:avg_irate
          - expr: |-
              avg by (node) (
                irate(node_disk_io_time_weighted_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
            record: node:node_disk_saturation:avg_irate
          - expr: avg(irate(node_disk_io_time_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m]))
            record: :node_disk_utilisation:avg_irate
          - expr: |-
              avg by (node) (
                irate(node_disk_io_time_seconds_total{job="node-exporter",device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+"}[1m])
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
            record: node:node_disk_utilisation:avg_irate
          - expr: |-
              1e3 * sum(
                (rate(node_vmstat_pgpgin{job="node-exporter"}[1m])
              + rate(node_vmstat_pgpgout{job="node-exporter"}[1m]))
              )
            record: :node_memory_swap_io_bytes:sum_rate
          - expr: |-
              1e3 * sum by (node) (
                (rate(node_vmstat_pgpgin{job="node-exporter"}[1m])
              + rate(node_vmstat_pgpgout{job="node-exporter"}[1m]))
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
            record: node:node_memory_swap_io_bytes:sum_rate
          - expr: |-
              node:node_cpu_utilisation:avg1m
                *
              node:node_num_cpu:sum
                /
              scalar(sum(node:node_num_cpu:sum))
            record: node:cluster_cpu_utilisation:ratio
          - expr: |-
              (node:node_memory_bytes_total:sum - node:node_memory_bytes_available:sum)
              /
              scalar(sum(node:node_memory_bytes_total:sum))
            record: node:cluster_memory_utilisation:ratio
          - expr: |-
              sum by (node) (
                node_load1{job="node-exporter"}
              * on (namespace, pod) group_left(node)
                node_namespace_pod:kube_pod_info:
              )
              /
              node:node_num_cpu:sum
            record: 'node:node_cpu_saturation_load1:'
          - expr: |-
              max by (instance, namespace, pod, device) (
                node_filesystem_avail_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"}
                /
                node_filesystem_size_bytes{fstype=~"ext[234]|btrfs|xfs|zfs"}
                )
            record: 'node:node_filesystem_avail:'
          - expr: |-
              max(
                max(
                  kube_pod_info{job="kube-state-metrics", host_ip!=""}
                ) by (node, host_ip)
                * on (host_ip) group_right (node)
                label_replace(
                  (
                    max(node_filesystem_files{job="node-exporter", mountpoint="/"})
                    by (instance)
                  ), "host_ip", "$1", "instance", "(.*):.*"
                )
              ) by (node)
            record: 'node:node_inodes_total:'
          - expr: |-
              max(
                max(
                  kube_pod_info{job="kube-state-metrics", host_ip!=""}
                ) by (node, host_ip)
                * on (host_ip) group_right (node)
                label_replace(
                  (
                    max(node_filesystem_files_free{job="node-exporter", mountpoint="/"})
                    by (instance)
                  ), "host_ip", "$1", "instance", "(.*):.*"
                )
              ) by (node)
            record: 'node:node_inodes_free:'
---
# Source: sumologic/templates/metrics/prometheus/servicemonitors.yaml
apiVersion: v1
kind: List
items:
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-fluentd-logs
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: fluentd-logs
    spec:
      endpoints:
        - port: metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/app: fluentd-logs
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-otelcol-logs
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: otelcol-logs
    spec:
      endpoints:
        - port: otelcol-metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/app: fluentd-logs
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-fluentd-metrics
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: fluentd-metrics
    spec:
      endpoints:
        - port: metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/app: fluentd-metrics
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-otelcol-metrics
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: otelcol-metrics
    spec:
      endpoints:
        - port: otelcol-metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/app: fluentd-metrics
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-fluentd-events
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: fluentd-events
    spec:
      endpoints:
        - port: metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/app: fluentd-events
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-fluent-bit
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: collection-fluent-bit
    spec:
      endpoints:
        - path: /api/v1/metrics/prometheus
          port: http
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          app.kubernetes.io/name: fluent-bit
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-otelcol-logs-collector
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: otelcol-logs-collector
    spec:
      endpoints:
        - port: metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/app: otelcol-logs-collector
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-otelcol-events
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: otelcol-events
    spec:
      endpoints:
        - port: otelcol-metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/app: otelcol-events
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-otelcol-traces
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
        sumologic.com/app: otelcol
    spec:
      endpoints:
        - port: metrics
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          sumologic.com/component: traces
          sumologic.com/scrape: "true"
  - apiVersion: monitoring.coreos.com/v1
    kind: ServiceMonitor
    metadata:
      name: collection-sumologic-prometheus
      namespace: monitoring
      labels:
        app: sumologic-prometheus

        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: sumologic
        app.kubernetes.io/version: "3.1.1"
        app.kubernetes.io/part-of: sumologic
        chart: sumologic-3.1.1
        release: "sumologic"
        heritage: "Helm"
    spec:
      endpoints:
        - path: /metrics
          port: web
      namespaceSelector:
        matchNames:
        - $(NAMESPACE)
      selector:
        matchLabels:
          operated-prometheus: "true"
---
# Source: sumologic/templates/priorityclass.yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: sumologic-sumologic-priorityclass
  labels:
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
value: 1000000
globalDefault: false
description: "This PriorityClass will be used for OTel Distro agents running as Daemonsets"
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/prometheus.yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: sumologic-kube-prometheus-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  alerting:
    alertmanagers:
      []
  image: "quay.io/prometheus/prometheus:v2.39.0"
  version: v2.39.0
  externalUrl: http://sumologic-kube-prometheus-prometheus.monitoring:9090
  paused: false
  replicas: 1
  shards: 1
  logLevel:  info
  logFormat:  logfmt
  listenLocal: false
  enableAdminAPI: false
  scrapeInterval: 30s
  resources:
    limits:
      cpu: 2000m
      memory: 8Gi
    requests:
      cpu: 500m
      memory: 1Gi
  retention: "1d"
  walCompression: true
  routePrefix: "/"
  serviceAccountName: sumologic-kube-prometheus-prometheus
  serviceMonitorSelector:
    matchLabels:
      release: "sumologic"

  serviceMonitorNamespaceSelector: {}
  podMonitorSelector:
    matchLabels:
      release: "sumologic"

  podMonitorNamespaceSelector: {}
  probeSelector:
    matchLabels:
      release: "sumologic"

  probeNamespaceSelector: {}
  remoteWrite:
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.state
      writeRelabelConfigs:
      - action: keep
        regex: kube-state-metrics;(?:kube_statefulset_status_observed_generation|kube_statefulset_status_replicas|kube_statefulset_replicas|kube_statefulset_metadata_generation|kube_daemonset_status_current_number_scheduled|kube_daemonset_status_desired_number_scheduled|kube_daemonset_status_number_misscheduled|kube_daemonset_status_number_unavailable|kube_deployment_spec_replicas|kube_deployment_status_replicas_available|kube_deployment_status_replicas_unavailable|kube_node_info|kube_node_status_allocatable|kube_node_status_capacity|kube_node_status_condition|kube_hpa_spec_max_replicas|kube_hpa_spec_min_replicas|kube_hpa_status_(condition|(current|desired)_replicas)|kube_service_info|kube_service_spec_external_ip|kube_service_spec_type|kube_service_status_load_balancer_ingress)
        sourceLabels:
        - job
        - __name__
      - action: labelmap
        regex: (pod|service)
        replacement: service_discovery_${1}
      - action: labeldrop
        regex: (pod|service|container)
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.state
      writeRelabelConfigs:
      - action: keep
        regex: kube-state-metrics;(?:kube_pod_status_phase)
        sourceLabels:
        - job
        - __name__
      - action: labeldrop
        regex: container
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.state
      writeRelabelConfigs:
      - action: keep
        regex: kube-state-metrics;(?:kube_pod_container_info|kube_pod_container_resource_requests|kube_pod_container_resource_limits|kube_pod_container_status_ready|kube_pod_container_status_terminated_reason|kube_pod_container_status_waiting_reason|kube_pod_container_status_restarts_total)
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.controller-manager
      writeRelabelConfigs:
      - action: keep
        regex: kubelet;cloudprovider_.*_api_request_duration_seconds.*
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.scheduler
      writeRelabelConfigs:
      - action: keep
        regex: kube-scheduler;scheduler_(?:e2e_scheduling|binding|framework_extension_point|scheduling_algorithm)_duration_seconds.*
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.apiserver
      writeRelabelConfigs:
      - action: keep
        regex: apiserver;(?:apiserver_request_(?:count|total)|apiserver_request_(?:duration_seconds|latencies)_(?:count|sum)|apiserver_request_latencies_summary(?:|_count|_sum)|etcd_request_cache_(?:add|get)_(?:duration_seconds|latencies_summary)_(?:count|sum)|etcd_helper_cache_(?:hit|miss)_(?:count|total))
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.kubelet
      writeRelabelConfigs:
      - action: keep
        regex: kubelet;(?:kubelet_docker_operations_errors(?:|_total)|kubelet_(?:docker|runtime)_operations_duration_seconds_(?:count|sum)|kubelet_running_(?:container|pod)(?:_count|s)|kubelet_(:?docker|runtime)_operations_latency_microseconds(?:|_count|_sum))
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.container
      writeRelabelConfigs:
      - action: labelmap
        regex: container_name
        replacement: container
      - action: drop
        regex: POD
        sourceLabels:
        - container
      - action: keep
        regex: kubelet;.+;(?:container_cpu_usage_seconds_total|container_memory_working_set_bytes|container_fs_usage_bytes|container_fs_limit_bytes|container_cpu_cfs_throttled_seconds_total)
        sourceLabels:
        - job
        - container
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.container
      writeRelabelConfigs:
      - action: keep
        regex: kubelet;(?:container_network_receive_bytes_total|container_network_transmit_bytes_total)
        sourceLabels:
        - job
        - __name__
      - action: labeldrop
        regex: container
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.node
      writeRelabelConfigs:
      - action: keep
        regex: node-exporter;(?:node_load1|node_load5|node_load15|node_cpu_seconds_total)
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.operator.rule
      writeRelabelConfigs:
      - action: keep
        regex: 'cluster_quantile:apiserver_request_duration_seconds:histogram_quantile|instance:node_filesystem_usage:sum|instance:node_network_receive_bytes:rate:sum|cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile|cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile|cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile|cluster_quantile:scheduler_framework_extension_point_duration_seconds:histogram_quantile|node_namespace_pod:kube_pod_info:|:kube_pod_info_node_count:|node:node_num_cpu:sum|:node_cpu_utilisation:avg1m|node:node_cpu_utilisation:avg1m|node:cluster_cpu_utilisation:ratio|:node_cpu_saturation_load1:|node:node_cpu_saturation_load1:|:node_memory_utilisation:|node:node_memory_bytes_total:sum|node:node_memory_utilisation:ratio|node:cluster_memory_utilisation:ratio|:node_memory_swap_io_bytes:sum_rate|node:node_memory_utilisation:|node:node_memory_utilisation_2:|node:node_memory_swap_io_bytes:sum_rate|:node_disk_utilisation:avg_irate|node:node_disk_utilisation:avg_irate|:node_disk_saturation:avg_irate|node:node_disk_saturation:avg_irate|node:node_filesystem_usage:|node:node_filesystem_avail:|:node_net_utilisation:sum_irate|node:node_net_utilisation:sum_irate|:node_net_saturation:sum_irate|node:node_net_saturation:sum_irate|node:node_inodes_total:|node:node_inodes_free:'
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics
      writeRelabelConfigs:
      - action: keep
        regex: (?:up|prometheus_remote_storage_.*|fluentd_.*|fluentbit.*|otelcol.*)
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.control-plane.coredns
      writeRelabelConfigs:
      - action: keep
        regex: coredns;(?:coredns_cache_(size|entries|(hits|misses)_total)|coredns_dns_request_duration_seconds_(count|sum)|coredns_(dns_request|dns_response_rcode|forward_request)_count_total|coredns_(forward_requests|dns_requests|dns_responses)_total|process_(cpu_seconds_total|open_fds|resident_memory_bytes))
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.control-plane.kube-etcd
      writeRelabelConfigs:
      - action: keep
        regex: kube-etcd;(?:etcd_debugging_(mvcc_db_total_size_in_bytes|store_(expires_total|watchers))|etcd_disk_(backend_commit|wal_fsync)_duration_seconds_bucket|etcd_grpc_proxy_cache_(hits|misses)_total|etcd_network_client_grpc_(received|sent)_bytes_total|etcd_server_(has_leader|leader_changes_seen_total)|etcd_server_proposals_(pending|(applied|committed|failed)_total)|process_(cpu_seconds_total|open_fds|resident_memory_bytes))
        sourceLabels:
        - job
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.nginx-ingress
      writeRelabelConfigs:
      - action: keep
        regex: (?:nginx_ingress_controller_ingress_resources_total|nginx_ingress_controller_nginx_(last_reload_(milliseconds|status)|reload(s|_errors)_total)|nginx_ingress_controller_virtualserver(|route)_resources_total|nginx_ingress_nginx_connections_(accepted|active|handled|reading|waiting|writing)|nginx_ingress_nginx_http_requests_total|nginx_ingress_nginxplus_(connections_(accepted|active|dropped|idle)|http_requests_(current|total)|resolver_(addr|formerr|name|noerror|notimp|nxdomain|refused|servfail|srv|timedout|unknown)|ssl_(handshakes_failed|session_reuses)|stream_server_zone_(connections|received|sent)|stream_upstream_server_(active|connect_time|fails|health_checks_fails|health_checks_unhealthy|received|response_time|sent|unavail|state)|(location|server)_zone_(discarded|received|requests|responses|sent|processing)|upstream_server_(fails|header_time|health_checks_fails|health_checks_unhealthy|received|sent|unavail|response_time|responses|requests)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.nginx
      writeRelabelConfigs:
      - action: keep
        regex: (?:nginx_(accepts|active|handled|reading|requests|waiting|writing)|nginx_plus_api_connections_(accepted|active|dropped|idle)|nginx_plus_api_http_caches_(cold|hit_bytes|max_size|miss_bytes|size|updating_bytes)|nginx_plus_api_http_location_zones_(discarded|received|requests|sent)|nginx_plus_api_http_location_zones_responses_(1xx|2xx|3xx|4xx|5xx|total)|nginx_plus_api_http_requests_(current|total)|nginx_plus_api_http_server_zones_(discarded|processing|received|requests|sent)|nginx_plus_api_http_server_zones_responses_(1xx|2xx|3xx|4xx|5xx|total)|nginx_plus_api_http_upstream_peers_(backup|downtime|fails|healthchecks_fails|healthchecks_unhealthy|received|requests|sent|unavail|response_time)|nginx_plus_api_http_upstream_peers_responses_(1xx|2xx|3xx|4xx|5xx|total)|nginx_plus_api_resolver_zones_(addr|formerr|name|noerror|notimp|nxdomain|refused|servfail|srv|timedout)|nginx_plus_api_ssl_(handshakes_failed|session_reuses)|nginx_plus_api_stream_server_zones_(connections|received|sent)|nginx_plus_api_stream_upstream_peers_(active|backup|connect_time|downtime|fails|healthchecks_fails|healthchecks_last_passed|healthchecks_unhealthy|received|response_time|sent|unavail))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.redis
      writeRelabelConfigs:
      - action: keep
        regex: (?:redis_((blocked_|)clients|cluster_enabled|cmdstat_calls|connected_slaves|(evicted|expired|tracking_total)_keys|instantaneous_ops_per_sec|keyspace_(hitrate|hits|misses)|(master|slave)_repl_offset|maxmemory|mem_fragmentation_(bytes|ratio)|rdb_changes_since_last_save|rejected_connections|total_commands_processed|total_net_(input|output)_bytes|uptime|used_(cpu_(sys|user)|memory(_overhead|_rss|_startup|))))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.jmx
      writeRelabelConfigs:
      - action: keep
        regex: (?:java_lang_(ClassLoading_(TotalL|Unl|L)oadedClassCount|Compilation_TotalCompilationTime|GarbageCollector_(Collection(Count|Time)|LastGcInfo_(GcThreadCount|duration|(memoryU|u)sage(After|Before)Gc_.*_used))|MemoryPool_(CollectionUsage(ThresholdSupported|_committed|_max|_used)|(Peak|)Usage_(committed|max|used)|UsageThresholdSupported)|Memory_((Non|)HeapMemoryUsage_(committed|max|used)|ObjectPendingFinalizationCount)|OperatingSystem_(AvailableProcessors|(CommittedVirtual|(Free|Total)(Physical|))MemorySize|(Free|Total)SwapSpaceSize|(Max|Open)FileDescriptorCount|ProcessCpu(Load|Time)|System(CpuLoad|LoadAverage))|Runtime_(BootClassPathSupported|Pid|Uptime|StartTime)|Threading_(CurrentThread(AllocatedBytes|(Cpu|User)Time)|(Daemon|Peak|TotalStarted|)ThreadCount|(ObjectMonitor|Synchronizer)UsageSupported|Thread(AllocatedMemory.*|ContentionMonitoring.*|CpuTime.*))))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.kafka
      writeRelabelConfigs:
      - action: keep
        regex: (?:kafka_(broker_.*|controller_.*|java_lang_.*|partition_.*|purgatory_.*|network_.*|replica_.*|request_.*|topic_.*|topics_.*|zookeeper_.*))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.mysql
      writeRelabelConfigs:
      - action: keep
        regex: (?:mysql_((uptime|connection_errors_.*|queries|slow_queries|questions|table_open_cache_.*|table_locks_.*|commands_.*|select_.*|sort_.*|mysqlx_connections_.*|mysqlx_worker_.*|connections|aborted_.*|locked_connects|bytes_.*|qcache_.*|threads_.*|opened_.*|created_tmp_.*)|innodb_(buffer_pool_.*|data_.*|rows_.*|row_lock_.*|log_waits)|perf_schema_(events_statements_.*|table_io_waits_.*|index_io_waits_.*|read.*|write.*)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.postgresql
      writeRelabelConfigs:
      - action: keep
        regex: (?:postgresql_(blks_(hit|read)|buffers_(backend|checkpoint|clean)|checkpoints_(req|timed)|db_size|deadlocks|flush_lag|heap_blks_(hit|read)|idx_blks_(hit|read)|idx_scan|idx_tup_(fetch|read)|index_size|n_dead_tup|n_live_tup|n_tup_(upd|ins|del|hot_upd)|num_locks|numbackends|replay_lag|replication_(delay|lag)|seq_scan|seq_tup_read|stat_ssl_compression_count|table_size|tidx_blks_(hit|read)|toast_blks_(hit|read)|tup_(deleted|fetched|inserted|returned|updated)|write_lag|xact_(commit|rollback)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.apache
      writeRelabelConfigs:
      - action: keep
        regex: (?:apache_((BusyWorkers|BytesPerReq|BytesPerSec|CPUChildrenSystem|CPUChildrenUser|CPULoad|CPUSystem|CPUUser|DurationPerReq|IdleWorkers|Load1|Load15|Load5|ParentServerConfigGeneration|ParentServerMPMGeneration|ReqPerSec|ServerUptimeSeconds|TotalAccesses|TotalDuration|TotalkBytes|Uptime)|(scboard_(closing|dnslookup|finishing|idle_cleanup|keepalive|logging|open|reading|sending|starting|waiting))))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.sqlserver
      writeRelabelConfigs:
      - action: keep
        regex: (?:sqlserver_(cpu_sqlserver_process_cpu|database_io_(read_(bytes|latency_ms)|write_(bytes|latency_ms))|memory_clerks_size_kb|performance_value|server_properties_server_memory|volume_space_(total_space_bytes|used_space_bytes)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.haproxy
      writeRelabelConfigs:
      - action: keep
        regex: (?:haproxy_(active_servers|backup_servers|bin|bout|chkfail|ctime|dreq|dresp|econ|ereq|eresp|http_response_(1xx|2xx|3xx|4xx|5xx|other)|qcur|qmax|qtime|rate|rtime|scur|slim|smax|ttime|weight|wredis|wretr))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.cassandra
      writeRelabelConfigs:
      - action: keep
        regex: (?:cassandra_(CacheMetrics_ChunkCache_OneMinuteRate|ClientMetrics_(connectedNativeClients_Value|RequestDiscarded_OneMinuteRate)|CommitLogMetrics_(CompletedTasks_Value|PendingTasks_Value)|DroppedMessageMetrics_Dropped_OneMinuteRate|java_(GarbageCollector_(ConcurrentMarkSweep|ParNew)_(CollectionCount|CollectionTime|LastGcInfo_duration|LastGcInfo_GcThreadCount|LastGcInfo_memoryUsageAfterGc_.*_used|LastGcInfo_memoryUsageBeforeGc_.*_used)|Memory_HeapMemoryUsage_used|OperatingSystem_(AvailableProcessors|FreePhysicalMemorySize|SystemCpuLoad|TotalPhysicalMemorySize|TotalSwapSpaceSize))|Net_FailureDetector_(DownEndpointCount|UpEndpointCount)|TableMetrics_(AllMemtablesHeapSize_Value|AllMemtablesLiveDataSize_Value|CompactionBytesWritten_Count|EstimatedPartitionCount_Value|KeyCacheHitRate_Value|LiveSSTableCount_Value|MemtableColumnsCount_Value|MemtableLiveDataSize_Value|MemtableOffHeapSize_Value|MemtableOnHeapSize_Value|MemtableSwitchCount_Count|PendingCompactions_Value|PendingFlushes_Count|PercentRepaired_Value|RangeLatency_Count|ReadLatency_50thPercentile|ReadLatency_Max|ReadLatency_OneMinuteRate|RowCacheHit_Count|RowCacheMiss_Count|SSTablesPerReadHistogram_50thPercentile|SSTablesPerReadHistogram_99thPercentile|SSTablesPerReadHistogram_Count|SSTablesPerReadHistogram_Max|TombstoneScannedHistogram_50thPercentile|TombstoneScannedHistogram_99thPercentile|TombstoneScannedHistogram_Max|TotalDiskSpaceUsed_Count|WaitingOnFreeMemtableSpace_Max|WriteLatency_50thPercentile|WriteLatency_99thPercentile|WriteLatency_Max|WriteLatency_OneMinuteRate)|ThreadPoolMetrics_(internal_(Count|Value)|request_(Count|Value)|transport_(Count|Value))))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.mongodb
      writeRelabelConfigs:
      - action: keep
        regex: (?:mongodb_(active_(reads|writes)|commands_per_sec|connections_current|db_stats_storage_size|deletes_per_sec|document_.*|flushes_per_sec|getmores_per_sec|inserts_per_sec|net_.*_bytes_count|open_connections|page_faults|percent_cache_(dirty|used)|queries_per_sec|queued_(reads|writes)|repl_((commands|deletes|getmores|inserts|oplog|queries|updates)_per_sec|queries|oplog_window_sec)|resident_megabytes|updates_per_sec|uptime_ns|vsize_megabytes|wtcache_bytes_read_into))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.rabbitmq
      writeRelabelConfigs:
      - action: keep
        regex: (?:rabbitmq_(exchange_messages_publish_(in_rate|in|out_rate|out)|node_(disk_free_limit|disk_free|mem_(limit|used)|uptime|fd_used|mnesia_(disk_tx_count|ram_tx_count)|gc_num_rate)|overview_(clustering_listerners|connections|exchanges|consumers|queues|messages_(delivered|published|unacked))|queue_(consumers|memory|slave_nodes|messages_(publish_rate|deliver_rate|memory|max_time|unack))))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.tomcat
      writeRelabelConfigs:
      - action: keep
        regex: (?:tomcat_(connector_(bytes_(received|sent)|current_(thread_(busy|count)|threads_busy)|error_count|max_threads|max_time|processing_time|request_count)|jmx_(jvm_memory_(HeapMemoryUsage_(max|used)|NonHeapMemoryUsage_(max|used))|OperatingSystem_(FreePhysicalMemorySize|FreeSwapSpaceSize|SystemCpuLoad|TotalPhysicalMemorySize|TotalSwapSpaceSize)|Servlet_processingTime)|jvm_memory_(free|max|total)|jvm_memorypool_(bytes_(received|sent)|current_thread_count|current_threads_busy|error_count|max_threads|max_time|max|processing_time|request_count|used)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.varnish
      writeRelabelConfigs:
      - action: keep
        regex: (?:varnish_(backend_(busy|conn|fail|recycle|req|retry|reuse|unhealthy)|bans_(completed|deleted|dups|lurker_(contention|obj_killed|tests_tested|tested|)|obj_killed|obj|persisted_(bytes|fragmentation))|bans|boot_.*_.*_(bodybytes|hdrbytes)|cache_(hit_grace|hitpass|miss|hit)|client_(req_400|req_417|req|resp_500)|n_(backend|expired|lru_nuked|vcl_avail)|pools|s0_g_(bytes|space)|s_(fetch|pipe_(in|out)|req_(bodybytes|hdrbytes)|resp_(bodybytes|hdrbytes)|sess)|sess_(closed_err|closed|conn|drop|dropped|fail|queued)|thread_queue_len|threads_(created|destroyed|failed|limited)|threads|uptime|vmods))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.memcached
      writeRelabelConfigs:
      - action: keep
        regex: (?:memcached_(accepting_conns|auth_(cmds|errors)|bytes_(read|written)|bytes|cas_*|cmd_.*|conn_yields|connection_structures|curr_(connections|items)|decr_.*|delete_.*|evictions|get_(hits|misses)|hash_(bytes|is_expanding)|incr_.*|limit_maxbytes|listen_disabled_num|reclaimed|threads|total_(connections|items)|uptime))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.elasticsearch
      writeRelabelConfigs:
      - action: keep
        regex: (?:elasticsearch_(cluster_health_(active_(primary_shards|shards)|delayed_unassigned_shards|indices_status_code|initializing_shards|number_of_(data_nodes|nodes|pending_tasks)|relocating_shards|unassigned_shards)|clusterstats_(indices_fielddata_evictions|nodes_jvm_mem_heap_used_in_bytes)|fs_total_(free_in_bytes|total_in_bytes)|indices_(flush_(total|total_time_in_millis)|get_(exists_time_in_millis|exists_total|missing_time_in_millis|missing_total|time_in_millis|total)|indexing_delete_time_in_millis|indexing_delete_total|indexing_index_time_in_millis|indexing_index_total|merges_total_time_in_millis|search_query_time_in_millis|search_query_total|segments_fixed_bit_set_memory_in_bytes|segments_terms_memory_in_bytes|stats_primaries_(docs_count|indexing_index_time_in_millis|query_cache_cache_size|query_cache_evictions|segments_doc_values_memory_in_bytes|segments_index_writer_memory_in_bytes|segments_memory_in_bytes)|stats_total___(fielddata_memory_size_in_bytes|indexing_index_total|merges_total)|stats_total_(docs_count|fielddata_memory_size_in_bytes|flush_total_time_in_millis|indexing_delete_total|indexing_index_time_in_millis|indexing_index_total|merges_total_docs|merges_total_size_in_bytes|merges_total_time_in_millis|query_cache_evictions|refresh_total|refresh_total_time_in_millis|search_fetch_time_in_millis|search_fetch_total|search_query_time_in_millis|search_query_total|segments_fixed_bit_set_memory_in_bytes|segments_index_writer_memory_in_bytes|segments_memory_in_bytes|segments_terms_memory_in_bytes|store_size_in_bytes|translog_operations|translog_size_in_bytes))|jvm_(gc_collectors_.*_collection_time_in_millis|mem_heap_committed_in_bytes|mem_heap_used_in_bytes|mem_heap_used_percent)|os_cpu_(load_average_5m|percent)|process_open_file_descriptors|thread_pool_(analyze_completed|analyze_threads|get_rejected|search_queue)|transport_(rx_size_in_bytes|tx_size_in_bytes)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.activemq
      writeRelabelConfigs:
      - action: keep
        regex: (?:activemq_(topic_.*|queue_.*|.*_QueueSize|broker_(AverageMessageSize|CurrentConnectionsCount|MemoryLimit|StoreLimit|TempLimit|TotalConnectionsCount|TotalConsumerCount|TotalDequeueCount|TotalEnqueueCount|TotalMessageCount|TotalProducerCount|UptimeMillis)|jvm_memory_(HeapMemoryUsage_max|HeapMemoryUsage_used|NonHeapMemoryUsage_used)|jvm_runtime_Uptime|OperatingSystem_(FreePhysicalMemorySize|SystemCpuLoad|TotalPhysicalMemorySize)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.couchbase
      writeRelabelConfigs:
      - action: keep
        regex: (?:couchbase_(node_.*|bucket_(ep_.*|vb_.*|delete_.*|cmd.*|bytes_.*|item_count|curr_connections|ops_per_sec|disk_write_queue|mem_.*|cas_hits|ops|curr_items|cpu_utilization_rate|swap_used|disk_used|rest_requests|hibernated_waked|xdc_ops)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.squidproxy
      writeRelabelConfigs:
      - action: keep
        regex: (?:squid_(uptime|cache(Ip(Entries|Requests|Hits)|Fqdn(Entries|Requests|Misses|NegativeHits)|Dns(Requests|Replies|SvcTime5)|Sys(PageFaults|NumReads)|Current(FileDescrCnt|UnusedFDescrCnt|ResFileDescrCnt)|Server(Requests|InKb|OutKb)|Http(AllSvcTime5|Errors|InKb|OutKb|AllSvcTime1)|Mem(MaxSize|Usage)|NumObjCount|CpuTime|MaxResSize|ProtoClientHttpRequests|Clients)))
        sourceLabels:
        - __name__
    - remoteTimeout: 5s
      url: http://$(METADATA_METRICS_SVC).$(NAMESPACE).svc.cluster.local.:9888/prometheus.metrics.applications.custom
      writeRelabelConfigs:
      - action: keep
        regex: ^true$
        sourceLabels:
        - _sumo_forward_
      - action: labeldrop
        regex: _sumo_forward_
  securityContext:
    fsGroup: 2000
    runAsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
  ruleNamespaceSelector: {}
  ruleSelector:
    matchLabels:
      release: "sumologic"

  podMetadata:
    annotations: {}
    labels: {}
  additionalScrapeConfigs:
    name: sumologic-kube-prometheus-prometheus-scrape-confg
    key: additional-scrape-configs.yaml
  containers:
    - env:
      - name: METADATA_METRICS_SVC
        valueFrom:
          configMapKeyRef:
            key: metadataMetrics
            name: sumologic-configmap
      - name: NAMESPACE
        valueFrom:
          configMapKeyRef:
            key: metadataNamespace
            name: sumologic-configmap
      name: config-reloader
  initContainers:
    - env:
      - name: METADATA_METRICS_SVC
        valueFrom:
          configMapKeyRef:
            key: metadataMetrics
            name: sumologic-configmap
      - name: NAMESPACE
        valueFrom:
          configMapKeyRef:
            key: metadataNamespace
            name: sumologic-configmap
      name: init-config-reloader
  portName: http-web
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/alertmanager.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-alertmanager.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: alertmanager.rules
    rules:
    - alert: AlertmanagerFailedReload
      annotations:
        description: Configuration has failed to load for {{ $labels.namespace }}/{{ $labels.pod}}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerfailedreload
        summary: Reloading an Alertmanager configuration has failed.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        max_over_time(alertmanager_config_last_reload_successful{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}[5m]) == 0
      for: 10m
      labels:
        severity: critical
    - alert: AlertmanagerMembersInconsistent
      annotations:
        description: Alertmanager {{ $labels.namespace }}/{{ $labels.pod}} has only found {{ $value }} members of the {{$labels.job}} cluster.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagermembersinconsistent
        summary: A member of an Alertmanager cluster has not found all other cluster members.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
          max_over_time(alertmanager_cluster_members{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}[5m])
        < on (namespace,service) group_left
          count by (namespace,service) (max_over_time(alertmanager_cluster_members{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}[5m]))
      for: 15m
      labels:
        severity: critical
    - alert: AlertmanagerFailedToSendAlerts
      annotations:
        description: Alertmanager {{ $labels.namespace }}/{{ $labels.pod}} failed to send {{ $value | humanizePercentage }} of notifications to {{ $labels.integration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerfailedtosendalerts
        summary: An Alertmanager instance failed to send notifications.
      expr: |-
        (
          rate(alertmanager_notifications_failed_total{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}[5m])
        /
          rate(alertmanager_notifications_total{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: warning
    - alert: AlertmanagerClusterFailedToSendAlerts
      annotations:
        description: The minimum notification failure rate to {{ $labels.integration }} sent from any instance in the {{$labels.job}} cluster is {{ $value | humanizePercentage }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterfailedtosendalerts
        summary: All Alertmanager instances in a cluster failed to send notifications to a critical integration.
      expr: |-
        min by (namespace,service, integration) (
          rate(alertmanager_notifications_failed_total{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring", integration=~`.*`}[5m])
        /
          rate(alertmanager_notifications_total{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring", integration=~`.*`}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: critical
    - alert: AlertmanagerClusterFailedToSendAlerts
      annotations:
        description: The minimum notification failure rate to {{ $labels.integration }} sent from any instance in the {{$labels.job}} cluster is {{ $value | humanizePercentage }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterfailedtosendalerts
        summary: All Alertmanager instances in a cluster failed to send notifications to a non-critical integration.
      expr: |-
        min by (namespace,service, integration) (
          rate(alertmanager_notifications_failed_total{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring", integration!~`.*`}[5m])
        /
          rate(alertmanager_notifications_total{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring", integration!~`.*`}[5m])
        )
        > 0.01
      for: 5m
      labels:
        severity: warning
    - alert: AlertmanagerConfigInconsistent
      annotations:
        description: Alertmanager instances within the {{$labels.job}} cluster have different configurations.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerconfiginconsistent
        summary: Alertmanager instances within the same cluster have different configurations.
      expr: |-
        count by (namespace,service) (
          count_values by (namespace,service) ("config_hash", alertmanager_config_hash{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"})
        )
        != 1
      for: 20m
      labels:
        severity: critical
    - alert: AlertmanagerClusterDown
      annotations:
        description: '{{ $value | humanizePercentage }} of Alertmanager instances within the {{$labels.job}} cluster have been up for less than half of the last 5m.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclusterdown
        summary: Half or more of the Alertmanager instances within the same cluster are down.
      expr: |-
        (
          count by (namespace,service) (
            avg_over_time(up{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}[5m]) < 0.5
          )
        /
          count by (namespace,service) (
            up{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}
          )
        )
        >= 0.5
      for: 5m
      labels:
        severity: critical
    - alert: AlertmanagerClusterCrashlooping
      annotations:
        description: '{{ $value | humanizePercentage }} of Alertmanager instances within the {{$labels.job}} cluster have restarted at least 5 times in the last 10m.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/alertmanager/alertmanagerclustercrashlooping
        summary: Half or more of the Alertmanager instances within the same cluster are crashlooping.
      expr: |-
        (
          count by (namespace,service) (
            changes(process_start_time_seconds{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}[10m]) > 4
          )
        /
          count by (namespace,service) (
            up{job="sumologic-kube-prometheus-alertmanager",namespace="monitoring"}
          )
        )
        >= 0.5
      for: 5m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/config-reloaders.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-config-reloaders
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: config-reloaders
    rules:
    - alert: ConfigReloaderSidecarErrors
      annotations:
        description: 'Errors encountered while the {{$labels.pod}} config-reloader sidecar attempts to sync config in {{$labels.namespace}} namespace.

          As a result, configuration for service running in {{$labels.pod}} may be stale and cannot be updated anymore.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/configreloadersidecarerrors
        summary: config-reloader sidecar has not had a successful reload for 10m
      expr: max_over_time(reloader_last_reload_successful{namespace=~".+"}[5m]) == 0
      for: 10m
      labels:
        severity: warning
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/etcd.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-etcd
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: etcd
    rules:
    - alert: etcdMembersDown
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": members are down ({{ $value }}).'
        summary: etcd cluster members are down.
      expr: |-
        max without (endpoint) (
          sum without (instance) (up{job=~".*etcd.*"} == bool 0)
        or
          count without (To) (
            sum without (instance) (rate(etcd_network_peer_sent_failures_total{job=~".*etcd.*"}[120s])) > 0.01
          )
        )
        > 0
      for: 10m
      labels:
        severity: critical
    - alert: etcdInsufficientMembers
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": insufficient members ({{ $value }}).'
        summary: etcd cluster has insufficient number of members.
      expr: sum(up{job=~".*etcd.*"} == bool 1) without (instance) < ((count(up{job=~".*etcd.*"}) without (instance) + 1) / 2)
      for: 3m
      labels:
        severity: critical
    - alert: etcdNoLeader
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": member {{ $labels.instance }} has no leader.'
        summary: etcd cluster has no leader.
      expr: etcd_server_has_leader{job=~".*etcd.*"} == 0
      for: 1m
      labels:
        severity: critical
    - alert: etcdHighNumberOfLeaderChanges
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": {{ $value }} leader changes within the last 15 minutes. Frequent elections may be a sign of insufficient resources, high network latency, or disruptions by other components and should be investigated.'
        summary: etcd cluster has high number of leader changes.
      expr: increase((max without (instance) (etcd_server_leader_changes_seen_total{job=~".*etcd.*"}) or 0*absent(etcd_server_leader_changes_seen_total{job=~".*etcd.*"}))[15m:1m]) >= 4
      for: 5m
      labels:
        severity: warning
    - alert: etcdHighNumberOfFailedGRPCRequests
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{ $labels.grpc_method }} failed on etcd instance {{ $labels.instance }}.'
        summary: etcd cluster has high number of failed grpc requests.
      expr: |-
        100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*", grpc_code=~"Unknown|FailedPrecondition|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded"}[5m])) without (grpc_type, grpc_code)
          /
        sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m])) without (grpc_type, grpc_code)
          > 1
      for: 10m
      labels:
        severity: warning
    - alert: etcdHighNumberOfFailedGRPCRequests
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": {{ $value }}% of requests for {{ $labels.grpc_method }} failed on etcd instance {{ $labels.instance }}.'
        summary: etcd cluster has high number of failed grpc requests.
      expr: |-
        100 * sum(rate(grpc_server_handled_total{job=~".*etcd.*", grpc_code=~"Unknown|FailedPrecondition|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded"}[5m])) without (grpc_type, grpc_code)
          /
        sum(rate(grpc_server_handled_total{job=~".*etcd.*"}[5m])) without (grpc_type, grpc_code)
          > 5
      for: 5m
      labels:
        severity: critical
    - alert: etcdGRPCRequestsSlow
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": 99th percentile of gRPC requests is {{ $value }}s on etcd instance {{ $labels.instance }} for {{ $labels.grpc_method }} method.'
        summary: etcd grpc requests are slow
      expr: |-
        histogram_quantile(0.99, sum(rate(grpc_server_handling_seconds_bucket{job=~".*etcd.*", grpc_method!="Defragment", grpc_type="unary"}[5m])) without(grpc_type))
        > 0.15
      for: 10m
      labels:
        severity: critical
    - alert: etcdMemberCommunicationSlow
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": member communication with {{ $labels.To }} is taking {{ $value }}s on etcd instance {{ $labels.instance }}.'
        summary: etcd cluster member communication is slow.
      expr: |-
        histogram_quantile(0.99, rate(etcd_network_peer_round_trip_time_seconds_bucket{job=~".*etcd.*"}[5m]))
        > 0.15
      for: 10m
      labels:
        severity: warning
    - alert: etcdHighNumberOfFailedProposals
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": {{ $value }} proposal failures within the last 30 minutes on etcd instance {{ $labels.instance }}.'
        summary: etcd cluster has high number of proposal failures.
      expr: rate(etcd_server_proposals_failed_total{job=~".*etcd.*"}[15m]) > 5
      for: 15m
      labels:
        severity: warning
    - alert: etcdHighFsyncDurations
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": 99th percentile fsync durations are {{ $value }}s on etcd instance {{ $labels.instance }}.'
        summary: etcd cluster 99th percentile fsync durations are too high.
      expr: |-
        histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
        > 0.5
      for: 10m
      labels:
        severity: warning
    - alert: etcdHighFsyncDurations
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": 99th percentile fsync durations are {{ $value }}s on etcd instance {{ $labels.instance }}.'
        summary: etcd cluster 99th percentile fsync durations are too high.
      expr: |-
        histogram_quantile(0.99, rate(etcd_disk_wal_fsync_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
        > 1
      for: 10m
      labels:
        severity: critical
    - alert: etcdHighCommitDurations
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": 99th percentile commit durations {{ $value }}s on etcd instance {{ $labels.instance }}.'
        summary: etcd cluster 99th percentile commit durations are too high.
      expr: |-
        histogram_quantile(0.99, rate(etcd_disk_backend_commit_duration_seconds_bucket{job=~".*etcd.*"}[5m]))
        > 0.25
      for: 10m
      labels:
        severity: warning
    - alert: etcdDatabaseQuotaLowSpace
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": database size exceeds the defined quota on etcd instance {{ $labels.instance }}, please defrag or increase the quota as the writes to etcd will be disabled when it is full.'
        summary: etcd cluster database is running full.
      expr: (last_over_time(etcd_mvcc_db_total_size_in_bytes[5m]) / last_over_time(etcd_server_quota_backend_bytes[5m]))*100 > 95
      for: 10m
      labels:
        severity: critical
    - alert: etcdExcessiveDatabaseGrowth
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": Predicting running out of disk space in the next four hours, based on write observations within the past four hours on etcd instance {{ $labels.instance }}, please check as it might be disruptive.'
        summary: etcd cluster database growing very fast.
      expr: predict_linear(etcd_mvcc_db_total_size_in_bytes[4h], 4*60*60) > etcd_server_quota_backend_bytes
      for: 10m
      labels:
        severity: warning
    - alert: etcdDatabaseHighFragmentationRatio
      annotations:
        description: 'etcd cluster "{{ $labels.job }}": database size in use on instance {{ $labels.instance }} is {{ $value | humanizePercentage }} of the actual allocated disk space, please run defragmentation (e.g. etcdctl defrag) to retrieve the unused fragmented disk space.'
        runbook_url: https://etcd.io/docs/v3.5/op-guide/maintenance/#defragmentation
        summary: etcd database size in use is less than 50% of the actual allocated storage.
      expr: (last_over_time(etcd_mvcc_db_total_size_in_use_in_bytes[5m]) / last_over_time(etcd_mvcc_db_total_size_in_bytes[5m])) < 0.5
      for: 10m
      labels:
        severity: warning
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/general.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-general.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: general.rules
    rules:
    - alert: TargetDown
      annotations:
        description: '{{ printf "%.4g" $value }}% of the {{ $labels.job }}/{{ $labels.service }} targets in {{ $labels.namespace }} namespace are down.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/targetdown
        summary: One or more targets are unreachable.
      expr: 100 * (count(up == 0) BY (job, namespace, service) / count(up) BY (job, namespace, service)) > 10
      for: 10m
      labels:
        severity: warning
    - alert: Watchdog
      annotations:
        description: 'This is an alert meant to ensure that the entire alerting pipeline is functional.

          This alert is always firing, therefore it should always be firing in Alertmanager

          and always fire against a receiver. There are integrations with various notification

          mechanisms that send a notification when this alert is not firing. For example the

          "DeadMansSnitch" integration in PagerDuty.

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/watchdog
        summary: An alert that should always be firing to certify that Alertmanager is working properly.
      expr: vector(1)
      labels:
        severity: none
    - alert: InfoInhibitor
      annotations:
        description: 'This is an alert that is used to inhibit info alerts.

          By themselves, the info-level alerts are sometimes very noisy, but they are relevant when combined with

          other alerts.

          This alert fires whenever there''s a severity="info" alert, and stops firing when another alert with a

          severity of ''warning'' or ''critical'' starts firing on the same namespace.

          This alert should be routed to a null receiver and configured to inhibit alerts with severity="info".

          '
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/infoinhibitor
        summary: Info-level alert inhibition.
      expr: ALERTS{severity = "info"} == 1 unless on(namespace) ALERTS{alertname != "InfoInhibitor", severity =~ "warning|critical", alertstate="firing"} == 1
      labels:
        severity: none
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/k8s.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-k8s.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: k8s.rules
    rules:
    - expr: |-
        sum by (cluster, namespace, pod, container) (
          irate(container_cpu_usage_seconds_total{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}[5m])
        ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
          1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
    - expr: |-
        container_memory_working_set_bytes{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
          max by(namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_working_set_bytes
    - expr: |-
        container_memory_rss{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
          max by(namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_rss
    - expr: |-
        container_memory_cache{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
          max by(namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_cache
    - expr: |-
        container_memory_swap{job="kubelet", metrics_path="/metrics/cadvisor", image!=""}
        * on (namespace, pod) group_left(node) topk by(namespace, pod) (1,
          max by(namespace, pod, node) (kube_pod_info{node!=""})
        )
      record: node_namespace_pod_container:container_memory_swap
    - expr: |-
        kube_pod_container_resource_requests{resource="memory",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
          (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
        )
      record: cluster:namespace:pod_memory:active:kube_pod_container_resource_requests
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_requests{resource="memory",job="kube-state-metrics"}
                ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_memory:kube_pod_container_resource_requests:sum
    - expr: |-
        kube_pod_container_resource_requests{resource="cpu",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
          (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
        )
      record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_requests{resource="cpu",job="kube-state-metrics"}
                ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_cpu:kube_pod_container_resource_requests:sum
    - expr: |-
        kube_pod_container_resource_limits{resource="memory",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
          (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
        )
      record: cluster:namespace:pod_memory:active:kube_pod_container_resource_limits
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_limits{resource="memory",job="kube-state-metrics"}
                ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_memory:kube_pod_container_resource_limits:sum
    - expr: |-
        kube_pod_container_resource_limits{resource="cpu",job="kube-state-metrics"}  * on (namespace, pod, cluster)
        group_left() max by (namespace, pod, cluster) (
         (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
         )
      record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits
    - expr: |-
        sum by (namespace, cluster) (
            sum by (namespace, pod, cluster) (
                max by (namespace, pod, container, cluster) (
                  kube_pod_container_resource_limits{resource="cpu",job="kube-state-metrics"}
                ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                  kube_pod_status_phase{phase=~"Pending|Running"} == 1
                )
            )
        )
      record: namespace_cpu:kube_pod_container_resource_limits:sum
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            label_replace(
              kube_pod_owner{job="kube-state-metrics", owner_kind="ReplicaSet"},
              "replicaset", "$1", "owner_name", "(.*)"
            ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
              1, max by (replicaset, namespace, owner_name) (
                kube_replicaset_owner{job="kube-state-metrics"}
              )
            ),
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: deployment
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="DaemonSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: daemonset
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="StatefulSet"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: statefulset
      record: namespace_workload_pod:kube_pod_owner:relabel
    - expr: |-
        max by (cluster, namespace, workload, pod) (
          label_replace(
            kube_pod_owner{job="kube-state-metrics", owner_kind="Job"},
            "workload", "$1", "owner_name", "(.*)"
          )
        )
      labels:
        workload_type: job
      record: namespace_workload_pod:kube_pod_owner:relabel
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-availability.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-apiserver-availability.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - interval: 3m
    name: kube-apiserver-availability.rules
    rules:
    - expr: avg_over_time(code_verb:apiserver_request_total:increase1h[30d]) * 24 * 30
      record: code_verb:apiserver_request_total:increase30d
    - expr: sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"LIST|GET"})
      labels:
        verb: read
      record: code:apiserver_request_total:increase30d
    - expr: sum by (cluster, code) (code_verb:apiserver_request_total:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
      labels:
        verb: write
      record: code:apiserver_request_total:increase30d
    - expr: sum by (cluster, verb, scope) (increase(apiserver_request_slo_duration_seconds_count[1h]))
      record: cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase1h
    - expr: sum by (cluster, verb, scope) (avg_over_time(cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d
    - expr: sum by (cluster, verb, scope, le) (increase(apiserver_request_slo_duration_seconds_bucket[1h]))
      record: cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase1h
    - expr: sum by (cluster, verb, scope, le) (avg_over_time(cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase1h[30d]) * 24 * 30)
      record: cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d
    - expr: |-
        1 - (
          (
            # write too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          ) +
          (
            # read too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"LIST|GET"})
            -
            (
              (
                sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
                or
                vector(0)
              )
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
              +
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
            )
          ) +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d)
      labels:
        verb: all
      record: apiserver_request:availability30d
    - expr: |-
        1 - (
          sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"LIST|GET"})
          -
          (
            # too slow
            (
              sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope=~"resource|",le="1"})
              or
              vector(0)
            )
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="namespace",le="5"})
            +
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"LIST|GET",scope="cluster",le="30"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="read",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="read"})
      labels:
        verb: read
      record: apiserver_request:availability30d
    - expr: |-
        1 - (
          (
            # too slow
            sum by (cluster) (cluster_verb_scope:apiserver_request_slo_duration_seconds_count:increase30d{verb=~"POST|PUT|PATCH|DELETE"})
            -
            sum by (cluster) (cluster_verb_scope_le:apiserver_request_slo_duration_seconds_bucket:increase30d{verb=~"POST|PUT|PATCH|DELETE",le="1"})
          )
          +
          # errors
          sum by (cluster) (code:apiserver_request_total:increase30d{verb="write",code=~"5.."} or vector(0))
        )
        /
        sum by (cluster) (code:apiserver_request_total:increase30d{verb="write"})
      labels:
        verb: write
      record: apiserver_request:availability30d
    - expr: sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: code_resource:apiserver_request_total:rate5m
    - expr: sum by (cluster,code,resource) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: code_resource:apiserver_request_total:rate5m
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"2.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"3.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"4.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
    - expr: sum by (cluster, code, verb) (increase(apiserver_request_total{job="apiserver",verb=~"LIST|GET|POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
      record: code_verb:apiserver_request_total:increase1h
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-burnrate.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-apiserver-burnrate.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kube-apiserver-burnrate.rules
    rules:
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1d]))
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1d]))
      labels:
        verb: read
      record: apiserver_request:burnrate1d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[1h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[1h]))
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[1h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[1h]))
      labels:
        verb: read
      record: apiserver_request:burnrate1h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[2h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[2h]))
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[2h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[2h]))
      labels:
        verb: read
      record: apiserver_request:burnrate2h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[30m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[30m]))
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[30m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[30m]))
      labels:
        verb: read
      record: apiserver_request:burnrate30m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[3d]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[3d]))
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[3d]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[3d]))
      labels:
        verb: read
      record: apiserver_request:burnrate3d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[5m]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[5m]))
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[5m]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[5m]))
      labels:
        verb: read
      record: apiserver_request:burnrate5m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
            -
            (
              (
                sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope=~"resource|",le="1"}[6h]))
                or
                vector(0)
              )
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="namespace",le="5"}[6h]))
              +
              sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward",scope="cluster",le="30"}[6h]))
            )
          )
          +
          # errors
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"LIST|GET"}[6h]))
      labels:
        verb: read
      record: apiserver_request:burnrate6h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1d]))
            -
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1d]))
      labels:
        verb: write
      record: apiserver_request:burnrate1d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[1h]))
            -
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[1h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[1h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[1h]))
      labels:
        verb: write
      record: apiserver_request:burnrate1h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[2h]))
            -
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[2h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[2h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[2h]))
      labels:
        verb: write
      record: apiserver_request:burnrate2h
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[30m]))
            -
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[30m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[30m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[30m]))
      labels:
        verb: write
      record: apiserver_request:burnrate30m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[3d]))
            -
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[3d]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[3d]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[3d]))
      labels:
        verb: write
      record: apiserver_request:burnrate3d
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))
            -
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[5m]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[5m]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[5m]))
      labels:
        verb: write
      record: apiserver_request:burnrate5m
    - expr: |-
        (
          (
            # too slow
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_count{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[6h]))
            -
            sum by (cluster) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward",le="1"}[6h]))
          )
          +
          sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",code=~"5.."}[6h]))
        )
        /
        sum by (cluster) (rate(apiserver_request_total{job="apiserver",verb=~"POST|PUT|PATCH|DELETE"}[6h]))
      labels:
        verb: write
      record: apiserver_request:burnrate6h
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-histogram.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-apiserver-histogram.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kube-apiserver-histogram.rules
    rules:
    - expr: histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"LIST|GET",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
      labels:
        quantile: '0.99'
        verb: read
      record: cluster_quantile:apiserver_request_slo_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.99, sum by (cluster, le, resource) (rate(apiserver_request_slo_duration_seconds_bucket{job="apiserver",verb=~"POST|PUT|PATCH|DELETE",subresource!~"proxy|attach|log|exec|portforward"}[5m]))) > 0
      labels:
        quantile: '0.99'
        verb: write
      record: cluster_quantile:apiserver_request_slo_duration_seconds:histogram_quantile
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-apiserver-slos.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-apiserver-slos
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kube-apiserver-slos
    rules:
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate1h) > (14.40 * 0.01000)
        and
        sum(apiserver_request:burnrate5m) > (14.40 * 0.01000)
      for: 2m
      labels:
        long: 1h
        severity: critical
        short: 5m
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate6h) > (6.00 * 0.01000)
        and
        sum(apiserver_request:burnrate30m) > (6.00 * 0.01000)
      for: 15m
      labels:
        long: 6h
        severity: critical
        short: 30m
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate1d) > (3.00 * 0.01000)
        and
        sum(apiserver_request:burnrate2h) > (3.00 * 0.01000)
      for: 1h
      labels:
        long: 1d
        severity: warning
        short: 2h
    - alert: KubeAPIErrorBudgetBurn
      annotations:
        description: The API server is burning too much error budget.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapierrorbudgetburn
        summary: The API server is burning too much error budget.
      expr: |-
        sum(apiserver_request:burnrate3d) > (1.00 * 0.01000)
        and
        sum(apiserver_request:burnrate6h) > (1.00 * 0.01000)
      for: 3h
      labels:
        long: 3d
        severity: warning
        short: 6h
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-prometheus-general.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-prometheus-general.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kube-prometheus-general.rules
    rules:
    - expr: count without(instance, pod, node) (up == 1)
      record: count:up1
    - expr: count without(instance, pod, node) (up == 0)
      record: count:up0
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-prometheus-node-recording.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-prometheus-node-recording.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kube-prometheus-node-recording.rules
    rules:
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[3m])) BY (instance)
      record: instance:node_cpu:rate:sum
    - expr: sum(rate(node_network_receive_bytes_total[3m])) BY (instance)
      record: instance:node_network_receive_bytes:rate:sum
    - expr: sum(rate(node_network_transmit_bytes_total[3m])) BY (instance)
      record: instance:node_network_transmit_bytes:rate:sum
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[5m])) WITHOUT (cpu, mode) / ON(instance) GROUP_LEFT() count(sum(node_cpu_seconds_total) BY (instance, cpu)) BY (instance)
      record: instance:node_cpu:ratio
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait",mode!="steal"}[5m]))
      record: cluster:node_cpu:sum_rate5m
    - expr: cluster:node_cpu:sum_rate5m / count(sum(node_cpu_seconds_total) BY (instance, cpu))
      record: cluster:node_cpu:ratio
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-scheduler.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-scheduler.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kube-scheduler.rules
    rules:
    - expr: histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.99'
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.99'
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.99, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.99'
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.9'
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.9'
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.9'
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.5'
      record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.5'
      record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
      labels:
        quantile: '0.5'
      record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kube-state-metrics.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kube-state-metrics
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kube-state-metrics
    rules:
    - alert: KubeStateMetricsListErrors
      annotations:
        description: kube-state-metrics is experiencing errors at an elevated rate in list operations. This is likely causing it to not be able to expose metrics about Kubernetes objects correctly or at all.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricslisterrors
        summary: kube-state-metrics is experiencing errors in list operations.
      expr: |-
        (sum(rate(kube_state_metrics_list_total{job="kube-state-metrics",result="error"}[5m]))
          /
        sum(rate(kube_state_metrics_list_total{job="kube-state-metrics"}[5m])))
        > 0.01
      for: 15m
      labels:
        severity: critical
    - alert: KubeStateMetricsWatchErrors
      annotations:
        description: kube-state-metrics is experiencing errors at an elevated rate in watch operations. This is likely causing it to not be able to expose metrics about Kubernetes objects correctly or at all.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricswatcherrors
        summary: kube-state-metrics is experiencing errors in watch operations.
      expr: |-
        (sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics",result="error"}[5m]))
          /
        sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics"}[5m])))
        > 0.01
      for: 15m
      labels:
        severity: critical
    - alert: KubeStateMetricsShardingMismatch
      annotations:
        description: kube-state-metrics pods are running with different --total-shards configuration, some Kubernetes objects may be exposed multiple times or not exposed at all.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricsshardingmismatch
        summary: kube-state-metrics sharding is misconfigured.
      expr: stdvar (kube_state_metrics_total_shards{job="kube-state-metrics"}) != 0
      for: 15m
      labels:
        severity: critical
    - alert: KubeStateMetricsShardsMissing
      annotations:
        description: kube-state-metrics shards are missing, some Kubernetes objects are not being exposed.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kube-state-metrics/kubestatemetricsshardsmissing
        summary: kube-state-metrics shards are missing.
      expr: |-
        2^max(kube_state_metrics_total_shards{job="kube-state-metrics"}) - 1
          -
        sum( 2 ^ max by (shard_ordinal) (kube_state_metrics_shard_ordinal{job="kube-state-metrics"}) )
        != 0
      for: 15m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubelet.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubelet.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubelet.rules
    rules:
    - expr: histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
      labels:
        quantile: '0.99'
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.9, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
      labels:
        quantile: '0.9'
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
    - expr: histogram_quantile(0.5, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (cluster, instance, le) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"})
      labels:
        quantile: '0.5'
      record: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-apps.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-apps
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-apps
    rules:
    - alert: KubePodCrashLooping
      annotations:
        description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff").'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodcrashlooping
        summary: Pod is crash looping.
      expr: max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics", namespace=~".*"}[5m]) >= 1
      for: 15m
      labels:
        severity: warning
    - alert: KubePodNotReady
      annotations:
        description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepodnotready
        summary: Pod has been in a non-ready state for more than 15 minutes.
      expr: |-
        sum by (namespace, pod, cluster) (
          max by(namespace, pod, cluster) (
            kube_pod_status_phase{job="kube-state-metrics", namespace=~".*", phase=~"Pending|Unknown"}
          ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (
            1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
          )
        ) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeDeploymentGenerationMismatch
      annotations:
        description: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentgenerationmismatch
        summary: Deployment generation mismatch due to possible roll-back
      expr: |-
        kube_deployment_status_observed_generation{job="kube-state-metrics", namespace=~".*"}
          !=
        kube_deployment_metadata_generation{job="kube-state-metrics", namespace=~".*"}
      for: 15m
      labels:
        severity: warning
    - alert: KubeDeploymentReplicasMismatch
      annotations:
        description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedeploymentreplicasmismatch
        summary: Deployment has not matched the expected number of replicas.
      expr: |-
        (
          kube_deployment_spec_replicas{job="kube-state-metrics", namespace=~".*"}
            >
          kube_deployment_status_replicas_available{job="kube-state-metrics", namespace=~".*"}
        ) and (
          changes(kube_deployment_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}[10m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeStatefulSetReplicasMismatch
      annotations:
        description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetreplicasmismatch
        summary: Deployment has not matched the expected number of replicas.
      expr: |-
        (
          kube_statefulset_status_replicas_ready{job="kube-state-metrics", namespace=~".*"}
            !=
          kube_statefulset_status_replicas{job="kube-state-metrics", namespace=~".*"}
        ) and (
          changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}[10m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeStatefulSetGenerationMismatch
      annotations:
        description: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetgenerationmismatch
        summary: StatefulSet generation mismatch due to possible roll-back
      expr: |-
        kube_statefulset_status_observed_generation{job="kube-state-metrics", namespace=~".*"}
          !=
        kube_statefulset_metadata_generation{job="kube-state-metrics", namespace=~".*"}
      for: 15m
      labels:
        severity: warning
    - alert: KubeStatefulSetUpdateNotRolledOut
      annotations:
        description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubestatefulsetupdatenotrolledout
        summary: StatefulSet update has not been rolled out.
      expr: |-
        (
          max without (revision) (
            kube_statefulset_status_current_revision{job="kube-state-metrics", namespace=~".*"}
              unless
            kube_statefulset_status_update_revision{job="kube-state-metrics", namespace=~".*"}
          )
            *
          (
            kube_statefulset_replicas{job="kube-state-metrics", namespace=~".*"}
              !=
            kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}
          )
        )  and (
          changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics", namespace=~".*"}[5m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeDaemonSetRolloutStuck
      annotations:
        description: DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetrolloutstuck
        summary: DaemonSet rollout is stuck.
      expr: |-
        (
          (
            kube_daemonset_status_current_number_scheduled{job="kube-state-metrics", namespace=~".*"}
             !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          ) or (
            kube_daemonset_status_number_misscheduled{job="kube-state-metrics", namespace=~".*"}
             !=
            0
          ) or (
            kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics", namespace=~".*"}
             !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          ) or (
            kube_daemonset_status_number_available{job="kube-state-metrics", namespace=~".*"}
             !=
            kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          )
        ) and (
          changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics", namespace=~".*"}[5m])
            ==
          0
        )
      for: 15m
      labels:
        severity: warning
    - alert: KubeContainerWaiting
      annotations:
        description: pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecontainerwaiting
        summary: Pod container waiting longer than 1 hour
      expr: sum by (namespace, pod, container, cluster) (kube_pod_container_status_waiting_reason{job="kube-state-metrics", namespace=~".*"}) > 0
      for: 1h
      labels:
        severity: warning
    - alert: KubeDaemonSetNotScheduled
      annotations:
        description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetnotscheduled
        summary: DaemonSet pods are not scheduled.
      expr: |-
        kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics", namespace=~".*"}
          -
        kube_daemonset_status_current_number_scheduled{job="kube-state-metrics", namespace=~".*"} > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeDaemonSetMisScheduled
      annotations:
        description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubedaemonsetmisscheduled
        summary: DaemonSet pods are misscheduled.
      expr: kube_daemonset_status_number_misscheduled{job="kube-state-metrics", namespace=~".*"} > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeJobNotCompleted
      annotations:
        description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobnotcompleted
        summary: Job did not complete in time
      expr: |-
        time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics", namespace=~".*"}
          and
        kube_job_status_active{job="kube-state-metrics", namespace=~".*"} > 0) > 43200
      labels:
        severity: warning
    - alert: KubeJobFailed
      annotations:
        description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubejobfailed
        summary: Job failed to complete.
      expr: kube_job_failed{job="kube-state-metrics", namespace=~".*"}  > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeHpaReplicasMismatch
      annotations:
        description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpareplicasmismatch
        summary: HPA has not matched desired number of replicas.
      expr: |-
        (kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics", namespace=~".*"}
          !=
        kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"})
          and
        (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}
          >
        kube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics", namespace=~".*"})
          and
        (kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}
          <
        kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics", namespace=~".*"})
          and
        changes(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}[15m]) == 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeHpaMaxedOut
      annotations:
        description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubehpamaxedout
        summary: HPA is running at max replicas
      expr: |-
        kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics", namespace=~".*"}
          ==
        kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics", namespace=~".*"}
      for: 15m
      labels:
        severity: warning
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-resources.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-resources
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-resources
    rules:
    - alert: KubeCPUOvercommit
      annotations:
        description: Cluster has overcommitted CPU resource requests for Pods by {{ $value }} CPU shares and cannot tolerate node failure.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecpuovercommit
        summary: Cluster has overcommitted CPU resource requests.
      expr: |-
        sum(namespace_cpu:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource="cpu"}) - max(kube_node_status_allocatable{resource="cpu"})) > 0
        and
        (sum(kube_node_status_allocatable{resource="cpu"}) - max(kube_node_status_allocatable{resource="cpu"})) > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeMemoryOvercommit
      annotations:
        description: Cluster has overcommitted memory resource requests for Pods by {{ $value | humanize }} bytes and cannot tolerate node failure.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubememoryovercommit
        summary: Cluster has overcommitted memory resource requests.
      expr: |-
        sum(namespace_memory:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource="memory"}) - max(kube_node_status_allocatable{resource="memory"})) > 0
        and
        (sum(kube_node_status_allocatable{resource="memory"}) - max(kube_node_status_allocatable{resource="memory"})) > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeCPUQuotaOvercommit
      annotations:
        description: Cluster has overcommitted CPU resource requests for Namespaces.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecpuquotaovercommit
        summary: Cluster has overcommitted CPU resource requests.
      expr: |-
        sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(cpu|requests.cpu)"}))
          /
        sum(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"})
          > 1.5
      for: 5m
      labels:
        severity: warning
    - alert: KubeMemoryQuotaOvercommit
      annotations:
        description: Cluster has overcommitted memory resource requests for Namespaces.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubememoryquotaovercommit
        summary: Cluster has overcommitted memory resource requests.
      expr: |-
        sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(memory|requests.memory)"}))
          /
        sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"})
          > 1.5
      for: 5m
      labels:
        severity: warning
    - alert: KubeQuotaAlmostFull
      annotations:
        description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubequotaalmostfull
        summary: Namespace quota is going to be full.
      expr: |-
        kube_resourcequota{job="kube-state-metrics", type="used"}
          / ignoring(instance, job, type)
        (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
          > 0.9 < 1
      for: 15m
      labels:
        severity: info
    - alert: KubeQuotaFullyUsed
      annotations:
        description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubequotafullyused
        summary: Namespace quota is fully used.
      expr: |-
        kube_resourcequota{job="kube-state-metrics", type="used"}
          / ignoring(instance, job, type)
        (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
          == 1
      for: 15m
      labels:
        severity: info
    - alert: KubeQuotaExceeded
      annotations:
        description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubequotaexceeded
        summary: Namespace quota has exceeded the limits.
      expr: |-
        kube_resourcequota{job="kube-state-metrics", type="used"}
          / ignoring(instance, job, type)
        (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)
          > 1
      for: 15m
      labels:
        severity: warning
    - alert: CPUThrottlingHigh
      annotations:
        description: '{{ $value | humanizePercentage }} throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }}.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/cputhrottlinghigh
        summary: Processes experience elevated CPU throttling.
      expr: |-
        sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (container, pod, namespace)
          /
        sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace)
          > ( 25 / 100 )
      for: 15m
      labels:
        severity: info
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-storage.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-storage
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-storage
    rules:
    - alert: KubePersistentVolumeFillingUp
      annotations:
        description: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is only {{ $value | humanizePercentage }} free.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumefillingup
        summary: PersistentVolume is filling up.
      expr: |-
        (
          kubelet_volume_stats_available_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.03
        and
        kubelet_volume_stats_used_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1m
      labels:
        severity: critical
    - alert: KubePersistentVolumeFillingUp
      annotations:
        description: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is expected to fill up within four days. Currently {{ $value | humanizePercentage }} is available.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumefillingup
        summary: PersistentVolume is filling up.
      expr: |-
        (
          kubelet_volume_stats_available_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_capacity_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.15
        and
        kubelet_volume_stats_used_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        and
        predict_linear(kubelet_volume_stats_available_bytes{job="kubelet", namespace=~".*", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1h
      labels:
        severity: warning
    - alert: KubePersistentVolumeInodesFillingUp
      annotations:
        description: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} only has {{ $value | humanizePercentage }} free inodes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeinodesfillingup
        summary: PersistentVolumeInodes are filling up.
      expr: |-
        (
          kubelet_volume_stats_inodes_free{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_inodes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.03
        and
        kubelet_volume_stats_inodes_used{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1m
      labels:
        severity: critical
    - alert: KubePersistentVolumeInodesFillingUp
      annotations:
        description: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim }} in Namespace {{ $labels.namespace }} is expected to run out of inodes within four days. Currently {{ $value | humanizePercentage }} of its inodes are free.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeinodesfillingup
        summary: PersistentVolumeInodes are filling up.
      expr: |-
        (
          kubelet_volume_stats_inodes_free{job="kubelet", namespace=~".*", metrics_path="/metrics"}
            /
          kubelet_volume_stats_inodes{job="kubelet", namespace=~".*", metrics_path="/metrics"}
        ) < 0.15
        and
        kubelet_volume_stats_inodes_used{job="kubelet", namespace=~".*", metrics_path="/metrics"} > 0
        and
        predict_linear(kubelet_volume_stats_inodes_free{job="kubelet", namespace=~".*", metrics_path="/metrics"}[6h], 4 * 24 * 3600) < 0
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_access_mode{ access_mode="ReadOnlyMany"} == 1
        unless on(namespace, persistentvolumeclaim)
        kube_persistentvolumeclaim_labels{label_excluded_from_alerts="true"} == 1
      for: 1h
      labels:
        severity: warning
    - alert: KubePersistentVolumeErrors
      annotations:
        description: The persistent volume {{ $labels.persistentvolume }} has status {{ $labels.phase }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubepersistentvolumeerrors
        summary: PersistentVolume is having issues with provisioning.
      expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
      for: 5m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-apiserver.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-system-apiserver
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-apiserver
    rules:
    - alert: KubeClientCertificateExpiration
      annotations:
        description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 7.0 days.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclientcertificateexpiration
        summary: Client certificate is about to expire.
      expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 604800
      labels:
        severity: warning
    - alert: KubeClientCertificateExpiration
      annotations:
        description: A client certificate used to authenticate to kubernetes apiserver is expiring in less than 24.0 hours.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclientcertificateexpiration
        summary: Client certificate is about to expire.
      expr: apiserver_client_certificate_expiration_seconds_count{job="apiserver"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="apiserver"}[5m]))) < 86400
      labels:
        severity: critical
    - alert: KubeAggregatedAPIErrors
      annotations:
        description: Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has reported errors. It has appeared unavailable {{ $value | humanize }} times averaged over the past 10m.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeaggregatedapierrors
        summary: Kubernetes aggregated API has reported errors.
      expr: sum by(name, namespace, cluster)(increase(aggregator_unavailable_apiservice_total[10m])) > 4
      labels:
        severity: warning
    - alert: KubeAggregatedAPIDown
      annotations:
        description: Kubernetes aggregated API {{ $labels.name }}/{{ $labels.namespace }} has been only {{ $value | humanize }}% available over the last 10m.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeaggregatedapidown
        summary: Kubernetes aggregated API is down.
      expr: (1 - max by(name, namespace, cluster)(avg_over_time(aggregator_unavailable_apiservice[10m]))) * 100 < 85
      for: 5m
      labels:
        severity: warning
    - alert: KubeAPIDown
      annotations:
        description: KubeAPI has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapidown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="apiserver"} == 1)
      for: 15m
      labels:
        severity: critical
    - alert: KubeAPITerminatedRequests
      annotations:
        description: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeapiterminatedrequests
        summary: The kubernetes apiserver has terminated {{ $value | humanizePercentage }} of its incoming requests.
      expr: sum(rate(apiserver_request_terminations_total{job="apiserver"}[10m]))  / (  sum(rate(apiserver_request_total{job="apiserver"}[10m])) + sum(rate(apiserver_request_terminations_total{job="apiserver"}[10m])) ) > 0.20
      for: 5m
      labels:
        severity: warning
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-controller-manager.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-system-controller-manager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-controller-manager
    rules:
    - alert: KubeControllerManagerDown
      annotations:
        description: KubeControllerManager has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubecontrollermanagerdown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kube-controller-manager"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-kube-proxy.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-system-kube-proxy
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-kube-proxy
    rules:
    - alert: KubeProxyDown
      annotations:
        description: KubeProxy has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeproxydown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kube-proxy"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-kubelet.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-system-kubelet
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-kubelet
    rules:
    - alert: KubeNodeNotReady
      annotations:
        description: '{{ $labels.node }} has been unready for more than 15 minutes.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodenotready
        summary: Node is not ready.
      expr: kube_node_status_condition{job="kube-state-metrics",condition="Ready",status="true"} == 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeNodeUnreachable
      annotations:
        description: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodeunreachable
        summary: Node is unreachable.
      expr: (kube_node_spec_taint{job="kube-state-metrics",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job="kube-state-metrics",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
      for: 15m
      labels:
        severity: warning
    - alert: KubeletTooManyPods
      annotations:
        description: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage }} of its Pod capacity.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubelettoomanypods
        summary: Kubelet is running at capacity.
      expr: |-
        count by(cluster, node) (
          (kube_pod_status_phase{job="kube-state-metrics",phase="Running"} == 1) * on(instance,pod,namespace,cluster) group_left(node) topk by(instance,pod,namespace,cluster) (1, kube_pod_info{job="kube-state-metrics"})
        )
        /
        max by(cluster, node) (
          kube_node_status_capacity{job="kube-state-metrics",resource="pods"} != 1
        ) > 0.95
      for: 15m
      labels:
        severity: info
    - alert: KubeNodeReadinessFlapping
      annotations:
        description: The readiness status of node {{ $labels.node }} has changed {{ $value }} times in the last 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubenodereadinessflapping
        summary: Node readiness status is flapping.
      expr: sum(changes(kube_node_status_condition{status="true",condition="Ready"}[15m])) by (cluster, node) > 2
      for: 15m
      labels:
        severity: warning
    - alert: KubeletPlegDurationHigh
      annotations:
        description: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of {{ $value }} seconds on node {{ $labels.node }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletplegdurationhigh
        summary: Kubelet Pod Lifecycle Event Generator is taking too long to relist.
      expr: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
      for: 5m
      labels:
        severity: warning
    - alert: KubeletPodStartUpLatencyHigh
      annotations:
        description: Kubelet Pod startup 99th percentile latency is {{ $value }} seconds on node {{ $labels.node }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletpodstartuplatencyhigh
        summary: Kubelet Pod startup latency is too high.
      expr: histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job="kubelet", metrics_path="/metrics"}[5m])) by (cluster, instance, le)) * on(cluster, instance) group_left(node) kubelet_node_name{job="kubelet", metrics_path="/metrics"} > 60
      for: 15m
      labels:
        severity: warning
    - alert: KubeletClientCertificateExpiration
      annotations:
        description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificateexpiration
        summary: Kubelet client certificate is about to expire.
      expr: kubelet_certificate_manager_client_ttl_seconds < 604800
      labels:
        severity: warning
    - alert: KubeletClientCertificateExpiration
      annotations:
        description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificateexpiration
        summary: Kubelet client certificate is about to expire.
      expr: kubelet_certificate_manager_client_ttl_seconds < 86400
      labels:
        severity: critical
    - alert: KubeletServerCertificateExpiration
      annotations:
        description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificateexpiration
        summary: Kubelet server certificate is about to expire.
      expr: kubelet_certificate_manager_server_ttl_seconds < 604800
      labels:
        severity: warning
    - alert: KubeletServerCertificateExpiration
      annotations:
        description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificateexpiration
        summary: Kubelet server certificate is about to expire.
      expr: kubelet_certificate_manager_server_ttl_seconds < 86400
      labels:
        severity: critical
    - alert: KubeletClientCertificateRenewalErrors
      annotations:
        description: Kubelet on node {{ $labels.node }} has failed to renew its client certificate ({{ $value | humanize }} errors in the last 5 minutes).
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletclientcertificaterenewalerrors
        summary: Kubelet has failed to renew its client certificate.
      expr: increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeletServerCertificateRenewalErrors
      annotations:
        description: Kubelet on node {{ $labels.node }} has failed to renew its server certificate ({{ $value | humanize }} errors in the last 5 minutes).
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletservercertificaterenewalerrors
        summary: Kubelet has failed to renew its server certificate.
      expr: increase(kubelet_server_expiration_renew_errors[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeletDown
      annotations:
        description: Kubelet has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeletdown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kubelet", metrics_path="/metrics"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system-scheduler.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-system-scheduler
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system-scheduler
    rules:
    - alert: KubeSchedulerDown
      annotations:
        description: KubeScheduler has disappeared from Prometheus target discovery.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeschedulerdown
        summary: Target disappeared from Prometheus target discovery.
      expr: absent(up{job="kube-scheduler"} == 1)
      for: 15m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-system.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-kubernetes-system
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: kubernetes-system
    rules:
    - alert: KubeVersionMismatch
      annotations:
        description: There are {{ $value }} different semantic versions of Kubernetes components running.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeversionmismatch
        summary: Different semantic versions of Kubernetes components running.
      expr: count by (cluster) (count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))) > 1
      for: 15m
      labels:
        severity: warning
    - alert: KubeClientErrors
      annotations:
        description: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/kubernetes/kubeclienterrors
        summary: Kubernetes API server client is experiencing errors.
      expr: |-
        (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (cluster, instance, job, namespace)
          /
        sum(rate(rest_client_requests_total[5m])) by (cluster, instance, job, namespace))
        > 0.01
      for: 15m
      labels:
        severity: warning
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/node-exporter.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-node-exporter.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: node-exporter.rules
    rules:
    - expr: |-
        count without (cpu, mode) (
          node_cpu_seconds_total{job="node-exporter",mode="idle"}
        )
      record: instance:node_num_cpu:sum
    - expr: |-
        1 - avg without (cpu) (
          sum without (mode) (rate(node_cpu_seconds_total{job="node-exporter", mode=~"idle|iowait|steal"}[5m]))
        )
      record: instance:node_cpu_utilisation:rate5m
    - expr: |-
        (
          node_load1{job="node-exporter"}
        /
          instance:node_num_cpu:sum{job="node-exporter"}
        )
      record: instance:node_load1_per_cpu:ratio
    - expr: |-
        1 - (
          (
            node_memory_MemAvailable_bytes{job="node-exporter"}
            or
            (
              node_memory_Buffers_bytes{job="node-exporter"}
              +
              node_memory_Cached_bytes{job="node-exporter"}
              +
              node_memory_MemFree_bytes{job="node-exporter"}
              +
              node_memory_Slab_bytes{job="node-exporter"}
            )
          )
        /
          node_memory_MemTotal_bytes{job="node-exporter"}
        )
      record: instance:node_memory_utilisation:ratio
    - expr: rate(node_vmstat_pgmajfault{job="node-exporter"}[5m])
      record: instance:node_vmstat_pgmajfault:rate5m
    - expr: rate(node_disk_io_time_seconds_total{job="node-exporter", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+)"}[5m])
      record: instance_device:node_disk_io_time_seconds:rate5m
    - expr: rate(node_disk_io_time_weighted_seconds_total{job="node-exporter", device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+)"}[5m])
      record: instance_device:node_disk_io_time_weighted_seconds:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_receive_bytes_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_receive_bytes_excluding_lo:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_transmit_bytes_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_transmit_bytes_excluding_lo:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_receive_drop_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_receive_drop_excluding_lo:rate5m
    - expr: |-
        sum without (device) (
          rate(node_network_transmit_drop_total{job="node-exporter", device!="lo"}[5m])
        )
      record: instance:node_network_transmit_drop_excluding_lo:rate5m
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/node-exporter.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-node-exporter
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: node-exporter
    rules:
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemspacefillingup
        summary: Filesystem is predicted to run out of space within the next 24 hours.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 15
        and
          predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h], 24*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up fast.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemspacefillingup
        summary: Filesystem is predicted to run out of space within the next 4 hours.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 10
        and
          predict_linear(node_filesystem_avail_bytes{job="node-exporter",fstype!=""}[6h], 4*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutofspace
        summary: Filesystem has less than 5% space left.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 5
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 30m
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutofspace
        summary: Filesystem has less than 3% space left.
      expr: |-
        (
          node_filesystem_avail_bytes{job="node-exporter",fstype!=""} / node_filesystem_size_bytes{job="node-exporter",fstype!=""} * 100 < 3
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 30m
      labels:
        severity: critical
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemfilesfillingup
        summary: Filesystem is predicted to run out of inodes within the next 24 hours.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 40
        and
          predict_linear(node_filesystem_files_free{job="node-exporter",fstype!=""}[6h], 24*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up fast.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemfilesfillingup
        summary: Filesystem is predicted to run out of inodes within the next 4 hours.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 20
        and
          predict_linear(node_filesystem_files_free{job="node-exporter",fstype!=""}[6h], 4*60*60) < 0
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutoffiles
        summary: Filesystem has less than 5% inodes left.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 5
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefilesystemalmostoutoffiles
        summary: Filesystem has less than 3% inodes left.
      expr: |-
        (
          node_filesystem_files_free{job="node-exporter",fstype!=""} / node_filesystem_files{job="node-exporter",fstype!=""} * 100 < 3
        and
          node_filesystem_readonly{job="node-exporter",fstype!=""} == 0
        )
      for: 1h
      labels:
        severity: critical
    - alert: NodeNetworkReceiveErrs
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodenetworkreceiveerrs
        summary: Network interface is reporting many receive errors.
      expr: rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m]) > 0.01
      for: 1h
      labels:
        severity: warning
    - alert: NodeNetworkTransmitErrs
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodenetworktransmiterrs
        summary: Network interface is reporting many transmit errors.
      expr: rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m]) > 0.01
      for: 1h
      labels:
        severity: warning
    - alert: NodeHighNumberConntrackEntriesUsed
      annotations:
        description: '{{ $value | humanizePercentage }} of conntrack entries are used.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodehighnumberconntrackentriesused
        summary: Number of conntrack are getting close to the limit.
      expr: (node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75
      labels:
        severity: warning
    - alert: NodeTextFileCollectorScrapeError
      annotations:
        description: Node Exporter text file collector failed to scrape.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodetextfilecollectorscrapeerror
        summary: Node Exporter text file collector failed to scrape.
      expr: node_textfile_scrape_error{job="node-exporter"} == 1
      labels:
        severity: warning
    - alert: NodeClockSkewDetected
      annotations:
        description: Clock on {{ $labels.instance }} is out of sync by more than 300s. Ensure NTP is configured correctly on this host.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodeclockskewdetected
        summary: Clock skew detected.
      expr: |-
        (
          node_timex_offset_seconds{job="node-exporter"} > 0.05
        and
          deriv(node_timex_offset_seconds{job="node-exporter"}[5m]) >= 0
        )
        or
        (
          node_timex_offset_seconds{job="node-exporter"} < -0.05
        and
          deriv(node_timex_offset_seconds{job="node-exporter"}[5m]) <= 0
        )
      for: 10m
      labels:
        severity: warning
    - alert: NodeClockNotSynchronising
      annotations:
        description: Clock on {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodeclocknotsynchronising
        summary: Clock not synchronising.
      expr: |-
        min_over_time(node_timex_sync_status{job="node-exporter"}[5m]) == 0
        and
        node_timex_maxerror_seconds{job="node-exporter"} >= 16
      for: 10m
      labels:
        severity: warning
    - alert: NodeRAIDDegraded
      annotations:
        description: RAID array '{{ $labels.device }}' on {{ $labels.instance }} is in degraded state due to one or more disks failures. Number of spare drives is insufficient to fix issue automatically.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/noderaiddegraded
        summary: RAID Array is degraded
      expr: node_md_disks_required{job="node-exporter",device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+)"} - ignoring (state) (node_md_disks{state="active",job="node-exporter",device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+)"}) > 0
      for: 15m
      labels:
        severity: critical
    - alert: NodeRAIDDiskFailure
      annotations:
        description: At least one device in RAID array on {{ $labels.instance }} failed. Array '{{ $labels.device }}' needs attention and possibly a disk swap.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/noderaiddiskfailure
        summary: Failed device in RAID array
      expr: node_md_disks{state="failed",job="node-exporter",device=~"(/dev/)?(mmcblk.p.+|nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+)"} > 0
      labels:
        severity: warning
    - alert: NodeFileDescriptorLimit
      annotations:
        description: File descriptors limit at {{ $labels.instance }} is currently at {{ printf "%.2f" $value }}%.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefiledescriptorlimit
        summary: Kernel is predicted to exhaust file descriptors limit soon.
      expr: |-
        (
          node_filefd_allocated{job="node-exporter"} * 100 / node_filefd_maximum{job="node-exporter"} > 70
        )
      for: 15m
      labels:
        severity: warning
    - alert: NodeFileDescriptorLimit
      annotations:
        description: File descriptors limit at {{ $labels.instance }} is currently at {{ printf "%.2f" $value }}%.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodefiledescriptorlimit
        summary: Kernel is predicted to exhaust file descriptors limit soon.
      expr: |-
        (
          node_filefd_allocated{job="node-exporter"} * 100 / node_filefd_maximum{job="node-exporter"} > 90
        )
      for: 15m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/node-network.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-node-network
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: node-network
    rules:
    - alert: NodeNetworkInterfaceFlapping
      annotations:
        description: Network interface "{{ $labels.device }}" changing its up status often on node-exporter {{ $labels.namespace }}/{{ $labels.pod }}
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/general/nodenetworkinterfaceflapping
        summary: Network interface is often changing its status
      expr: changes(node_network_up{job="node-exporter",device!~"veth.+"}[2m]) > 2
      for: 2m
      labels:
        severity: warning
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/node.rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-node.rules
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: node.rules
    rules:
    - expr: |-
        topk by(cluster, namespace, pod) (1,
          max by (cluster, node, namespace, pod) (
            label_replace(kube_pod_info{job="kube-state-metrics",node!=""}, "pod", "$1", "pod", "(.*)")
        ))
      record: 'node_namespace_pod:kube_pod_info:'
    - expr: |-
        count by (cluster, node) (sum by (node, cpu) (
          node_cpu_seconds_total{job="node-exporter"}
        * on (namespace, pod) group_left(node)
          topk by(namespace, pod) (1, node_namespace_pod:kube_pod_info:)
        ))
      record: node:node_num_cpu:sum
    - expr: |-
        sum(
          node_memory_MemAvailable_bytes{job="node-exporter"} or
          (
            node_memory_Buffers_bytes{job="node-exporter"} +
            node_memory_Cached_bytes{job="node-exporter"} +
            node_memory_MemFree_bytes{job="node-exporter"} +
            node_memory_Slab_bytes{job="node-exporter"}
          )
        ) by (cluster)
      record: :node_memory_MemAvailable_bytes:sum
    - expr: |-
        sum(rate(node_cpu_seconds_total{job="node-exporter",mode!="idle",mode!="iowait",mode!="steal"}[5m])) /
        count(sum(node_cpu_seconds_total{job="node-exporter"}) by (cluster, instance, cpu))
      record: cluster:node_cpu:ratio_rate5m
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/prometheus-operator.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-prometheus-operator
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: prometheus-operator
    rules:
    - alert: PrometheusOperatorListErrors
      annotations:
        description: Errors while performing List operations in controller {{$labels.controller}} in {{$labels.namespace}} namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorlisterrors
        summary: Errors while performing list operations in controller.
      expr: (sum by (controller,namespace) (rate(prometheus_operator_list_operations_failed_total{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[10m])) / sum by (controller,namespace) (rate(prometheus_operator_list_operations_total{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[10m]))) > 0.4
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusOperatorWatchErrors
      annotations:
        description: Errors while performing watch operations in controller {{$labels.controller}} in {{$labels.namespace}} namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorwatcherrors
        summary: Errors while performing watch operations in controller.
      expr: (sum by (controller,namespace) (rate(prometheus_operator_watch_operations_failed_total{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m])) / sum by (controller,namespace) (rate(prometheus_operator_watch_operations_total{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m]))) > 0.4
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusOperatorSyncFailed
      annotations:
        description: Controller {{ $labels.controller }} in {{ $labels.namespace }} namespace fails to reconcile {{ $value }} objects.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorsyncfailed
        summary: Last controller reconciliation failed
      expr: min_over_time(prometheus_operator_syncs{status="failed",job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m]) > 0
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorReconcileErrors
      annotations:
        description: '{{ $value | humanizePercentage }} of reconciling operations failed for {{ $labels.controller }} controller in {{ $labels.namespace }} namespace.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorreconcileerrors
        summary: Errors while reconciling controller.
      expr: (sum by (controller,namespace) (rate(prometheus_operator_reconcile_errors_total{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m]))) / (sum by (controller,namespace) (rate(prometheus_operator_reconcile_operations_total{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m]))) > 0.1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorNodeLookupErrors
      annotations:
        description: Errors while reconciling Prometheus in {{ $labels.namespace }} Namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatornodelookuperrors
        summary: Errors while reconciling Prometheus.
      expr: rate(prometheus_operator_node_address_lookup_errors_total{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m]) > 0.1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorNotReady
      annotations:
        description: Prometheus operator in {{ $labels.namespace }} namespace isn't ready to reconcile {{ $labels.controller }} resources.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatornotready
        summary: Prometheus operator not ready
      expr: min by (controller,namespace) (max_over_time(prometheus_operator_ready{job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m]) == 0)
      for: 5m
      labels:
        severity: warning
    - alert: PrometheusOperatorRejectedResources
      annotations:
        description: Prometheus operator in {{ $labels.namespace }} namespace rejected {{ printf "%0.0f" $value }} {{ $labels.controller }}/{{ $labels.resource }} resources.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorrejectedresources
        summary: Resources rejected by Prometheus operator
      expr: min_over_time(prometheus_operator_managed_resources{state="rejected",job="sumologic-kube-prometheus-operator",namespace="monitoring"}[5m]) > 0
      for: 5m
      labels:
        severity: warning
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/prometheus.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: sumologic-kube-prometheus-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  groups:
  - name: prometheus
    rules:
    - alert: PrometheusBadConfig
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed to reload its configuration.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusbadconfig
        summary: Failed Prometheus configuration reload.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        max_over_time(prometheus_config_last_reload_successful{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) == 0
      for: 10m
      labels:
        severity: critical
    - alert: PrometheusNotificationQueueRunningFull
      annotations:
        description: Alert notification queue of Prometheus {{$labels.namespace}}/{{$labels.pod}} is running full.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusnotificationqueuerunningfull
        summary: Prometheus alert notification queue predicted to run full in less than 30m.
      expr: |-
        # Without min_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        (
          predict_linear(prometheus_notifications_queue_length{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m], 60 * 30)
        >
          min_over_time(prometheus_notifications_queue_capacity{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m])
        )
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusErrorSendingAlertsToSomeAlertmanagers
      annotations:
        description: '{{ printf "%.1f" $value }}% errors while sending alerts from Prometheus {{$labels.namespace}}/{{$labels.pod}} to Alertmanager {{$labels.alertmanager}}.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheuserrorsendingalertstosomealertmanagers
        summary: Prometheus has encountered more than 1% errors sending alerts to a specific Alertmanager.
      expr: |-
        (
          rate(prometheus_notifications_errors_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m])
        /
          rate(prometheus_notifications_sent_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m])
        )
        * 100
        > 1
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusNotConnectedToAlertmanagers
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is not connected to any Alertmanagers.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusnotconnectedtoalertmanagers
        summary: Prometheus is not connected to any Alertmanagers.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        max_over_time(prometheus_notifications_alertmanagers_discovered{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) < 1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusTSDBReloadsFailing
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected {{$value | humanize}} reload failures over the last 3h.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheustsdbreloadsfailing
        summary: Prometheus has issues reloading blocks from disk.
      expr: increase(prometheus_tsdb_reloads_failures_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[3h]) > 0
      for: 4h
      labels:
        severity: warning
    - alert: PrometheusTSDBCompactionsFailing
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has detected {{$value | humanize}} compaction failures over the last 3h.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheustsdbcompactionsfailing
        summary: Prometheus has issues compacting blocks.
      expr: increase(prometheus_tsdb_compactions_failed_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[3h]) > 0
      for: 4h
      labels:
        severity: warning
    - alert: PrometheusNotIngestingSamples
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is not ingesting samples.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusnotingestingsamples
        summary: Prometheus is not ingesting samples.
      expr: |-
        (
          rate(prometheus_tsdb_head_samples_appended_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) <= 0
        and
          (
            sum without(scrape_job) (prometheus_target_metadata_cache_entries{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}) > 0
          or
            sum without(rule_group) (prometheus_rule_group_rules{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}) > 0
          )
        )
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusDuplicateTimestamps
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is dropping {{ printf "%.4g" $value  }} samples/s with different values but duplicated timestamp.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusduplicatetimestamps
        summary: Prometheus is dropping samples with duplicate timestamps.
      expr: rate(prometheus_target_scrapes_sample_duplicate_timestamp_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOutOfOrderTimestamps
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} is dropping {{ printf "%.4g" $value  }} samples/s with timestamps arriving out of order.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusoutofordertimestamps
        summary: Prometheus drops samples with out-of-order timestamps.
      expr: rate(prometheus_target_scrapes_sample_out_of_order_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusRemoteStorageFailures
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} failed to send {{ printf "%.1f" $value }}% of the samples to {{ $labels.remote_name}}:{{ $labels.url }}
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusremotestoragefailures
        summary: Prometheus fails to send samples to remote storage.
      expr: |-
        (
          (rate(prometheus_remote_storage_failed_samples_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) or rate(prometheus_remote_storage_samples_failed_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]))
        /
          (
            (rate(prometheus_remote_storage_failed_samples_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) or rate(prometheus_remote_storage_samples_failed_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]))
          +
            (rate(prometheus_remote_storage_succeeded_samples_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) or rate(prometheus_remote_storage_samples_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]))
          )
        )
        * 100
        > 1
      for: 15m
      labels:
        severity: critical
    - alert: PrometheusRemoteWriteBehind
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} remote write is {{ printf "%.1f" $value }}s behind for {{ $labels.remote_name}}:{{ $labels.url }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusremotewritebehind
        summary: Prometheus remote write is behind.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        (
          max_over_time(prometheus_remote_storage_highest_timestamp_in_seconds{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m])
        - ignoring(remote_name, url) group_right
          max_over_time(prometheus_remote_storage_queue_highest_sent_timestamp_seconds{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m])
        )
        > 120
      for: 15m
      labels:
        severity: critical
    - alert: PrometheusRemoteWriteDesiredShards
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} remote write desired shards calculation wants to run {{ $value }} shards for queue {{ $labels.remote_name}}:{{ $labels.url }}, which is more than the max of {{ printf `prometheus_remote_storage_shards_max{instance="%s",job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}` $labels.instance | query | first | value }}.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusremotewritedesiredshards
        summary: Prometheus remote write desired shards calculation wants to run more than configured max shards.
      expr: |-
        # Without max_over_time, failed scrapes could create false negatives, see
        # https://www.robustperception.io/alerting-on-gauges-in-prometheus-2-0 for details.
        (
          max_over_time(prometheus_remote_storage_shards_desired{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m])
        >
          max_over_time(prometheus_remote_storage_shards_max{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m])
        )
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusRuleFailures
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed to evaluate {{ printf "%.0f" $value }} rules in the last 5m.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusrulefailures
        summary: Prometheus is failing rule evaluations.
      expr: increase(prometheus_rule_evaluation_failures_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: critical
    - alert: PrometheusMissingRuleEvaluations
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has missed {{ printf "%.0f" $value }} rule group evaluations in the last 5m.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusmissingruleevaluations
        summary: Prometheus is missing rule evaluations due to slow rule group evaluation.
      expr: increase(prometheus_rule_group_iterations_missed_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusTargetLimitHit
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has dropped {{ printf "%.0f" $value }} targets because the number of targets exceeded the configured target_limit.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheustargetlimithit
        summary: Prometheus has dropped targets because some scrape configs have exceeded the targets limit.
      expr: increase(prometheus_target_scrape_pool_exceeded_target_limit_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusLabelLimitHit
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has dropped {{ printf "%.0f" $value }} targets because some samples exceeded the configured label_limit, label_name_length_limit or label_value_length_limit.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheuslabellimithit
        summary: Prometheus has dropped targets because some scrape configs have exceeded the labels limit.
      expr: increase(prometheus_target_scrape_pool_exceeded_label_limits_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusScrapeBodySizeLimitHit
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed {{ printf "%.0f" $value }} scrapes in the last 5m because some targets exceeded the configured body_size_limit.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusscrapebodysizelimithit
        summary: Prometheus has dropped some targets that exceeded body size limit.
      expr: increase(prometheus_target_scrapes_exceeded_body_size_limit_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusScrapeSampleLimitHit
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} has failed {{ printf "%.0f" $value }} scrapes in the last 5m because some targets exceeded the configured sample_limit.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheusscrapesamplelimithit
        summary: Prometheus has failed scrapes that have exceeded the configured sample limit.
      expr: increase(prometheus_target_scrapes_exceeded_sample_limit_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusTargetSyncFailure
      annotations:
        description: '{{ printf "%.0f" $value }} targets in Prometheus {{$labels.namespace}}/{{$labels.pod}} have failed to sync because invalid configuration was supplied.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheustargetsyncfailure
        summary: Prometheus has failed to sync targets.
      expr: increase(prometheus_target_sync_failed_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[30m]) > 0
      for: 5m
      labels:
        severity: critical
    - alert: PrometheusHighQueryLoad
      annotations:
        description: Prometheus {{$labels.namespace}}/{{$labels.pod}} query API has less than 20% available capacity in its query engine for the last 15 minutes.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheushighqueryload
        summary: Prometheus is reaching its maximum capacity serving concurrent requests.
      expr: avg_over_time(prometheus_engine_queries{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) / max_over_time(prometheus_engine_queries_concurrent_max{job="sumologic-kube-prometheus-prometheus",namespace="monitoring"}[5m]) > 0.8
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusErrorSendingAlertsToAnyAlertmanager
      annotations:
        description: '{{ printf "%.1f" $value }}% minimum errors while sending alerts from Prometheus {{$labels.namespace}}/{{$labels.pod}} to any Alertmanager.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus/prometheuserrorsendingalertstoanyalertmanager
        summary: Prometheus encounters more than 3% errors sending alerts to any Alertmanager.
      expr: |-
        min without (alertmanager) (
          rate(prometheus_notifications_errors_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring",alertmanager!~``}[5m])
        /
          rate(prometheus_notifications_sent_total{job="sumologic-kube-prometheus-prometheus",namespace="monitoring",alertmanager!~``}[5m])
        )
        * 100
        > 3
      for: 15m
      labels:
        severity: critical
---
# Source: sumologic/charts/kube-prometheus-stack/charts/kube-state-metrics/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-state-metrics
  namespace: monitoring
  labels:
    helm.sh/chart: kube-state-metrics-4.20.2
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: kube-state-metrics
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "2.6.0"
    release: sumologic
spec:
  jobLabel: app.kubernetes.io/name
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/instance: sumologic
  endpoints:
    - port: http
      honorLabels: true
---
# Source: sumologic/charts/kube-prometheus-stack/charts/prometheus-node-exporter/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-prometheus-node-exporter
  namespace: monitoring
  labels:
    helm.sh/chart: prometheus-node-exporter-4.3.0
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: metrics
    app.kubernetes.io/part-of: prometheus-node-exporter
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/name: prometheus-node-exporter
    app.kubernetes.io/version: "1.3.1"
    jobLabel: node-exporter
    release: sumologic
spec:
  jobLabel: jobLabel
  selector:
    matchLabels:

      app.kubernetes.io/instance: sumologic
      app.kubernetes.io/name: prometheus-node-exporter
  endpoints:
    - port: http-metrics
      scheme: http
---
# Source: sumologic/charts/kube-prometheus-stack/templates/exporters/core-dns/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-coredns
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-coredns

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  selector:
    matchLabels:
      app: kube-prometheus-stack-coredns
      release: "sumologic"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    metricRelabelings:
    - action: keep
      regex: (?:coredns_cache_(size|entries|(hits|misses)_total)|coredns_dns_request_duration_seconds_(count|sum)|coredns_(dns_request|dns_response_rcode|forward_request)_count_total|coredns_(forward_requests|dns_requests|dns_responses)_total|process_(cpu_seconds_total|open_fds|resident_memory_bytes))
      sourceLabels:
      - __name__
---
# Source: sumologic/charts/kube-prometheus-stack/templates/exporters/kube-api-server/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-apiserver
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-apiserver

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    port: https
    scheme: https
    metricRelabelings:
      - action: keep
        regex: (?:apiserver_request_(?:count|total)|apiserver_request_(?:duration_seconds|latencies)_(?:count|sum)|apiserver_request_latencies_summary(?:|_count|_sum)|apiserver_request_duration_seconds_bucket)
        sourceLabels:
        - __name__
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      serverName: kubernetes
      insecureSkipVerify: false
  jobLabel: component
  namespaceSelector:
    matchNames:
    - default
  selector:
    matchLabels:
      component: apiserver
      provider: kubernetes
---
# Source: sumologic/charts/kube-prometheus-stack/templates/exporters/kube-controller-manager/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-kube-controller-manager
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-controller-manager

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-controller-manager
      release: "sumologic"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    scheme: https
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
    metricRelabelings:
    - action: keep
      regex: (?:cloudprovider_.*_api_request_duration_seconds.*)
      sourceLabels:
      - __name__
---
# Source: sumologic/charts/kube-prometheus-stack/templates/exporters/kube-etcd/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-kube-etcd
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-etcd

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-etcd
      release: "sumologic"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    metricRelabelings:
    - action: keep
      regex: (?:etcd_request_cache_(?:add|get)_(?:duration_seconds|latencies_summary)_(?:count|sum)|etcd_helper_cache_(?:hit|miss)_(?:count|total)|etcd_debugging_(mvcc_db_total_size_in_bytes|store_(expires_total|watchers))|etcd_disk_(backend_commit|wal_fsync)_duration_seconds_bucket|etcd_grpc_proxy_cache_(hits|misses)_total|etcd_network_client_grpc_(received|sent)_bytes_total|etcd_server_(has_leader|leader_changes_seen_total)|etcd_server_proposals_(pending|(applied|committed|failed)_total)|process_(cpu_seconds_total|open_fds|resident_memory_bytes))
      sourceLabels:
      - __name__
---
# Source: sumologic/charts/kube-prometheus-stack/templates/exporters/kube-proxy/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-kube-proxy
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-proxy

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-proxy
      release: "sumologic"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
---
# Source: sumologic/charts/kube-prometheus-stack/templates/exporters/kube-scheduler/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-kube-scheduler
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kube-scheduler

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  jobLabel: jobLabel
  selector:
    matchLabels:
      app: kube-prometheus-stack-kube-scheduler
      release: "sumologic"
  namespaceSelector:
    matchNames:
      - "kube-system"
  endpoints:
  - port: http-metrics
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    scheme: https
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
    metricRelabelings:
    - action: keep
      regex: (?:scheduler_(?:e2e_scheduling|binding|framework_extension_point|scheduling_algorithm)_duration_seconds.*)
      sourceLabels:
      - __name__
---
# Source: sumologic/charts/kube-prometheus-stack/templates/exporters/kubelet/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-kubelet
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-kubelet
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  endpoints:
  - port: https-metrics
    scheme: https
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    honorLabels: true
    metricRelabelings:
    - action: keep
      regex: (?:kubelet_docker_operations_errors(?:|_total)|kubelet_(?:docker|runtime)_operations_duration_seconds_(?:count|sum)|kubelet_running_(?:container|pod)(?:_count|s)|kubelet_(:?docker|runtime)_operations_latency_microseconds(?:|_count|_sum))
      sourceLabels:
      - __name__
    - action: labeldrop
      regex: id
    relabelings:
    - sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
  - port: https-metrics
    scheme: https
    path: /metrics/cadvisor
    honorLabels: true
    tlsConfig:
      caFile: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      insecureSkipVerify: true
    bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    metricRelabelings:
    - action: keep
      regex: (?:container_cpu_usage_seconds_total|container_memory_working_set_bytes|container_fs_usage_bytes|container_fs_limit_bytes|container_cpu_cfs_throttled_seconds_total|container_network_receive_bytes_total|container_network_transmit_bytes_total)
      sourceLabels:
      - __name__
    - action: labelmap
      regex: container_name
      replacement: container
    - action: drop
      regex: POD
      sourceLabels:
      - container
    - action: labeldrop
      regex: (id|name)
    relabelings:
    - sourceLabels:
      - __metrics_path__
      targetLabel: metrics_path
  jobLabel: k8s-app
  namespaceSelector:
    matchNames:
    - kube-system
  selector:
    matchLabels:
      app.kubernetes.io/name: kubelet
      k8s-app: kubelet
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus-operator/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-operator
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-operator

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  endpoints:
  - port: http
    honorLabels: true
  selector:
    matchLabels:
      app: kube-prometheus-stack-operator
      release: "sumologic"
  namespaceSelector:
    matchNames:
      - "monitoring"
---
# Source: sumologic/charts/kube-prometheus-stack/templates/prometheus/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumologic-kube-prometheus-prometheus
  namespace: monitoring
  labels:
    app: kube-prometheus-stack-prometheus

    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: sumologic
    app.kubernetes.io/version: "40.5.0"
    app.kubernetes.io/part-of: kube-prometheus-stack
    chart: kube-prometheus-stack-40.5.0
    release: "sumologic"
    heritage: "Helm"
spec:
  selector:
    matchLabels:
      app: kube-prometheus-stack-prometheus
      release: "sumologic"
      self-monitor: "true"
  namespaceSelector:
    matchNames:
      - "monitoring"
  endpoints:
  - port: http-web
    path: "/metrics"
---
# Source: sumologic/templates/setup/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name:  sumologic-sumologic-setup
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "0"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
---
# Source: sumologic/templates/setup/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name:  sumologic-sumologic-setup
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "2"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
  custom.sh: |
    #!/bin/bash
    #
    # This script copies files from /customer-scripts to /scripts/<dirname> basing on the filename
    #
    # Example file structure:
    #
    # /customer-scripts
    #  dir1_main.tf
    #  dir1_setup.sh
    #  dir2_list.txt
    #  dir2_setup.sh
    #
    # Expected structure:
    #
    # /scripts
    #  dir1
    #     main.tf
    #     setup.sh
    #  dir2
    #      list.txt
    #      setup.sh
    #
    # shellcheck disable=SC2010
    # extract target directory names from the file names using _ as separator

    set -euo pipefail

    err_report() {
        echo "Custom script error on line $1"
        exit 1
    }
    trap 'err_report $LINENO' ERR

    declare -a dirs
    ls -1 /customer-scripts 2>/dev/null | grep _ | grep -oE '^.*?_' | sed 's/_//g' | sort | uniq | read -ar dirs || true
    for dir in "${dirs[@]}"; do
      target="/scripts/${dir}"
      mkdir "${target}"
      # Get files for given directory and take only filename part (after first _)
      declare -a files
      ls -1 /customer-scripts 2>/dev/null | grep _ | grep -oE '^.*?_' | sed 's/_//g' | sort | uniq | read -ar files || true
      for file in "${files[@]}"; do
        cp "/customer-scripts/${dir}_${file}" "${target}/${file}"
      done

      if [[ ! -f setup.sh ]]; then
        echo "You're missing setup.sh script in custom scripts directory: '${dir}'"
        continue
      fi

      cd "${target}" && bash setup.sh
    done
  dashboards.sh: |
    #!/bin/bash

    set -euo pipefail

    SUMOLOGIC_ACCESSID=${SUMOLOGIC_ACCESSID:=""}
    readonly SUMOLOGIC_ACCESSID
    SUMOLOGIC_ACCESSKEY=${SUMOLOGIC_ACCESSKEY:=""}
    readonly SUMOLOGIC_ACCESSKEY
    SUMOLOGIC_BASE_URL=${SUMOLOGIC_BASE_URL:=""}
    readonly SUMOLOGIC_BASE_URL

    INTEGRATIONS_FOLDER_NAME="Sumo Logic Integrations"
    K8S_FOLDER_NAME="Kubernetes"
    K8S_APP_UUID="162ceac7-166a-4475-8427-65e170ae9837"

    function load_dashboards_folder_id() {
      local ADMIN_FOLDER_JOB_ID
      ADMIN_FOLDER_JOB_ID="$(curl -XGET -s \
              -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
              -H "isAdminMode: true" \
              "${SUMOLOGIC_BASE_URL}"v2/content/folders/adminRecommended | jq '.id' | tr -d '"' )"
      readonly ADMIN_FOLDER_JOB_ID

      local ADMIN_FOLDER_JOB_STATUS
      ADMIN_FOLDER_JOB_STATUS="InProgress"
      while [[ "${ADMIN_FOLDER_JOB_STATUS}" = "InProgress" ]]; do
        ADMIN_FOLDER_JOB_STATUS="$(curl -XGET -s \
              -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
              "${SUMOLOGIC_BASE_URL}"v2/content/folders/adminRecommended/"${ADMIN_FOLDER_JOB_ID}"/status | jq '.status' | tr -d '"' )"

        sleep 1
      done

      if [[ "${ADMIN_FOLDER_JOB_STATUS}" != "Success" ]]; then
        echo "Could not fetch data from the \"Admin Recommended\" content folder. The K8s Dashboards won't be installed."
        echo "You can still install them manually:"
        echo "https://help.sumologic.com/docs/integrations/containers-orchestration/kubernetes#installing-the-kubernetes-app"
        exit 1
      fi

      local ADMIN_FOLDER
      ADMIN_FOLDER="$(curl -XGET -s \
              -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
              -H "isAdminMode: true" \
              "${SUMOLOGIC_BASE_URL}"v2/content/folders/adminRecommended/"${ADMIN_FOLDER_JOB_ID}"/result )"
      readonly ADMIN_FOLDER

      local ADMIN_FOLDER_CHILDREN
      ADMIN_FOLDER_CHILDREN="$( echo "${ADMIN_FOLDER}" | jq '.children[]')"
      readonly ADMIN_FOLDER_CHILDREN

      local ADMIN_FOLDER_ID
      ADMIN_FOLDER_ID="$( echo "${ADMIN_FOLDER}" | jq '.id' | tr -d '"')"
      readonly ADMIN_FOLDER_ID

      INTEGRATIONS_FOLDER_ID="$( echo "${ADMIN_FOLDER_CHILDREN}" | \
                jq -r "select(.name == \"${INTEGRATIONS_FOLDER_NAME}\") | .id" )"

      if [[ -z "${INTEGRATIONS_FOLDER_ID}" ]]; then
        INTEGRATIONS_FOLDER_ID="$(curl -XPOST -s \
                -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
                -H "isAdminMode: true" \
                -H "Content-Type: application/json" \
                -d "{\"name\":\"${INTEGRATIONS_FOLDER_NAME}\",\"parentId\":\"${ADMIN_FOLDER_ID}\",\"description\":\"Content provided by the Sumo Logic integrations.\"}" \
                "${SUMOLOGIC_BASE_URL}"v2/content/folders | \
                jq -r " .id" )"
      fi

      local INTEGRATIONS_FOLDER_CHILDREN
      INTEGRATIONS_FOLDER_CHILDREN="$(curl -XGET -s \
                -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
                -H "isAdminMode: true" \
                "${SUMOLOGIC_BASE_URL}"v2/content/folders/"${INTEGRATIONS_FOLDER_ID}" | \
                jq '.children[]')"
      readonly INTEGRATIONS_FOLDER_CHILDREN

      K8S_FOLDER_ID="$( echo "${INTEGRATIONS_FOLDER_CHILDREN}" | \
                jq -r "select(.name == \"${K8S_FOLDER_NAME}\") | .id" )"
    }

    load_dashboards_folder_id

    if [[ -z "${K8S_FOLDER_ID}" ]]; then
      APP_INSTALL_JOB_RESPONSE="$(curl -XPOST -s \
             -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
             -H "isAdminMode: true" \
             -H "Content-Type: application/json" \
             -d "{\"name\":\"${K8S_FOLDER_NAME}\",\"destinationFolderId\":\"${INTEGRATIONS_FOLDER_ID}\",\"description\":\"Kubernetes dashboards provided by Sumo Logic.\"}" \
             "${SUMOLOGIC_BASE_URL}"v1/apps/"${K8S_APP_UUID}"/install )"
      readonly APP_INSTALL_JOB_RESPONSE

      APP_INSTALL_JOB_ID="$(echo "${APP_INSTALL_JOB_RESPONSE}" | jq '.id' | tr -d '"' )"
      readonly APP_INSTALL_JOB_ID

      APP_INSTALL_JOB_STATUS="InProgress"
      while [[ "${APP_INSTALL_JOB_STATUS}" = "InProgress" ]]; do
        APP_INSTALL_JOB_STATUS="$(curl -XGET -s \
              -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
              "${SUMOLOGIC_BASE_URL}"v1/apps/install/"${APP_INSTALL_JOB_ID}"/status | jq '.status' | tr -d '"' )"

        sleep 1
      done

      if [[ "${APP_INSTALL_JOB_STATUS}" != "Success" ]]; then
        ERROR_MSG="$(curl -XGET -s \
              -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
              "${SUMOLOGIC_BASE_URL}"v1/apps/install/"${APP_INSTALL_JOB_ID}"/status )"
        echo "${ERROR_MSG}"

        echo "Installation of the K8s Dashboards failed."
        echo "You can still install them manually:"
        echo "https://help.sumologic.com/docs/integrations/containers-orchestration/kubernetes#installing-the-kubernetes-app"
        exit 2
      else
        load_dashboards_folder_id

        ORG_ID="$(curl -XGET -s \
                -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
                "${SUMOLOGIC_BASE_URL}"v1/account/contract | jq '.orgId' | tr -d '"' )"
        readonly ORG_ID

        PERMS_ERRORS=$( curl -XPUT -s \
          -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
          -H "isAdminMode: true" \
          -H "Content-Type: application/json" \
          -d "{\"contentPermissionAssignments\": [{\"permissionName\": \"View\",\"sourceType\": \"org\",\"sourceId\": \"${ORG_ID}\",\"contentId\": \"${K8S_FOLDER_ID}\"}],\"notifyRecipients\":false,\"notificationMessage\":\"\"}" \
          "${SUMOLOGIC_BASE_URL}"v2/content/"${K8S_FOLDER_ID}"/permissions/add | jq '.errors' )
        readonly PERMS_ERRORS

        if [[ "${PERMS_ERRORS}" != "null" ]]; then
          echo "Setting permissions for the installed content failed."
          echo "${PERMS_ERRORS}"
        fi

        echo "Installation of the K8s Dashboards succeeded."
      fi
    else
      echo "The K8s Dashboards have been already installed."
      echo "You can (re)install them manually with:"
      echo "https://help.sumologic.com/docs/integrations/containers-orchestration/kubernetes#installing-the-kubernetes-app"
    fi
  fields.tf: |
    resource "sumologic_field" "cluster" {
      count = var.create_fields ? 1 : 0

      field_name = "cluster"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "container" {
      count = var.create_fields ? 1 : 0

      field_name = "container"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "daemonset" {
      count = var.create_fields ? 1 : 0

      field_name = "daemonset"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "deployment" {
      count = var.create_fields ? 1 : 0

      field_name = "deployment"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "host" {
      count = var.create_fields ? 1 : 0

      field_name = "host"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "namespace" {
      count = var.create_fields ? 1 : 0

      field_name = "namespace"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "node" {
      count = var.create_fields ? 1 : 0

      field_name = "node"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "pod" {
      count = var.create_fields ? 1 : 0

      field_name = "pod"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "service" {
      count = var.create_fields ? 1 : 0

      field_name = "service"
      data_type = "String"
      state = "Enabled"
    }
    resource "sumologic_field" "statefulset" {
      count = var.create_fields ? 1 : 0

      field_name = "statefulset"
      data_type = "String"
      state = "Enabled"
    }
  locals.tf: |
    locals {
      default_events_source                       = "events"
      default_logs_source                         = "logs"
      apiserver_metrics_source                    = "apiserver-metrics"
      control_plane_metrics_source                = "control-plane-metrics"
      controller_metrics_source                   = "kube-controller-manager-metrics"
      default_metrics_source                      = "(default-metrics)"
      kubelet_metrics_source                      = "kubelet-metrics"
      node_metrics_source                         = "node-exporter-metrics"
      scheduler_metrics_source                    = "kube-scheduler-metrics"
      state_metrics_source                        = "kube-state-metrics"
      default_traces_source                       = "traces"
    }
  main.tf: |
    terraform {
      required_providers {
        sumologic = {
          source  = "sumologic/sumologic"
          version = "~> 2.18"
        }
        kubernetes = {
          source  = "hashicorp/kubernetes"
          version = "~> 2.4"
        }
      }
    }
  monitors.sh: |
    #!/bin/bash

    SUMOLOGIC_ACCESSID=${SUMOLOGIC_ACCESSID:=""}
    readonly SUMOLOGIC_ACCESSID
    SUMOLOGIC_ACCESSKEY=${SUMOLOGIC_ACCESSKEY:=""}
    readonly SUMOLOGIC_ACCESSKEY
    SUMOLOGIC_BASE_URL=${SUMOLOGIC_BASE_URL:=""}
    readonly SUMOLOGIC_BASE_URL

    INTEGRATIONS_FOLDER_NAME="Sumo Logic Integrations"
    MONITORS_FOLDER_NAME="Kubernetes"
    MONITORS_DISABLED="false"

    MONITORS_ROOT_ID="$(curl -XGET -s \
            -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
            "${SUMOLOGIC_BASE_URL}"v1/monitors/root | jq -r '.id' )"
    readonly MONITORS_ROOT_ID

    # verify if the integrations folder already exists
    INTEGRATIONS_RESPONSE="$(curl -XGET -s -G \
            -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
            "${SUMOLOGIC_BASE_URL}"v1/monitors/search \
            --data-urlencode "query=type:folder ${INTEGRATIONS_FOLDER_NAME}" | \
            jq '.[]' )"
    readonly INTEGRATIONS_RESPONSE

    INTEGRATIONS_FOLDER_ID="$( echo "${INTEGRATIONS_RESPONSE}" | \
            jq -r "select(.item.name == \"${INTEGRATIONS_FOLDER_NAME}\") | select(.item.parentId == \"${MONITORS_ROOT_ID}\") | .item.id" )"

    # and create it if necessary
    if [[ -z "${INTEGRATIONS_FOLDER_ID}" ]]; then
      INTEGRATIONS_FOLDER_ID="$(curl -XPOST -s \
                  -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
                  -H "Content-Type: application/json" \
                  -d "{\"name\":\"${INTEGRATIONS_FOLDER_NAME}\",\"type\":\"MonitorsLibraryFolder\",\"description\":\"Monitors provided by the Sumo Logic integrations.\"}" \
                  "${SUMOLOGIC_BASE_URL}"v1/monitors?parentId="${MONITORS_ROOT_ID}" | \
                  jq -r " .id" )"
    fi

    # verify if the k8s monitors folder already exists
    MONITORS_RESPONSE="$(curl -XGET -s -G \
            -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
            "${SUMOLOGIC_BASE_URL}"v1/monitors/search \
            --data-urlencode "query=type:folder ${MONITORS_FOLDER_NAME}" | \
            jq '.[]' )"
    readonly MONITORS_RESPONSE

    MONITORS_FOLDER_ID="$( echo "${MONITORS_RESPONSE}" | \
            jq -r "select(.item.name == \"${MONITORS_FOLDER_NAME}\") | select(.item.parentId == \"${INTEGRATIONS_FOLDER_ID}\") | .item.id" )"
    readonly MONITORS_FOLDER_ID

    if [[ -z "${MONITORS_FOLDER_ID}" ]]; then
      # go to monitors directory
      cd /monitors || exit 2

      # Fall back to init -upgrade to prevent:
      # Error: Inconsistent dependency lock file
      terraform init -input=false || terraform init -input=false -upgrade

      # extract environment from SUMOLOGIC_BASE_URL
      # see: https://help.sumologic.com/docs/api/getting-started/#sumo-logic-endpoints-by-deployment-and-firewall-security
      SUMOLOGIC_ENV=$( echo "${SUMOLOGIC_BASE_URL}" | sed -E 's/https:\/\/.*(au|ca|de|eu|fed|in|jp|us2)\.sumologic\.com.*/\1/' )
      if [[ "${SUMOLOGIC_BASE_URL}" == "${SUMOLOGIC_ENV}" ]] ; then
        SUMOLOGIC_ENV="us1"
      fi

      TF_LOG_PROVIDER=DEBUG terraform apply \
          -auto-approve \
          -var="access_id=${SUMOLOGIC_ACCESSID}" \
          -var="access_key=${SUMOLOGIC_ACCESSKEY}" \
          -var="environment=${SUMOLOGIC_ENV}" \
          -var="folder=${MONITORS_FOLDER_NAME}" \
          -var="folder_parent_id=${INTEGRATIONS_FOLDER_ID}" \
          -var="monitors_disabled=${MONITORS_DISABLED}" \
          || { echo "Error during applying Terraform monitors."; exit 1; }
    else
      echo "The monitors have been already installed in ${MONITORS_FOLDER_NAME}."
      echo "You can (re)install them manually with:"
      echo "https://github.com/SumoLogic/terraform-sumologic-sumo-logic-monitor/tree/main/monitor_packages/kubernetes"
    fi
  providers.tf: |-
    provider "sumologic" {}

    provider "kubernetes" {

        cluster_ca_certificate    = file("/var/run/secrets/kubernetes.io/serviceaccount/ca.crt")
        host                      = "https://kubernetes.default.svc"
        token                     = file("/var/run/secrets/kubernetes.io/serviceaccount/token")
    }
  resources.tf: |
    resource "sumologic_collector" "collector" {
        name  = var.collector_name
        fields  = {
        }
    }

    resource "sumologic_http_source" "default_events_source" {
        name         = local.default_events_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "default_logs_source" {
        name         = local.default_logs_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "apiserver_metrics_source" {
        name         = local.apiserver_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "control_plane_metrics_source" {
        name         = local.control_plane_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "controller_metrics_source" {
        name         = local.controller_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "default_metrics_source" {
        name         = local.default_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "kubelet_metrics_source" {
        name         = local.kubelet_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "node_metrics_source" {
        name         = local.node_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "scheduler_metrics_source" {
        name         = local.scheduler_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "state_metrics_source" {
        name         = local.state_metrics_source
        collector_id = sumologic_collector.collector.id
    }

    resource "sumologic_http_source" "default_traces_source" {
        name         = local.default_traces_source
        collector_id = sumologic_collector.collector.id
        content_type = "Zipkin"
    }

    resource "kubernetes_secret" "sumologic_collection_secret" {
      metadata {
        name = "sumologic"
        namespace = var.namespace_name
      }

      data = {
        endpoint-events                           = sumologic_http_source.default_events_source.url
        endpoint-logs                             = sumologic_http_source.default_logs_source.url
        endpoint-metrics-apiserver                = sumologic_http_source.apiserver_metrics_source.url
        endpoint-control_plane_metrics_source     = sumologic_http_source.control_plane_metrics_source.url
        endpoint-metrics-kube-controller-manager  = sumologic_http_source.controller_metrics_source.url
        endpoint-metrics                          = sumologic_http_source.default_metrics_source.url
        endpoint-metrics-kubelet                  = sumologic_http_source.kubelet_metrics_source.url
        endpoint-metrics-node-exporter            = sumologic_http_source.node_metrics_source.url
        endpoint-metrics-kube-scheduler           = sumologic_http_source.scheduler_metrics_source.url
        endpoint-metrics-kube-state               = sumologic_http_source.state_metrics_source.url
        endpoint-traces                           = sumologic_http_source.default_traces_source.url
      }

      type = "Opaque"
    }
  setup.sh: |
    #!/bin/bash

    readonly DEBUG_MODE=${DEBUG_MODE:="true"}
    readonly DEBUG_MODE_ENABLED_FLAG="true"

    # Let's compare the variables ignoring the case with help of ${VARIABLE,,} which makes the string lowercased
    # so that we don't have to deal with True vs true vs TRUE
    if [[ ${DEBUG_MODE,,} == "${DEBUG_MODE_ENABLED_FLAG}" ]]; then
        echo "Entering the debug mode with continuous sleep. No setup will be performed."
        echo "Please exec into the setup container and run the setup.sh by hand or set the sumologic.setup.debug=false and reinstall."

        while true; do
            sleep 10
            DATE=$(date)
            echo "${DATE} Sleeping in the debug mode..."
        done
    fi

    function fix_sumo_base_url() {
      local BASE_URL
      BASE_URL=${SUMOLOGIC_BASE_URL}

      if [[ "${BASE_URL}" =~ ^\s*$ ]]; then
        BASE_URL="https://api.sumologic.com/api/"
      fi

      # shellcheck disable=SC2312
      OPTIONAL_REDIRECTION="$(curl -XGET -s -o /dev/null -D - \
              -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
              "${BASE_URL}"v1/collectors \
              | grep -Fi location )"

      if [[ ! ${OPTIONAL_REDIRECTION} =~ ^\s*$ ]]; then
        BASE_URL=$( echo "${OPTIONAL_REDIRECTION}" | sed -E 's/.*: (https:\/\/.*(au|ca|de|eu|fed|in|jp|us2)?\.sumologic\.com\/api\/).*/\1/' )
      fi

      BASE_URL=${BASE_URL%v1*}

      echo "${BASE_URL}"
    }

    SUMOLOGIC_BASE_URL=$(fix_sumo_base_url)
    export SUMOLOGIC_BASE_URL
    # Support proxy for Terraform
    export HTTP_PROXY=${HTTP_PROXY:=""}
    export HTTPS_PROXY=${HTTPS_PROXY:=""}
    export NO_PROXY=${NO_PROXY:=""}

    function get_remaining_fields() {
        local RESPONSE
        RESPONSE="$(curl -XGET -s \
            -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
            "${SUMOLOGIC_BASE_URL}"v1/fields/quota)"
        readonly RESPONSE

        echo "${RESPONSE}"
    }

    # Check if we'd have at least 10 fields remaining after additional fields
    # would be created for the collection
    function should_create_fields() {
        local RESPONSE
        RESPONSE=$(get_remaining_fields)
        readonly RESPONSE

        if ! jq -e <<< "${RESPONSE}" ; then
            printf "Failed requesting fields API:\n%s\n" "${RESPONSE}"
            return 1
        fi

        if ! jq -e '.remaining' <<< "${RESPONSE}" ; then
            printf "Failed requesting fields API:\n%s\n" "${RESPONSE}"
            return 1
        fi

        local REMAINING
        REMAINING=$(jq -e '.remaining' <<< "${RESPONSE}")
        readonly REMAINING
        if [[ $(( REMAINING - 10 )) -ge 10 ]] ; then
            return 0
        else
            return 1
        fi
    }

    cp /etc/terraform/{locals,main,providers,resources,variables,fields}.tf /terraform/
    cd /terraform || exit 1

    # Fall back to init -upgrade to prevent:
    # Error: Inconsistent dependency lock file
    terraform init -input=false -get=false || terraform init -input=false -upgrade

    # Sumo Logic fields
    if should_create_fields ; then
        readonly CREATE_FIELDS=1
        # shellcheck disable=SC2312
        FIELDS_RESPONSE="$(curl -XGET -s \
            -u "${SUMOLOGIC_ACCESSID}:${SUMOLOGIC_ACCESSKEY}" \
            "${SUMOLOGIC_BASE_URL}"v1/fields | jq '.data[]' )"
        readonly FIELDS_RESPONSE

        declare -ra FIELDS=("cluster" "container" "daemonset" "deployment" "host" "namespace" "node" "pod" "service" "statefulset")
        for FIELD in "${FIELDS[@]}" ; do
            FIELD_ID=$( echo "${FIELDS_RESPONSE}" | jq -r "select(.fieldName == \"${FIELD}\") | .fieldId" )
            # Don't try to import non existing fields
            if [[ -z "${FIELD_ID}" ]]; then
                continue
            fi

            terraform import \
                -var="create_fields=1" \
                sumologic_field."${FIELD}" "${FIELD_ID}"
        done
    else
        readonly CREATE_FIELDS=0
        echo "Couldn't automatically create fields"
        echo "You do not have enough field capacity to create the required fields automatically."
        echo "Please refer to https://help.sumologic.com/docs/manage/fields/ to manually create the fields after you have removed unused fields to free up capacity."
    fi

    readonly COLLECTOR_NAME="kubernetes"

    # Sumo Logic Collector and HTTP sources
    # Only import sources when collector exists.
    if terraform import sumologic_collector.collector "${COLLECTOR_NAME}"; then
    true  # prevent to render empty if; then
    terraform import sumologic_http_source.default_events_source "${COLLECTOR_NAME}/events"
    terraform import sumologic_http_source.default_logs_source "${COLLECTOR_NAME}/logs"
    terraform import sumologic_http_source.apiserver_metrics_source "${COLLECTOR_NAME}/apiserver-metrics"
    terraform import sumologic_http_source.control_plane_metrics_source "${COLLECTOR_NAME}/control-plane-metrics"
    terraform import sumologic_http_source.controller_metrics_source "${COLLECTOR_NAME}/kube-controller-manager-metrics"
    terraform import sumologic_http_source.default_metrics_source "${COLLECTOR_NAME}/(default-metrics)"
    terraform import sumologic_http_source.kubelet_metrics_source "${COLLECTOR_NAME}/kubelet-metrics"
    terraform import sumologic_http_source.node_metrics_source "${COLLECTOR_NAME}/node-exporter-metrics"
    terraform import sumologic_http_source.scheduler_metrics_source "${COLLECTOR_NAME}/kube-scheduler-metrics"
    terraform import sumologic_http_source.state_metrics_source "${COLLECTOR_NAME}/kube-state-metrics"
    terraform import sumologic_http_source.default_traces_source "${COLLECTOR_NAME}/traces"
    fi

    # Kubernetes Secret
    terraform import kubernetes_secret.sumologic_collection_secret monitoring/sumologic

    # Apply planned changes
    TF_LOG_PROVIDER=DEBUG terraform apply \
        -auto-approve \
        -var="create_fields=${CREATE_FIELDS}" \
        || { echo "Error during applying Terraform changes"; exit 1; }

    # Setup Sumo Logic monitors if enabled
    bash /etc/terraform/monitors.sh

    # Setup Sumo Logic dashboards if enabled
    bash /etc/terraform/dashboards.sh

    # Cleanup env variables
    export SUMOLOGIC_BASE_URL=
    export SUMOLOGIC_ACCESSKEY=
    export SUMOLOGIC_ACCESSID=

    bash /etc/terraform/custom.sh
  variables.tf: |
    variable "collector_name" {
      type  = string
      default = "kubernetes"
    }

    variable "namespace_name" {
      type  = string
      default = "monitoring"
    }

    variable "create_fields" {
      description = "If set, Terraform will attempt to create fields at Sumo Logic"
      type        = bool
      default     = true
    }
---
# Source: sumologic/templates/setup/custom-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name:  sumologic-sumologic-setup-custom
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "2"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
data:
---
# Source: sumologic/templates/setup/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name:  sumologic-sumologic-setup
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "1"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs: ["get", "list", "describe", "create", "patch"]
---
# Source: sumologic/templates/setup/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name:  sumologic-sumologic-setup
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "2"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: sumologic-sumologic-setup
subjects:
  - kind: ServiceAccount
    name: sumologic-sumologic-setup
    namespace: monitoring
---
# Source: sumologic/templates/setup/job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: sumologic-sumologic-setup
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-weight: "3"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    app: sumologic-sumologic
    chart: "sumologic-3.1.1"
    release: "sumologic"
    heritage: "Helm"
spec:
  template:
    metadata:
      annotations:
      labels:
    spec:
      restartPolicy: OnFailure
      serviceAccountName: sumologic-sumologic-setup
      volumes:
      - name: setup
        configMap:
          name: sumologic-sumologic-setup
          defaultMode: 0777
      - name: custom
        configMap:
          name: sumologic-sumologic-setup-custom
          defaultMode: 0777
      containers:
      - name: setup
        image: public.ecr.aws/sumologic/kubernetes-setup:3.5.0
        imagePullPolicy: IfNotPresent
        command: ["/etc/terraform/setup.sh"]
        resources:
          limits:
            cpu: 2000m
            memory: 256Mi
          requests:
            cpu: 200m
            memory: 64Mi
        volumeMounts:
        - name: setup
          mountPath: /etc/terraform
        - name: custom
          mountPath: /customer-scripts
        envFrom:
        - secretRef:
            name: sumologic-secret
        env:
        - name: SUMOLOGIC_BASE_URL
          value:
        - name: NO_PROXY
          value: kubernetes.default.svc
      securityContext:
        runAsUser: 999
