---
# yaml-language-server: $schema=https://kubernetes-schemas.falhalla.com/helmrelease_v2beta1.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: qbittorrent-vpn
  namespace: downloads
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 1.5.1
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controller:
      type: statefulset
    image:
      repository: ghcr.io/cftechwiz/qbittorrent
      tag: 4.6.7@sha256:c834abe0306712340600659baed52849b983cf8046bd5cfd7e55db2b6f7643fd
    env:
      TZ: America/Chicago
      QBITTORRENT__PORT: &port 80
    service:
      main:
        ports:
          http:
            port: *port
    ingress:
      main:
        enabled: true
        ingressClassName: nginx
        annotations:
          hajimari.io/enabled: "false"
        hosts:
          - host: &host qbvpn.intra.falhalla.com
            paths:
              - path: /
                pathType: Prefix
        tls:
          - hosts:
              - *host
    podSecurityContext:
      runAsUser: 568
      runAsGroup: 568
      fsGroup: 568
      fsGroupChangePolicy: "OnRootMismatch"
      supplementalGroups: [100]
    volumeClaimTemplates:
      - name: config
        mountPath: /config
        accessMode: ReadWriteOnce
        size: 1Gi
        storageClass: ceph-block
    podAnnotations:
      setGateway: "true"
    persistence:
      downloads:
        enabled: true
        type: nfs
        server: falhallanas.lab
        path: /nfs/Downloads
        mountPath: /downloads
      media:
        enabled: true
        type: nfs
        server: falhallanas.lab
        path: /nfs/Media
        mountPath: /media
      incomplete:
        enabled: true
        type: emptyDir
    nodeSelector:
      node-role.kubernetes.io/worker: "true"
    resources:
      requests:
        # cpu: 1m
        memory: 100Mi
      limits:
        memory: 500Mi
